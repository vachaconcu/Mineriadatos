{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnetv2PRUEBAS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vachaconcu/Mineriadatos/blob/master/Resnetv2PRUEBAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMbq5gCEA3B7",
        "colab_type": "code",
        "outputId": "73528678-2b55-49f5-b4fb-46648ecb4fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CTb70R3YZDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from numpy import load\n",
        "os.chdir('/content/drive/My Drive/Mineria/Interna/datos')\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_val_int.npz') ; x_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_train.npz') ; x_train = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_val_int.npz') ; y_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_train.npz') ; y_train = datos['arr_0']\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_val_ext.npz') ; y_test2 = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_val_ext.npz') ; x_test2 = datos['arr_0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7RbMR55bWhS",
        "colab_type": "code",
        "outputId": "645962ef-cc5e-4fed-d5f5-f9fee771e232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('x_test =',x_test.shape)\n",
        "print('x_train =',x_train.shape)\n",
        "print('y_test =',y_test.shape)\n",
        "print('y_train =',y_train.shape)\n",
        "\n",
        "print('y_test_ext=', y_test2.shape)\n",
        "print('x_test_ext=', x_test2.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test = (1719, 200, 200, 3)\n",
            "x_train = (6874, 200, 200, 3)\n",
            "y_test = (1719, 2)\n",
            "y_train = (6874, 2)\n",
            "y_test_ext= (2063, 2)\n",
            "x_test_ext= (2063, 200, 200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9DCAJzn05wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoVqIG4mojgL",
        "colab_type": "code",
        "outputId": "bdcc0254-9e19-47f0-a052-a1363bd04fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 32 \n",
        "epochs = 80\n",
        "data_augmentation = True\n",
        "num_classes = 2\n",
        "subtract_pixel_mean = True # subtracting pixel mean improves accuracy\n",
        "n = 2\n",
        "version = 2\n",
        "\n",
        "# computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "model_type"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ResNet20v2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kql8upFhpIg_",
        "colab_type": "code",
        "outputId": "6d245d7a-8472-4ec9-dce3-aa6c7b74568b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# if subtract pixel mean is enabled \n",
        "# center the column-data around zero\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "    X_test2= x_test2\n",
        "    x_test2 -= x_train_mean\n",
        "    \n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (6874, 200, 200, 3)\n",
            "6874 train samples\n",
            "1719 test samples\n",
            "y_train shape: (6874, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j58TCUSpTH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmx8ifYrprJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    dropout=0.5\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Y0J8UMp3TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=2):\n",
        "\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVUkR2XgqCuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T92lYa5JqG1t",
        "colab_type": "code",
        "outputId": "8ac94c86-4b3f-4400-b4fc-c2e6f5f737e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200, 200, 16) 0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 200, 200, 16) 272         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200, 200, 16) 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 200, 200, 16) 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 64) 1088        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 64) 1088        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 200, 200, 64) 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 64) 0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 200, 200, 16) 1040        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 16) 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 200, 200, 16) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 200, 200, 64) 1088        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 200, 200, 64) 0           add[0][0]                        \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 200, 200, 64) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 100, 100, 64) 4160        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 100, 100, 64) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 100, 100, 64) 36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 100, 100, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 100, 100, 64) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 100, 100, 128 8320        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 100, 100, 128 8320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 100, 100, 128 0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 100, 100, 128 512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 100, 100, 128 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 100, 100, 128 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 100, 100, 64) 8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 100, 100, 64) 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 100, 100, 64) 0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 128 8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 100, 100, 128 0           add_2[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 100, 128 512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100, 100, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 100, 100, 128 0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 50, 50, 128)  16512       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 50, 50, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 50, 50, 128)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 50, 50, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 50, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 50, 50, 128)  0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 256)  33024       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 256)  33024       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 50, 50, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 50, 50, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 50, 50, 256)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 50, 50, 128)  32896       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 50, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 50, 50, 128)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 50, 50, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 50, 50, 128)  0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 50, 50, 256)  33024       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 50, 50, 256)  0           add_4[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 50, 50, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 50, 50, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 50, 50, 256)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 6, 6, 256)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            18434       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 589,954\n",
            "Trainable params: 586,466\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCCfDIRF1uOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using last check point\n",
        "#from tensorflow.keras.models import load_model\n",
        "\n",
        "#model = load_model('/content/drive/My Drive/Mineria/Interna/datos/Modelos/mujer_ResNet20v2_model.083.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiZiKwkziQ4s",
        "colab_type": "code",
        "outputId": "9ba65938-d2bc-4750-ef61-352b986e8367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Resnetv2')\n",
        "model_name = 'HM_0.5_0.5_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0346 - accuracy: 0.7014\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.76033, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.001.h5\n",
            "214/214 [==============================] - 127s 595ms/step - loss: 1.0346 - accuracy: 0.7014 - val_loss: 0.8766 - val_accuracy: 0.7603 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8369 - accuracy: 0.7738\n",
            "Epoch 00002: val_accuracy did not improve from 0.76033\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.8369 - accuracy: 0.7738 - val_loss: 0.9144 - val_accuracy: 0.6998 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7961 - accuracy: 0.7667\n",
            "Epoch 00003: val_accuracy improved from 0.76033 to 0.76265, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.003.h5\n",
            "214/214 [==============================] - 124s 579ms/step - loss: 0.7961 - accuracy: 0.7667 - val_loss: 0.7604 - val_accuracy: 0.7627 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.7979\n",
            "Epoch 00004: val_accuracy improved from 0.76265 to 0.81734, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.004.h5\n",
            "214/214 [==============================] - 124s 578ms/step - loss: 0.6994 - accuracy: 0.7979 - val_loss: 0.6372 - val_accuracy: 0.8173 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.7938\n",
            "Epoch 00005: val_accuracy improved from 0.81734 to 0.82548, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.005.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.6569 - accuracy: 0.7938 - val_loss: 0.5943 - val_accuracy: 0.8255 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.8027\n",
            "Epoch 00006: val_accuracy did not improve from 0.82548\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.6158 - accuracy: 0.8027 - val_loss: 0.6647 - val_accuracy: 0.7720 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.8160\n",
            "Epoch 00007: val_accuracy did not improve from 0.82548\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.5856 - accuracy: 0.8160 - val_loss: 0.5780 - val_accuracy: 0.8074 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.8204\n",
            "Epoch 00008: val_accuracy did not improve from 0.82548\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.5579 - accuracy: 0.8204 - val_loss: 0.5958 - val_accuracy: 0.7871 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5340 - accuracy: 0.8240\n",
            "Epoch 00009: val_accuracy improved from 0.82548 to 0.84002, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.009.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.5340 - accuracy: 0.8240 - val_loss: 0.4881 - val_accuracy: 0.8400 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.8213\n",
            "Epoch 00010: val_accuracy improved from 0.84002 to 0.84410, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.010.h5\n",
            "214/214 [==============================] - 124s 578ms/step - loss: 0.5219 - accuracy: 0.8213 - val_loss: 0.4777 - val_accuracy: 0.8441 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.8265\n",
            "Epoch 00011: val_accuracy improved from 0.84410 to 0.84700, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.011.h5\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.5058 - accuracy: 0.8265 - val_loss: 0.4766 - val_accuracy: 0.8470 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4890 - accuracy: 0.8310\n",
            "Epoch 00012: val_accuracy did not improve from 0.84700\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4890 - accuracy: 0.8310 - val_loss: 0.4805 - val_accuracy: 0.8325 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.8297\n",
            "Epoch 00013: val_accuracy improved from 0.84700 to 0.85398, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.013.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.4779 - accuracy: 0.8297 - val_loss: 0.4402 - val_accuracy: 0.8540 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4745 - accuracy: 0.8343\n",
            "Epoch 00014: val_accuracy improved from 0.85398 to 0.85631, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.014.h5\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.4745 - accuracy: 0.8343 - val_loss: 0.4408 - val_accuracy: 0.8563 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.8372\n",
            "Epoch 00015: val_accuracy did not improve from 0.85631\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.4705 - accuracy: 0.8372 - val_loss: 0.4337 - val_accuracy: 0.8551 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4552 - accuracy: 0.8404\n",
            "Epoch 00016: val_accuracy did not improve from 0.85631\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4552 - accuracy: 0.8404 - val_loss: 0.4234 - val_accuracy: 0.8534 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.8419\n",
            "Epoch 00017: val_accuracy did not improve from 0.85631\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.4526 - accuracy: 0.8419 - val_loss: 0.4179 - val_accuracy: 0.8540 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.8423\n",
            "Epoch 00018: val_accuracy did not improve from 0.85631\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.4383 - accuracy: 0.8423 - val_loss: 0.4485 - val_accuracy: 0.8412 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 19/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8486\n",
            "Epoch 00019: val_accuracy did not improve from 0.85631\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4326 - accuracy: 0.8486 - val_loss: 0.4375 - val_accuracy: 0.8487 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.8464\n",
            "Epoch 00020: val_accuracy improved from 0.85631 to 0.87609, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.020.h5\n",
            "214/214 [==============================] - 124s 578ms/step - loss: 0.4289 - accuracy: 0.8464 - val_loss: 0.3810 - val_accuracy: 0.8761 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 21/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4168 - accuracy: 0.8544\n",
            "Epoch 00021: val_accuracy did not improve from 0.87609\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4168 - accuracy: 0.8544 - val_loss: 0.3709 - val_accuracy: 0.8714 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.8511\n",
            "Epoch 00022: val_accuracy did not improve from 0.87609\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.4187 - accuracy: 0.8511 - val_loss: 0.3834 - val_accuracy: 0.8761 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4082 - accuracy: 0.8629\n",
            "Epoch 00023: val_accuracy did not improve from 0.87609\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.4082 - accuracy: 0.8629 - val_loss: 0.3769 - val_accuracy: 0.8732 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.8593\n",
            "Epoch 00024: val_accuracy improved from 0.87609 to 0.87725, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.024.h5\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4061 - accuracy: 0.8593 - val_loss: 0.3709 - val_accuracy: 0.8773 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.8617\n",
            "Epoch 00025: val_accuracy improved from 0.87725 to 0.88424, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.025.h5\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.4029 - accuracy: 0.8617 - val_loss: 0.3706 - val_accuracy: 0.8842 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 26/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3921 - accuracy: 0.8626\n",
            "Epoch 00026: val_accuracy did not improve from 0.88424\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3921 - accuracy: 0.8626 - val_loss: 0.4293 - val_accuracy: 0.8586 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4067 - accuracy: 0.8588\n",
            "Epoch 00027: val_accuracy did not improve from 0.88424\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.4067 - accuracy: 0.8588 - val_loss: 0.3919 - val_accuracy: 0.8714 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 28/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.8619\n",
            "Epoch 00028: val_accuracy did not improve from 0.88424\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4039 - accuracy: 0.8619 - val_loss: 0.3630 - val_accuracy: 0.8842 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 29/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8584\n",
            "Epoch 00029: val_accuracy did not improve from 0.88424\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3998 - accuracy: 0.8584 - val_loss: 0.3775 - val_accuracy: 0.8819 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3881 - accuracy: 0.8655\n",
            "Epoch 00030: val_accuracy improved from 0.88424 to 0.88947, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.030.h5\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3881 - accuracy: 0.8655 - val_loss: 0.3672 - val_accuracy: 0.8895 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 31/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8766\n",
            "Epoch 00031: val_accuracy improved from 0.88947 to 0.89005, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.031.h5\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3736 - accuracy: 0.8766 - val_loss: 0.3503 - val_accuracy: 0.8901 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 32/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3776 - accuracy: 0.8717\n",
            "Epoch 00032: val_accuracy improved from 0.89005 to 0.89587, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.032.h5\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.3776 - accuracy: 0.8717 - val_loss: 0.3404 - val_accuracy: 0.8959 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 33/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8705\n",
            "Epoch 00033: val_accuracy did not improve from 0.89587\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3792 - accuracy: 0.8705 - val_loss: 0.3479 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 34/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3795 - accuracy: 0.8728\n",
            "Epoch 00034: val_accuracy did not improve from 0.89587\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3795 - accuracy: 0.8728 - val_loss: 0.3763 - val_accuracy: 0.8796 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 35/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.8783\n",
            "Epoch 00035: val_accuracy did not improve from 0.89587\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3703 - accuracy: 0.8783 - val_loss: 0.3612 - val_accuracy: 0.8807 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 36/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8765\n",
            "Epoch 00036: val_accuracy improved from 0.89587 to 0.90285, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.036.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.3743 - accuracy: 0.8765 - val_loss: 0.3283 - val_accuracy: 0.9029 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 37/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.8794\n",
            "Epoch 00037: val_accuracy did not improve from 0.90285\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3634 - accuracy: 0.8794 - val_loss: 0.3600 - val_accuracy: 0.8883 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 38/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3694 - accuracy: 0.8777\n",
            "Epoch 00038: val_accuracy did not improve from 0.90285\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3694 - accuracy: 0.8777 - val_loss: 0.3560 - val_accuracy: 0.8842 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 39/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3576 - accuracy: 0.8804\n",
            "Epoch 00039: val_accuracy did not improve from 0.90285\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.3576 - accuracy: 0.8804 - val_loss: 0.3466 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 40/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3680 - accuracy: 0.8781\n",
            "Epoch 00040: val_accuracy did not improve from 0.90285\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3680 - accuracy: 0.8781 - val_loss: 0.4137 - val_accuracy: 0.8662 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 41/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.8753\n",
            "Epoch 00041: val_accuracy improved from 0.90285 to 0.90692, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.041.h5\n",
            "214/214 [==============================] - 124s 578ms/step - loss: 0.3673 - accuracy: 0.8753 - val_loss: 0.3218 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 42/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3554 - accuracy: 0.8837\n",
            "Epoch 00042: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3554 - accuracy: 0.8837 - val_loss: 0.3511 - val_accuracy: 0.8912 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 43/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.8774\n",
            "Epoch 00043: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3628 - accuracy: 0.8774 - val_loss: 0.3961 - val_accuracy: 0.8761 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 44/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 0.8861\n",
            "Epoch 00044: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.3461 - accuracy: 0.8861 - val_loss: 0.3383 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 45/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8832\n",
            "Epoch 00045: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3496 - accuracy: 0.8832 - val_loss: 0.3509 - val_accuracy: 0.8912 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 46/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.8872\n",
            "Epoch 00046: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 574ms/step - loss: 0.3425 - accuracy: 0.8872 - val_loss: 0.3405 - val_accuracy: 0.9011 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 47/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8863\n",
            "Epoch 00047: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3511 - accuracy: 0.8863 - val_loss: 0.3662 - val_accuracy: 0.8743 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 48/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8866\n",
            "Epoch 00048: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 574ms/step - loss: 0.3429 - accuracy: 0.8866 - val_loss: 0.3204 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 49/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8932\n",
            "Epoch 00049: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 574ms/step - loss: 0.3415 - accuracy: 0.8932 - val_loss: 0.4413 - val_accuracy: 0.8546 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 50/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.8886\n",
            "Epoch 00050: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3460 - accuracy: 0.8886 - val_loss: 0.3540 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 51/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8857\n",
            "Epoch 00051: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3494 - accuracy: 0.8857 - val_loss: 0.3908 - val_accuracy: 0.8755 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 52/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8994\n",
            "Epoch 00052: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3281 - accuracy: 0.8994 - val_loss: 0.4443 - val_accuracy: 0.8592 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 53/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3412 - accuracy: 0.8936\n",
            "Epoch 00053: val_accuracy improved from 0.90692 to 0.90809, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.053.h5\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.3412 - accuracy: 0.8936 - val_loss: 0.3160 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 54/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8933\n",
            "Epoch 00054: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3345 - accuracy: 0.8933 - val_loss: 0.3762 - val_accuracy: 0.8883 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 55/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8970\n",
            "Epoch 00055: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3309 - accuracy: 0.8970 - val_loss: 0.3315 - val_accuracy: 0.9029 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 56/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.8918\n",
            "Epoch 00056: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3381 - accuracy: 0.8918 - val_loss: 0.3422 - val_accuracy: 0.9017 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 57/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.8973\n",
            "Epoch 00057: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3300 - accuracy: 0.8973 - val_loss: 0.3293 - val_accuracy: 0.9052 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 58/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.8961\n",
            "Epoch 00058: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3290 - accuracy: 0.8961 - val_loss: 0.3497 - val_accuracy: 0.8994 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 59/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.8999\n",
            "Epoch 00059: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 574ms/step - loss: 0.3265 - accuracy: 0.8999 - val_loss: 0.3165 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 60/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.8981\n",
            "Epoch 00060: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 124s 578ms/step - loss: 0.3273 - accuracy: 0.8981 - val_loss: 0.3557 - val_accuracy: 0.8959 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 61/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3216 - accuracy: 0.9008\n",
            "Epoch 00061: val_accuracy improved from 0.90809 to 0.91041, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.061.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.3216 - accuracy: 0.9008 - val_loss: 0.3330 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 62/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8974\n",
            "Epoch 00062: val_accuracy did not improve from 0.91041\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3311 - accuracy: 0.8974 - val_loss: 0.3408 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 63/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.9022\n",
            "Epoch 00063: val_accuracy improved from 0.91041 to 0.91332, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.063.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.3226 - accuracy: 0.9022 - val_loss: 0.3146 - val_accuracy: 0.9133 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 64/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.8983\n",
            "Epoch 00064: val_accuracy did not improve from 0.91332\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3304 - accuracy: 0.8983 - val_loss: 0.3473 - val_accuracy: 0.9017 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 65/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.8942\n",
            "Epoch 00065: val_accuracy improved from 0.91332 to 0.91507, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.065.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.3305 - accuracy: 0.8942 - val_loss: 0.3137 - val_accuracy: 0.9151 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 66/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.9011\n",
            "Epoch 00066: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3239 - accuracy: 0.9011 - val_loss: 0.3413 - val_accuracy: 0.9023 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 67/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.9024\n",
            "Epoch 00067: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.3222 - accuracy: 0.9024 - val_loss: 0.3053 - val_accuracy: 0.9151 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 68/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.9009\n",
            "Epoch 00068: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 573ms/step - loss: 0.3204 - accuracy: 0.9009 - val_loss: 0.3444 - val_accuracy: 0.8999 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 69/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.9087\n",
            "Epoch 00069: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3146 - accuracy: 0.9087 - val_loss: 0.3679 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 70/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.9037\n",
            "Epoch 00070: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3170 - accuracy: 0.9037 - val_loss: 0.3133 - val_accuracy: 0.9092 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 71/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.9030\n",
            "Epoch 00071: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3168 - accuracy: 0.9030 - val_loss: 0.3222 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 72/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.9044\n",
            "Epoch 00072: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3174 - accuracy: 0.9044 - val_loss: 0.3780 - val_accuracy: 0.8912 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 73/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.9031\n",
            "Epoch 00073: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3231 - accuracy: 0.9031 - val_loss: 0.3119 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 74/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3199 - accuracy: 0.9025\n",
            "Epoch 00074: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3199 - accuracy: 0.9025 - val_loss: 0.3562 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 75/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9091\n",
            "Epoch 00075: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3092 - accuracy: 0.9091 - val_loss: 0.3232 - val_accuracy: 0.9122 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 76/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.9049\n",
            "Epoch 00076: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3147 - accuracy: 0.9049 - val_loss: 0.3490 - val_accuracy: 0.8982 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 77/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.9057\n",
            "Epoch 00077: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3173 - accuracy: 0.9057 - val_loss: 0.3372 - val_accuracy: 0.9011 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 78/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3291 - accuracy: 0.9002\n",
            "Epoch 00078: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3291 - accuracy: 0.9002 - val_loss: 0.3433 - val_accuracy: 0.8959 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 79/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.9089\n",
            "Epoch 00079: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3084 - accuracy: 0.9089 - val_loss: 0.3522 - val_accuracy: 0.9011 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 80/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.9085\n",
            "Epoch 00080: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3087 - accuracy: 0.9085 - val_loss: 0.3276 - val_accuracy: 0.9098 - lr: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezaiJkW-irF6",
        "colab_type": "code",
        "outputId": "199a4fc4-85c9-46a3-b5d7-c6065a7c9659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b8zeH3hLdZt",
        "colab_type": "code",
        "outputId": "0afdf9ae-6296-4335-d82b-1ec5c00d2d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    dropout=0.6\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=2):\n",
        "\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)\n",
        "\n",
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Resnetv2')\n",
        "model_name = 'HM_0.25_0.25_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200, 200, 16) 0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 200, 200, 16) 272         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200, 200, 16) 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 200, 200, 16) 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 64) 1088        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 64) 1088        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 200, 200, 64) 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 64) 0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 200, 200, 16) 1040        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 16) 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 200, 200, 16) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 200, 200, 64) 1088        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 200, 200, 64) 0           add[0][0]                        \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 200, 200, 64) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 100, 100, 64) 4160        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 100, 100, 64) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 100, 100, 64) 36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 100, 100, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 100, 100, 64) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 100, 100, 128 8320        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 100, 100, 128 8320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 100, 100, 128 0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 100, 100, 128 512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 100, 100, 128 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 100, 100, 128 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 100, 100, 64) 8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 100, 100, 64) 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 100, 100, 64) 0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 128 8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 100, 100, 128 0           add_2[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 100, 128 512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100, 100, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 100, 100, 128 0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 50, 50, 128)  16512       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 50, 50, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 50, 50, 128)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 50, 50, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 50, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 50, 50, 128)  0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 256)  33024       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 256)  33024       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 50, 50, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 50, 50, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 50, 50, 256)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 50, 50, 128)  32896       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 50, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 50, 50, 128)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 50, 50, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 50, 50, 128)  0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 50, 50, 256)  33024       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 50, 50, 256)  0           add_4[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 50, 50, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 50, 50, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 50, 50, 256)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 6, 6, 256)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            18434       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 589,954\n",
            "Trainable params: 586,466\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0217 - accuracy: 0.6919\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.76323, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.001.h5\n",
            "214/214 [==============================] - 188s 879ms/step - loss: 1.0217 - accuracy: 0.6919 - val_loss: 0.8983 - val_accuracy: 0.7632 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8521 - accuracy: 0.7555\n",
            "Epoch 00002: val_accuracy improved from 0.76323 to 0.76382, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.002.h5\n",
            "214/214 [==============================] - 185s 865ms/step - loss: 0.8521 - accuracy: 0.7555 - val_loss: 0.7928 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7568 - accuracy: 0.7821\n",
            "Epoch 00003: val_accuracy improved from 0.76382 to 0.80454, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.003.h5\n",
            "214/214 [==============================] - 185s 865ms/step - loss: 0.7568 - accuracy: 0.7821 - val_loss: 0.6908 - val_accuracy: 0.8045 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.7869\n",
            "Epoch 00004: val_accuracy did not improve from 0.80454\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.6928 - accuracy: 0.7869 - val_loss: 0.7660 - val_accuracy: 0.7568 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.7974\n",
            "Epoch 00005: val_accuracy improved from 0.80454 to 0.82606, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.005.h5\n",
            "214/214 [==============================] - 185s 865ms/step - loss: 0.6396 - accuracy: 0.7974 - val_loss: 0.5770 - val_accuracy: 0.8261 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6043 - accuracy: 0.8040\n",
            "Epoch 00006: val_accuracy did not improve from 0.82606\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.6043 - accuracy: 0.8040 - val_loss: 0.5774 - val_accuracy: 0.8162 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5926 - accuracy: 0.8011\n",
            "Epoch 00007: val_accuracy did not improve from 0.82606\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.5926 - accuracy: 0.8011 - val_loss: 0.5569 - val_accuracy: 0.8121 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5583 - accuracy: 0.8077\n",
            "Epoch 00008: val_accuracy did not improve from 0.82606\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.5583 - accuracy: 0.8077 - val_loss: 0.5150 - val_accuracy: 0.8255 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.8220\n",
            "Epoch 00009: val_accuracy improved from 0.82606 to 0.84293, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.009.h5\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.5289 - accuracy: 0.8220 - val_loss: 0.4823 - val_accuracy: 0.8429 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.8232\n",
            "Epoch 00010: val_accuracy did not improve from 0.84293\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.5131 - accuracy: 0.8232 - val_loss: 0.4846 - val_accuracy: 0.8325 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.8268\n",
            "Epoch 00011: val_accuracy did not improve from 0.84293\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.5015 - accuracy: 0.8268 - val_loss: 0.4673 - val_accuracy: 0.8418 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.8239\n",
            "Epoch 00012: val_accuracy improved from 0.84293 to 0.85282, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.012.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.5055 - accuracy: 0.8239 - val_loss: 0.4393 - val_accuracy: 0.8528 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4852 - accuracy: 0.8329\n",
            "Epoch 00013: val_accuracy did not improve from 0.85282\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.4852 - accuracy: 0.8329 - val_loss: 0.4540 - val_accuracy: 0.8424 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.8310\n",
            "Epoch 00014: val_accuracy did not improve from 0.85282\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.4730 - accuracy: 0.8310 - val_loss: 0.5035 - val_accuracy: 0.8278 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.8324\n",
            "Epoch 00015: val_accuracy did not improve from 0.85282\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.4753 - accuracy: 0.8324 - val_loss: 0.4441 - val_accuracy: 0.8458 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.8407\n",
            "Epoch 00016: val_accuracy did not improve from 0.85282\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.4583 - accuracy: 0.8407 - val_loss: 0.4507 - val_accuracy: 0.8418 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.8432\n",
            "Epoch 00017: val_accuracy improved from 0.85282 to 0.86097, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.017.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.4564 - accuracy: 0.8432 - val_loss: 0.4056 - val_accuracy: 0.8610 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.8359\n",
            "Epoch 00018: val_accuracy did not improve from 0.86097\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.4601 - accuracy: 0.8359 - val_loss: 0.5157 - val_accuracy: 0.8173 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 19/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.8438\n",
            "Epoch 00019: val_accuracy did not improve from 0.86097\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.4439 - accuracy: 0.8438 - val_loss: 0.4079 - val_accuracy: 0.8598 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.8432\n",
            "Epoch 00020: val_accuracy improved from 0.86097 to 0.86271, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.020.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.4455 - accuracy: 0.8432 - val_loss: 0.3974 - val_accuracy: 0.8627 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 21/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.8500\n",
            "Epoch 00021: val_accuracy did not improve from 0.86271\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.4262 - accuracy: 0.8500 - val_loss: 0.4153 - val_accuracy: 0.8551 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.8461\n",
            "Epoch 00022: val_accuracy did not improve from 0.86271\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.4368 - accuracy: 0.8461 - val_loss: 0.3885 - val_accuracy: 0.8621 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4258 - accuracy: 0.8518\n",
            "Epoch 00023: val_accuracy did not improve from 0.86271\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.4258 - accuracy: 0.8518 - val_loss: 0.3998 - val_accuracy: 0.8522 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4265 - accuracy: 0.8445\n",
            "Epoch 00024: val_accuracy improved from 0.86271 to 0.86969, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.024.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.4265 - accuracy: 0.8445 - val_loss: 0.3764 - val_accuracy: 0.8697 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.8511\n",
            "Epoch 00025: val_accuracy did not improve from 0.86969\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.4232 - accuracy: 0.8511 - val_loss: 0.4643 - val_accuracy: 0.8360 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 26/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.8524\n",
            "Epoch 00026: val_accuracy improved from 0.86969 to 0.87318, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.026.h5\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.4192 - accuracy: 0.8524 - val_loss: 0.3814 - val_accuracy: 0.8732 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4137 - accuracy: 0.8546\n",
            "Epoch 00027: val_accuracy improved from 0.87318 to 0.88540, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.027.h5\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.4137 - accuracy: 0.8546 - val_loss: 0.3548 - val_accuracy: 0.8854 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 28/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4183 - accuracy: 0.8552\n",
            "Epoch 00028: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.4183 - accuracy: 0.8552 - val_loss: 0.3862 - val_accuracy: 0.8639 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 29/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.8606\n",
            "Epoch 00029: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.4036 - accuracy: 0.8606 - val_loss: 0.3821 - val_accuracy: 0.8679 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8655\n",
            "Epoch 00030: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.3980 - accuracy: 0.8655 - val_loss: 0.3851 - val_accuracy: 0.8703 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 31/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.8609\n",
            "Epoch 00031: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.4068 - accuracy: 0.8609 - val_loss: 0.3814 - val_accuracy: 0.8714 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 32/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.8654\n",
            "Epoch 00032: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3987 - accuracy: 0.8654 - val_loss: 0.3938 - val_accuracy: 0.8645 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 33/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.8670\n",
            "Epoch 00033: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3971 - accuracy: 0.8670 - val_loss: 0.3888 - val_accuracy: 0.8709 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 34/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3969 - accuracy: 0.8622\n",
            "Epoch 00034: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3969 - accuracy: 0.8622 - val_loss: 0.3997 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 35/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8682\n",
            "Epoch 00035: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3846 - accuracy: 0.8682 - val_loss: 0.5373 - val_accuracy: 0.8086 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 36/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3929 - accuracy: 0.8645\n",
            "Epoch 00036: val_accuracy improved from 0.88540 to 0.88656, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.036.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3929 - accuracy: 0.8645 - val_loss: 0.3499 - val_accuracy: 0.8866 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 37/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8715\n",
            "Epoch 00037: val_accuracy did not improve from 0.88656\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3857 - accuracy: 0.8715 - val_loss: 0.3469 - val_accuracy: 0.8854 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 38/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3880 - accuracy: 0.8692\n",
            "Epoch 00038: val_accuracy did not improve from 0.88656\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.3880 - accuracy: 0.8692 - val_loss: 0.3893 - val_accuracy: 0.8621 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 39/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8702\n",
            "Epoch 00039: val_accuracy did not improve from 0.88656\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3882 - accuracy: 0.8702 - val_loss: 0.4025 - val_accuracy: 0.8604 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 40/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8689\n",
            "Epoch 00040: val_accuracy did not improve from 0.88656\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.3854 - accuracy: 0.8689 - val_loss: 0.3833 - val_accuracy: 0.8767 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 41/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3748 - accuracy: 0.8785\n",
            "Epoch 00041: val_accuracy did not improve from 0.88656\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3748 - accuracy: 0.8785 - val_loss: 0.3978 - val_accuracy: 0.8703 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 42/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8765\n",
            "Epoch 00042: val_accuracy did not improve from 0.88656\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3746 - accuracy: 0.8765 - val_loss: 0.3559 - val_accuracy: 0.8819 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 43/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.8749\n",
            "Epoch 00043: val_accuracy did not improve from 0.88656\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.3782 - accuracy: 0.8749 - val_loss: 0.3899 - val_accuracy: 0.8720 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 44/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.8775\n",
            "Epoch 00044: val_accuracy did not improve from 0.88656\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3757 - accuracy: 0.8775 - val_loss: 0.4337 - val_accuracy: 0.8610 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 45/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3697 - accuracy: 0.8777\n",
            "Epoch 00045: val_accuracy did not improve from 0.88656\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3697 - accuracy: 0.8777 - val_loss: 0.3683 - val_accuracy: 0.8773 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 46/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3715 - accuracy: 0.8777\n",
            "Epoch 00046: val_accuracy improved from 0.88656 to 0.89238, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.046.h5\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3715 - accuracy: 0.8777 - val_loss: 0.3466 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 47/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8790\n",
            "Epoch 00047: val_accuracy did not improve from 0.89238\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3655 - accuracy: 0.8790 - val_loss: 0.3545 - val_accuracy: 0.8901 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 48/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3665 - accuracy: 0.8850\n",
            "Epoch 00048: val_accuracy did not improve from 0.89238\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3665 - accuracy: 0.8850 - val_loss: 0.3842 - val_accuracy: 0.8860 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 49/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8803\n",
            "Epoch 00049: val_accuracy did not improve from 0.89238\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3663 - accuracy: 0.8803 - val_loss: 0.3781 - val_accuracy: 0.8831 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 50/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8819\n",
            "Epoch 00050: val_accuracy did not improve from 0.89238\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3655 - accuracy: 0.8819 - val_loss: 0.3594 - val_accuracy: 0.8871 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 51/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.8812\n",
            "Epoch 00051: val_accuracy did not improve from 0.89238\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3609 - accuracy: 0.8812 - val_loss: 0.3633 - val_accuracy: 0.8883 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 52/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8857\n",
            "Epoch 00052: val_accuracy did not improve from 0.89238\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3607 - accuracy: 0.8857 - val_loss: 0.3461 - val_accuracy: 0.8912 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 53/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8870\n",
            "Epoch 00053: val_accuracy improved from 0.89238 to 0.89354, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.053.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.3583 - accuracy: 0.8870 - val_loss: 0.3505 - val_accuracy: 0.8935 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 54/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3582 - accuracy: 0.8866\n",
            "Epoch 00054: val_accuracy improved from 0.89354 to 0.89703, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.054.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.3582 - accuracy: 0.8866 - val_loss: 0.3504 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 55/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8832\n",
            "Epoch 00055: val_accuracy did not improve from 0.89703\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3607 - accuracy: 0.8832 - val_loss: 0.3467 - val_accuracy: 0.8965 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 56/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3472 - accuracy: 0.8961\n",
            "Epoch 00056: val_accuracy did not improve from 0.89703\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3472 - accuracy: 0.8961 - val_loss: 0.3415 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 57/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.8917\n",
            "Epoch 00057: val_accuracy did not improve from 0.89703\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.3485 - accuracy: 0.8917 - val_loss: 0.3668 - val_accuracy: 0.8866 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 58/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.8841\n",
            "Epoch 00058: val_accuracy did not improve from 0.89703\n",
            "214/214 [==============================] - 183s 853ms/step - loss: 0.3586 - accuracy: 0.8841 - val_loss: 0.3875 - val_accuracy: 0.8784 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 59/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.8891\n",
            "Epoch 00059: val_accuracy did not improve from 0.89703\n",
            "214/214 [==============================] - 183s 853ms/step - loss: 0.3486 - accuracy: 0.8891 - val_loss: 0.3491 - val_accuracy: 0.8918 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 60/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.8921\n",
            "Epoch 00060: val_accuracy did not improve from 0.89703\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.3498 - accuracy: 0.8921 - val_loss: 0.3803 - val_accuracy: 0.8860 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 61/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3554 - accuracy: 0.8872\n",
            "Epoch 00061: val_accuracy improved from 0.89703 to 0.90052, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.061.h5\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3554 - accuracy: 0.8872 - val_loss: 0.3318 - val_accuracy: 0.9005 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 62/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.8949\n",
            "Epoch 00062: val_accuracy did not improve from 0.90052\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.3406 - accuracy: 0.8949 - val_loss: 0.4166 - val_accuracy: 0.8633 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 63/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.8891\n",
            "Epoch 00063: val_accuracy did not improve from 0.90052\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3550 - accuracy: 0.8891 - val_loss: 0.3437 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 64/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.8921\n",
            "Epoch 00064: val_accuracy did not improve from 0.90052\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3476 - accuracy: 0.8921 - val_loss: 0.3545 - val_accuracy: 0.8965 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 65/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.8948\n",
            "Epoch 00065: val_accuracy did not improve from 0.90052\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3474 - accuracy: 0.8948 - val_loss: 0.3718 - val_accuracy: 0.8854 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 66/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.8918\n",
            "Epoch 00066: val_accuracy did not improve from 0.90052\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3458 - accuracy: 0.8918 - val_loss: 0.3730 - val_accuracy: 0.8906 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 67/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.8939\n",
            "Epoch 00067: val_accuracy did not improve from 0.90052\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3430 - accuracy: 0.8939 - val_loss: 0.4086 - val_accuracy: 0.8726 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 68/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.8932\n",
            "Epoch 00068: val_accuracy did not improve from 0.90052\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3490 - accuracy: 0.8932 - val_loss: 0.3578 - val_accuracy: 0.8982 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 69/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3439 - accuracy: 0.8977\n",
            "Epoch 00069: val_accuracy improved from 0.90052 to 0.90576, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.069.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3439 - accuracy: 0.8977 - val_loss: 0.3241 - val_accuracy: 0.9058 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 70/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.8975\n",
            "Epoch 00070: val_accuracy did not improve from 0.90576\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3406 - accuracy: 0.8975 - val_loss: 0.3328 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 71/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.8977\n",
            "Epoch 00071: val_accuracy did not improve from 0.90576\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3307 - accuracy: 0.8977 - val_loss: 0.3367 - val_accuracy: 0.8965 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 72/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.8932\n",
            "Epoch 00072: val_accuracy did not improve from 0.90576\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3482 - accuracy: 0.8932 - val_loss: 0.3578 - val_accuracy: 0.8965 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 73/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.8964\n",
            "Epoch 00073: val_accuracy did not improve from 0.90576\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3377 - accuracy: 0.8964 - val_loss: 0.3572 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 74/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3348 - accuracy: 0.8943\n",
            "Epoch 00074: val_accuracy did not improve from 0.90576\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3348 - accuracy: 0.8943 - val_loss: 0.3299 - val_accuracy: 0.8982 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 75/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8973\n",
            "Epoch 00075: val_accuracy did not improve from 0.90576\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3312 - accuracy: 0.8973 - val_loss: 0.3742 - val_accuracy: 0.8901 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 76/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3497 - accuracy: 0.8880\n",
            "Epoch 00076: val_accuracy improved from 0.90576 to 0.90750, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.076.h5\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3497 - accuracy: 0.8880 - val_loss: 0.3424 - val_accuracy: 0.9075 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 77/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.8936\n",
            "Epoch 00077: val_accuracy did not improve from 0.90750\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3387 - accuracy: 0.8936 - val_loss: 0.3732 - val_accuracy: 0.8837 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 78/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3451 - accuracy: 0.8946\n",
            "Epoch 00078: val_accuracy did not improve from 0.90750\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3451 - accuracy: 0.8946 - val_loss: 0.3733 - val_accuracy: 0.8895 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 79/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 0.8897\n",
            "Epoch 00079: val_accuracy did not improve from 0.90750\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3461 - accuracy: 0.8897 - val_loss: 0.4085 - val_accuracy: 0.8674 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 80/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.8984\n",
            "Epoch 00080: val_accuracy did not improve from 0.90750\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3336 - accuracy: 0.8984 - val_loss: 0.3386 - val_accuracy: 0.9017 - lr: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYGE4N1MLeRI",
        "colab_type": "code",
        "outputId": "80ee24e0-5fd4-44c6-e7d8-fde7a98e8000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hDwTgshEMEKF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5e31ba1-f5a8-4f41-cb13-ba9656f51c22"
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    dropout=0.3\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=2):\n",
        "\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)\n",
        "\n",
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Resnetv2')\n",
        "model_name = 'HM_0.3_0.3_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200, 200, 16) 0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 200, 200, 16) 272         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200, 200, 16) 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 200, 200, 16) 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 64) 1088        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 64) 1088        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 200, 200, 64) 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 64) 0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 200, 200, 16) 1040        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 16) 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 200, 200, 16) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 200, 200, 64) 1088        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 200, 200, 64) 0           add[0][0]                        \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 200, 200, 64) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 100, 100, 64) 4160        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 100, 100, 64) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 100, 100, 64) 36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 100, 100, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 100, 100, 64) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 100, 100, 128 8320        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 100, 100, 128 8320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 100, 100, 128 0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 100, 100, 128 512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 100, 100, 128 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 100, 100, 128 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 100, 100, 64) 8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 100, 100, 64) 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 100, 100, 64) 0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 128 8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 100, 100, 128 0           add_2[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 100, 128 512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100, 100, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 100, 100, 128 0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 50, 50, 128)  16512       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 50, 50, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 50, 50, 128)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 50, 50, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 50, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 50, 50, 128)  0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 256)  33024       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 256)  33024       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 50, 50, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 50, 50, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 50, 50, 256)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 50, 50, 128)  32896       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 50, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 50, 50, 128)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 50, 50, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 50, 50, 128)  0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 50, 50, 256)  33024       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 50, 50, 256)  0           add_4[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 50, 50, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 50, 50, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 50, 50, 256)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 6, 6, 256)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            18434       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 589,954\n",
            "Trainable params: 586,466\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9938 - accuracy: 0.7363\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.73822, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.001.h5\n",
            "214/214 [==============================] - 232s 1s/step - loss: 0.9938 - accuracy: 0.7363 - val_loss: 0.9167 - val_accuracy: 0.7382 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8566 - accuracy: 0.7644\n",
            "Epoch 00002: val_accuracy improved from 0.73822 to 0.76731, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.002.h5\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.8566 - accuracy: 0.7644 - val_loss: 0.8104 - val_accuracy: 0.7673 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7736 - accuracy: 0.7787\n",
            "Epoch 00003: val_accuracy improved from 0.76731 to 0.77196, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.003.h5\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.7736 - accuracy: 0.7787 - val_loss: 0.7535 - val_accuracy: 0.7720 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7056 - accuracy: 0.7895\n",
            "Epoch 00004: val_accuracy improved from 0.77196 to 0.80279, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.004.h5\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.7056 - accuracy: 0.7895 - val_loss: 0.6411 - val_accuracy: 0.8028 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6575 - accuracy: 0.7961\n",
            "Epoch 00005: val_accuracy improved from 0.80279 to 0.82723, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.005.h5\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.6575 - accuracy: 0.7961 - val_loss: 0.5819 - val_accuracy: 0.8272 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6094 - accuracy: 0.8084\n",
            "Epoch 00006: val_accuracy did not improve from 0.82723\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.6094 - accuracy: 0.8084 - val_loss: 0.5577 - val_accuracy: 0.8243 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.8033\n",
            "Epoch 00007: val_accuracy did not improve from 0.82723\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.5859 - accuracy: 0.8033 - val_loss: 0.5689 - val_accuracy: 0.8080 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5577 - accuracy: 0.8118\n",
            "Epoch 00008: val_accuracy improved from 0.82723 to 0.83537, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.008.h5\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.5577 - accuracy: 0.8118 - val_loss: 0.5084 - val_accuracy: 0.8354 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.8118\n",
            "Epoch 00009: val_accuracy did not improve from 0.83537\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.5441 - accuracy: 0.8118 - val_loss: 0.4947 - val_accuracy: 0.8301 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.8148\n",
            "Epoch 00010: val_accuracy did not improve from 0.83537\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.5224 - accuracy: 0.8148 - val_loss: 0.5210 - val_accuracy: 0.8191 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.8180\n",
            "Epoch 00011: val_accuracy did not improve from 0.83537\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.5092 - accuracy: 0.8180 - val_loss: 0.4713 - val_accuracy: 0.8348 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4874 - accuracy: 0.8281\n",
            "Epoch 00012: val_accuracy improved from 0.83537 to 0.85166, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.012.h5\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.4874 - accuracy: 0.8281 - val_loss: 0.4471 - val_accuracy: 0.8517 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.8369\n",
            "Epoch 00013: val_accuracy did not improve from 0.85166\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.4742 - accuracy: 0.8369 - val_loss: 0.4355 - val_accuracy: 0.8511 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.8376\n",
            "Epoch 00014: val_accuracy improved from 0.85166 to 0.86387, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.014.h5\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.4563 - accuracy: 0.8376 - val_loss: 0.4034 - val_accuracy: 0.8639 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.8419\n",
            "Epoch 00015: val_accuracy improved from 0.86387 to 0.87435, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.015.h5\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.4465 - accuracy: 0.8419 - val_loss: 0.3880 - val_accuracy: 0.8743 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.8386\n",
            "Epoch 00016: val_accuracy did not improve from 0.87435\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.4501 - accuracy: 0.8386 - val_loss: 0.5695 - val_accuracy: 0.7929 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.8484\n",
            "Epoch 00017: val_accuracy did not improve from 0.87435\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.4363 - accuracy: 0.8484 - val_loss: 0.4132 - val_accuracy: 0.8540 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4189 - accuracy: 0.8534\n",
            "Epoch 00018: val_accuracy did not improve from 0.87435\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.4189 - accuracy: 0.8534 - val_loss: 0.3788 - val_accuracy: 0.8714 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 19/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.8546\n",
            "Epoch 00019: val_accuracy did not improve from 0.87435\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.4163 - accuracy: 0.8546 - val_loss: 0.3747 - val_accuracy: 0.8674 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.8614\n",
            "Epoch 00020: val_accuracy improved from 0.87435 to 0.87900, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.020.h5\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.4044 - accuracy: 0.8614 - val_loss: 0.3670 - val_accuracy: 0.8790 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 21/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.8628\n",
            "Epoch 00021: val_accuracy did not improve from 0.87900\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3978 - accuracy: 0.8628 - val_loss: 0.3800 - val_accuracy: 0.8668 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.8667\n",
            "Epoch 00022: val_accuracy improved from 0.87900 to 0.88191, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.022.h5\n",
            "214/214 [==============================] - 230s 1s/step - loss: 0.3933 - accuracy: 0.8667 - val_loss: 0.3691 - val_accuracy: 0.8819 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3930 - accuracy: 0.8639\n",
            "Epoch 00023: val_accuracy did not improve from 0.88191\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3930 - accuracy: 0.8639 - val_loss: 0.3578 - val_accuracy: 0.8790 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.8707\n",
            "Epoch 00024: val_accuracy did not improve from 0.88191\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3785 - accuracy: 0.8707 - val_loss: 0.4922 - val_accuracy: 0.8214 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.8701\n",
            "Epoch 00025: val_accuracy did not improve from 0.88191\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3752 - accuracy: 0.8701 - val_loss: 0.4074 - val_accuracy: 0.8598 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 26/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.8673\n",
            "Epoch 00026: val_accuracy improved from 0.88191 to 0.89354, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.026.h5\n",
            "214/214 [==============================] - 230s 1s/step - loss: 0.3718 - accuracy: 0.8673 - val_loss: 0.3243 - val_accuracy: 0.8935 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.8804\n",
            "Epoch 00027: val_accuracy did not improve from 0.89354\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3626 - accuracy: 0.8804 - val_loss: 0.4096 - val_accuracy: 0.8645 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 28/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.8841\n",
            "Epoch 00028: val_accuracy did not improve from 0.89354\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.3520 - accuracy: 0.8841 - val_loss: 0.3662 - val_accuracy: 0.8848 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 29/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3487 - accuracy: 0.8832\n",
            "Epoch 00029: val_accuracy improved from 0.89354 to 0.90227, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.029.h5\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3487 - accuracy: 0.8832 - val_loss: 0.3257 - val_accuracy: 0.9023 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.8799\n",
            "Epoch 00030: val_accuracy did not improve from 0.90227\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.3546 - accuracy: 0.8799 - val_loss: 0.3831 - val_accuracy: 0.8703 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 31/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3483 - accuracy: 0.8818\n",
            "Epoch 00031: val_accuracy improved from 0.90227 to 0.90634, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.031.h5\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3483 - accuracy: 0.8818 - val_loss: 0.3118 - val_accuracy: 0.9063 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 32/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8859\n",
            "Epoch 00032: val_accuracy did not improve from 0.90634\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3429 - accuracy: 0.8859 - val_loss: 0.3379 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 33/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.8847\n",
            "Epoch 00033: val_accuracy did not improve from 0.90634\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.3510 - accuracy: 0.8847 - val_loss: 0.3248 - val_accuracy: 0.8930 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 34/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.8899\n",
            "Epoch 00034: val_accuracy did not improve from 0.90634\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3313 - accuracy: 0.8899 - val_loss: 0.3826 - val_accuracy: 0.8685 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 35/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.8911\n",
            "Epoch 00035: val_accuracy did not improve from 0.90634\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3308 - accuracy: 0.8911 - val_loss: 0.3092 - val_accuracy: 0.8999 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 36/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.8929\n",
            "Epoch 00036: val_accuracy did not improve from 0.90634\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.3255 - accuracy: 0.8929 - val_loss: 0.3662 - val_accuracy: 0.8825 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 37/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3390 - accuracy: 0.8888\n",
            "Epoch 00037: val_accuracy did not improve from 0.90634\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.3390 - accuracy: 0.8888 - val_loss: 0.3375 - val_accuracy: 0.8895 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 38/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3330 - accuracy: 0.8907\n",
            "Epoch 00038: val_accuracy did not improve from 0.90634\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.3330 - accuracy: 0.8907 - val_loss: 0.3387 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 39/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.8930\n",
            "Epoch 00039: val_accuracy improved from 0.90634 to 0.91623, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.039.h5\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.3251 - accuracy: 0.8930 - val_loss: 0.3074 - val_accuracy: 0.9162 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 40/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.8946\n",
            "Epoch 00040: val_accuracy did not improve from 0.91623\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.3213 - accuracy: 0.8946 - val_loss: 0.3173 - val_accuracy: 0.8994 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 41/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.8965\n",
            "Epoch 00041: val_accuracy did not improve from 0.91623\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.3193 - accuracy: 0.8965 - val_loss: 0.3098 - val_accuracy: 0.8982 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 42/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.9040\n",
            "Epoch 00042: val_accuracy did not improve from 0.91623\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.3033 - accuracy: 0.9040 - val_loss: 0.2884 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 43/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.8954\n",
            "Epoch 00043: val_accuracy did not improve from 0.91623\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.3130 - accuracy: 0.8954 - val_loss: 0.2900 - val_accuracy: 0.9098 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 44/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.8939\n",
            "Epoch 00044: val_accuracy did not improve from 0.91623\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.3207 - accuracy: 0.8939 - val_loss: 0.2822 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 45/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.9053\n",
            "Epoch 00045: val_accuracy improved from 0.91623 to 0.92554, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.045.h5\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.3047 - accuracy: 0.9053 - val_loss: 0.2744 - val_accuracy: 0.9255 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 46/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.9028\n",
            "Epoch 00046: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.3072 - accuracy: 0.9028 - val_loss: 0.2963 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 47/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.8993\n",
            "Epoch 00047: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.3091 - accuracy: 0.8993 - val_loss: 0.3049 - val_accuracy: 0.9098 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 48/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.9079\n",
            "Epoch 00048: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2941 - accuracy: 0.9079 - val_loss: 0.3199 - val_accuracy: 0.8982 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 49/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.9056\n",
            "Epoch 00049: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2991 - accuracy: 0.9056 - val_loss: 0.2902 - val_accuracy: 0.9127 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 50/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 0.9044\n",
            "Epoch 00050: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2969 - accuracy: 0.9044 - val_loss: 0.2773 - val_accuracy: 0.9209 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 51/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.9043\n",
            "Epoch 00051: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.3003 - accuracy: 0.9043 - val_loss: 0.2852 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 52/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.9085\n",
            "Epoch 00052: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.2878 - accuracy: 0.9085 - val_loss: 0.2830 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 53/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.9060\n",
            "Epoch 00053: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2891 - accuracy: 0.9060 - val_loss: 0.2718 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 54/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.9072\n",
            "Epoch 00054: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2915 - accuracy: 0.9072 - val_loss: 0.2931 - val_accuracy: 0.9162 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 55/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.9094\n",
            "Epoch 00055: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2820 - accuracy: 0.9094 - val_loss: 0.2936 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 56/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.9095\n",
            "Epoch 00056: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2925 - accuracy: 0.9095 - val_loss: 0.2755 - val_accuracy: 0.9186 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 57/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.9116\n",
            "Epoch 00057: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2809 - accuracy: 0.9116 - val_loss: 0.2768 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 58/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.9126\n",
            "Epoch 00058: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2799 - accuracy: 0.9126 - val_loss: 0.3106 - val_accuracy: 0.9052 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 59/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.9116\n",
            "Epoch 00059: val_accuracy improved from 0.92554 to 0.92787, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.3_0.3_ResNet20v2_model.059.h5\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2756 - accuracy: 0.9116 - val_loss: 0.2657 - val_accuracy: 0.9279 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 60/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.9122\n",
            "Epoch 00060: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2879 - accuracy: 0.9122 - val_loss: 0.3031 - val_accuracy: 0.9075 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 61/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.9088\n",
            "Epoch 00061: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2876 - accuracy: 0.9088 - val_loss: 0.2712 - val_accuracy: 0.9151 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 62/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.9160\n",
            "Epoch 00062: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2738 - accuracy: 0.9160 - val_loss: 0.2823 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 63/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2769 - accuracy: 0.9142\n",
            "Epoch 00063: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2769 - accuracy: 0.9142 - val_loss: 0.2705 - val_accuracy: 0.9168 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 64/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2697 - accuracy: 0.9149\n",
            "Epoch 00064: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2697 - accuracy: 0.9149 - val_loss: 0.2848 - val_accuracy: 0.9122 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 65/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.9126\n",
            "Epoch 00065: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2743 - accuracy: 0.9126 - val_loss: 0.2620 - val_accuracy: 0.9174 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 66/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.9136\n",
            "Epoch 00066: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2820 - accuracy: 0.9136 - val_loss: 0.2629 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 67/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2693 - accuracy: 0.9158\n",
            "Epoch 00067: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2693 - accuracy: 0.9158 - val_loss: 0.2969 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 68/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.9209\n",
            "Epoch 00068: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2686 - accuracy: 0.9209 - val_loss: 0.2780 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 69/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2753 - accuracy: 0.9152\n",
            "Epoch 00069: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2753 - accuracy: 0.9152 - val_loss: 0.2759 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 70/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2704 - accuracy: 0.9138\n",
            "Epoch 00070: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2704 - accuracy: 0.9138 - val_loss: 0.3019 - val_accuracy: 0.9122 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 71/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.9192\n",
            "Epoch 00071: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2717 - accuracy: 0.9192 - val_loss: 0.2697 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 72/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.9208\n",
            "Epoch 00072: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2610 - accuracy: 0.9208 - val_loss: 0.3300 - val_accuracy: 0.9139 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 73/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.9183\n",
            "Epoch 00073: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2694 - accuracy: 0.9183 - val_loss: 0.3129 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 74/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.9199\n",
            "Epoch 00074: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2653 - accuracy: 0.9199 - val_loss: 0.3465 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 75/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.9154\n",
            "Epoch 00075: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2726 - accuracy: 0.9154 - val_loss: 0.3949 - val_accuracy: 0.8743 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 76/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.9212\n",
            "Epoch 00076: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2673 - accuracy: 0.9212 - val_loss: 0.3506 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 77/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.9201\n",
            "Epoch 00077: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2619 - accuracy: 0.9201 - val_loss: 0.3135 - val_accuracy: 0.9046 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 78/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2597 - accuracy: 0.9215\n",
            "Epoch 00078: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2597 - accuracy: 0.9215 - val_loss: 0.2585 - val_accuracy: 0.9238 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 79/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.9206\n",
            "Epoch 00079: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2579 - accuracy: 0.9206 - val_loss: 0.2632 - val_accuracy: 0.9232 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 80/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.9201\n",
            "Epoch 00080: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.2623 - accuracy: 0.9201 - val_loss: 0.2727 - val_accuracy: 0.9174 - lr: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3o_6mWLAMHxW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "ee6808c1-e536-412d-bc79-807772818d31"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lZI3PoikMMfQ",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    dropout=0.1\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=2):\n",
        "\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)\n",
        "\n",
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Resnetv2')\n",
        "model_name = 'HM_0.1_0.1_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "avoByxSrMO-0",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}