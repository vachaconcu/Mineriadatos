{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnetv2_0.25.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vachaconcu/Mineriadatos/blob/master/Resnetv2_0_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CTb70R3YZDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from numpy import load\n",
        "os.chdir('/content/drive/My Drive/Mineria/Interna/datos')\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_val_int.npz') ; x_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_train.npz') ; x_train = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_val_int.npz') ; y_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_train.npz') ; y_train = datos['arr_0']\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_val_ext.npz') ; y_test2 = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_val_ext.npz') ; x_test2 = datos['arr_0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7RbMR55bWhS",
        "colab_type": "code",
        "outputId": "33263a0c-2436-461f-a258-44607e120db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('x_test =',x_test.shape)\n",
        "print('x_train =',x_train.shape)\n",
        "print('y_test =',y_test.shape)\n",
        "print('y_train =',y_train.shape)\n",
        "\n",
        "print('y_test_ext=', y_test2.shape)\n",
        "print('x_test_ext=', x_test2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test = (1719, 200, 200, 3)\n",
            "x_train = (6874, 200, 200, 3)\n",
            "y_test = (1719, 2)\n",
            "y_train = (6874, 2)\n",
            "y_test_ext= (2063, 2)\n",
            "x_test_ext= (2063, 200, 200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9DCAJzn05wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoVqIG4mojgL",
        "colab_type": "code",
        "outputId": "9d0381e7-1728-4974-c703-d70708f9fbbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 32 \n",
        "epochs = 80\n",
        "data_augmentation = True\n",
        "num_classes = 2\n",
        "subtract_pixel_mean = True # subtracting pixel mean improves accuracy\n",
        "n = 2\n",
        "version = 2\n",
        "\n",
        "# computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "model_type"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ResNet20v2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kql8upFhpIg_",
        "colab_type": "code",
        "outputId": "46535971-e592-4795-8d3c-c6d52d58f7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# if subtract pixel mean is enabled \n",
        "# center the column-data around zero\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "    X_test2= x_test2\n",
        "    x_test2 -= x_train_mean\n",
        "    \n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (6874, 200, 200, 3)\n",
            "6874 train samples\n",
            "1719 test samples\n",
            "y_train shape: (6874, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j58TCUSpTH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmx8ifYrprJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    dropout=0.5\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Y0J8UMp3TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=2):\n",
        "\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVUkR2XgqCuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T92lYa5JqG1t",
        "colab_type": "code",
        "outputId": "8ac94c86-4b3f-4400-b4fc-c2e6f5f737e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200, 200, 16) 0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 200, 200, 16) 272         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200, 200, 16) 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 200, 200, 16) 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 64) 1088        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 64) 1088        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 200, 200, 64) 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 64) 0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 200, 200, 16) 1040        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 16) 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 200, 200, 16) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 200, 200, 64) 1088        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 200, 200, 64) 0           add[0][0]                        \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 200, 200, 64) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 100, 100, 64) 4160        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 100, 100, 64) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 100, 100, 64) 36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 100, 100, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 100, 100, 64) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 100, 100, 128 8320        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 100, 100, 128 8320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 100, 100, 128 0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 100, 100, 128 512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 100, 100, 128 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 100, 100, 128 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 100, 100, 64) 8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 100, 100, 64) 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 100, 100, 64) 0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 128 8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 100, 100, 128 0           add_2[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 100, 128 512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100, 100, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 100, 100, 128 0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 50, 50, 128)  16512       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 50, 50, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 50, 50, 128)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 50, 50, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 50, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 50, 50, 128)  0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 256)  33024       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 256)  33024       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 50, 50, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 50, 50, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 50, 50, 256)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 50, 50, 128)  32896       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 50, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 50, 50, 128)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 50, 50, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 50, 50, 128)  0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 50, 50, 256)  33024       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 50, 50, 256)  0           add_4[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 50, 50, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 50, 50, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 50, 50, 256)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 6, 6, 256)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            18434       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 589,954\n",
            "Trainable params: 586,466\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCCfDIRF1uOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using last check point\n",
        "#from tensorflow.keras.models import load_model\n",
        "\n",
        "#model = load_model('/content/drive/My Drive/Mineria/Interna/datos/Modelos/mujer_ResNet20v2_model.083.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiZiKwkziQ4s",
        "colab_type": "code",
        "outputId": "9ba65938-d2bc-4750-ef61-352b986e8367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Resnetv2')\n",
        "model_name = 'HM_0.5_0.5_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0346 - accuracy: 0.7014\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.76033, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.001.h5\n",
            "214/214 [==============================] - 127s 595ms/step - loss: 1.0346 - accuracy: 0.7014 - val_loss: 0.8766 - val_accuracy: 0.7603 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8369 - accuracy: 0.7738\n",
            "Epoch 00002: val_accuracy did not improve from 0.76033\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.8369 - accuracy: 0.7738 - val_loss: 0.9144 - val_accuracy: 0.6998 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7961 - accuracy: 0.7667\n",
            "Epoch 00003: val_accuracy improved from 0.76033 to 0.76265, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.003.h5\n",
            "214/214 [==============================] - 124s 579ms/step - loss: 0.7961 - accuracy: 0.7667 - val_loss: 0.7604 - val_accuracy: 0.7627 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.7979\n",
            "Epoch 00004: val_accuracy improved from 0.76265 to 0.81734, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.004.h5\n",
            "214/214 [==============================] - 124s 578ms/step - loss: 0.6994 - accuracy: 0.7979 - val_loss: 0.6372 - val_accuracy: 0.8173 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.7938\n",
            "Epoch 00005: val_accuracy improved from 0.81734 to 0.82548, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.005.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.6569 - accuracy: 0.7938 - val_loss: 0.5943 - val_accuracy: 0.8255 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.8027\n",
            "Epoch 00006: val_accuracy did not improve from 0.82548\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.6158 - accuracy: 0.8027 - val_loss: 0.6647 - val_accuracy: 0.7720 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.8160\n",
            "Epoch 00007: val_accuracy did not improve from 0.82548\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.5856 - accuracy: 0.8160 - val_loss: 0.5780 - val_accuracy: 0.8074 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.8204\n",
            "Epoch 00008: val_accuracy did not improve from 0.82548\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.5579 - accuracy: 0.8204 - val_loss: 0.5958 - val_accuracy: 0.7871 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5340 - accuracy: 0.8240\n",
            "Epoch 00009: val_accuracy improved from 0.82548 to 0.84002, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.009.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.5340 - accuracy: 0.8240 - val_loss: 0.4881 - val_accuracy: 0.8400 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.8213\n",
            "Epoch 00010: val_accuracy improved from 0.84002 to 0.84410, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.010.h5\n",
            "214/214 [==============================] - 124s 578ms/step - loss: 0.5219 - accuracy: 0.8213 - val_loss: 0.4777 - val_accuracy: 0.8441 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.8265\n",
            "Epoch 00011: val_accuracy improved from 0.84410 to 0.84700, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.011.h5\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.5058 - accuracy: 0.8265 - val_loss: 0.4766 - val_accuracy: 0.8470 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4890 - accuracy: 0.8310\n",
            "Epoch 00012: val_accuracy did not improve from 0.84700\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4890 - accuracy: 0.8310 - val_loss: 0.4805 - val_accuracy: 0.8325 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.8297\n",
            "Epoch 00013: val_accuracy improved from 0.84700 to 0.85398, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.013.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.4779 - accuracy: 0.8297 - val_loss: 0.4402 - val_accuracy: 0.8540 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4745 - accuracy: 0.8343\n",
            "Epoch 00014: val_accuracy improved from 0.85398 to 0.85631, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.014.h5\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.4745 - accuracy: 0.8343 - val_loss: 0.4408 - val_accuracy: 0.8563 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.8372\n",
            "Epoch 00015: val_accuracy did not improve from 0.85631\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.4705 - accuracy: 0.8372 - val_loss: 0.4337 - val_accuracy: 0.8551 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4552 - accuracy: 0.8404\n",
            "Epoch 00016: val_accuracy did not improve from 0.85631\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4552 - accuracy: 0.8404 - val_loss: 0.4234 - val_accuracy: 0.8534 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.8419\n",
            "Epoch 00017: val_accuracy did not improve from 0.85631\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.4526 - accuracy: 0.8419 - val_loss: 0.4179 - val_accuracy: 0.8540 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.8423\n",
            "Epoch 00018: val_accuracy did not improve from 0.85631\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.4383 - accuracy: 0.8423 - val_loss: 0.4485 - val_accuracy: 0.8412 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 19/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8486\n",
            "Epoch 00019: val_accuracy did not improve from 0.85631\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4326 - accuracy: 0.8486 - val_loss: 0.4375 - val_accuracy: 0.8487 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.8464\n",
            "Epoch 00020: val_accuracy improved from 0.85631 to 0.87609, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.020.h5\n",
            "214/214 [==============================] - 124s 578ms/step - loss: 0.4289 - accuracy: 0.8464 - val_loss: 0.3810 - val_accuracy: 0.8761 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 21/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4168 - accuracy: 0.8544\n",
            "Epoch 00021: val_accuracy did not improve from 0.87609\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4168 - accuracy: 0.8544 - val_loss: 0.3709 - val_accuracy: 0.8714 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.8511\n",
            "Epoch 00022: val_accuracy did not improve from 0.87609\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.4187 - accuracy: 0.8511 - val_loss: 0.3834 - val_accuracy: 0.8761 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4082 - accuracy: 0.8629\n",
            "Epoch 00023: val_accuracy did not improve from 0.87609\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.4082 - accuracy: 0.8629 - val_loss: 0.3769 - val_accuracy: 0.8732 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.8593\n",
            "Epoch 00024: val_accuracy improved from 0.87609 to 0.87725, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.024.h5\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4061 - accuracy: 0.8593 - val_loss: 0.3709 - val_accuracy: 0.8773 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.8617\n",
            "Epoch 00025: val_accuracy improved from 0.87725 to 0.88424, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.025.h5\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.4029 - accuracy: 0.8617 - val_loss: 0.3706 - val_accuracy: 0.8842 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 26/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3921 - accuracy: 0.8626\n",
            "Epoch 00026: val_accuracy did not improve from 0.88424\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3921 - accuracy: 0.8626 - val_loss: 0.4293 - val_accuracy: 0.8586 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4067 - accuracy: 0.8588\n",
            "Epoch 00027: val_accuracy did not improve from 0.88424\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.4067 - accuracy: 0.8588 - val_loss: 0.3919 - val_accuracy: 0.8714 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 28/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.8619\n",
            "Epoch 00028: val_accuracy did not improve from 0.88424\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.4039 - accuracy: 0.8619 - val_loss: 0.3630 - val_accuracy: 0.8842 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 29/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8584\n",
            "Epoch 00029: val_accuracy did not improve from 0.88424\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3998 - accuracy: 0.8584 - val_loss: 0.3775 - val_accuracy: 0.8819 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3881 - accuracy: 0.8655\n",
            "Epoch 00030: val_accuracy improved from 0.88424 to 0.88947, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.030.h5\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3881 - accuracy: 0.8655 - val_loss: 0.3672 - val_accuracy: 0.8895 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 31/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8766\n",
            "Epoch 00031: val_accuracy improved from 0.88947 to 0.89005, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.031.h5\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3736 - accuracy: 0.8766 - val_loss: 0.3503 - val_accuracy: 0.8901 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 32/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3776 - accuracy: 0.8717\n",
            "Epoch 00032: val_accuracy improved from 0.89005 to 0.89587, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.032.h5\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.3776 - accuracy: 0.8717 - val_loss: 0.3404 - val_accuracy: 0.8959 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 33/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8705\n",
            "Epoch 00033: val_accuracy did not improve from 0.89587\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3792 - accuracy: 0.8705 - val_loss: 0.3479 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 34/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3795 - accuracy: 0.8728\n",
            "Epoch 00034: val_accuracy did not improve from 0.89587\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3795 - accuracy: 0.8728 - val_loss: 0.3763 - val_accuracy: 0.8796 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 35/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.8783\n",
            "Epoch 00035: val_accuracy did not improve from 0.89587\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3703 - accuracy: 0.8783 - val_loss: 0.3612 - val_accuracy: 0.8807 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 36/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8765\n",
            "Epoch 00036: val_accuracy improved from 0.89587 to 0.90285, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.036.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.3743 - accuracy: 0.8765 - val_loss: 0.3283 - val_accuracy: 0.9029 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 37/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.8794\n",
            "Epoch 00037: val_accuracy did not improve from 0.90285\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3634 - accuracy: 0.8794 - val_loss: 0.3600 - val_accuracy: 0.8883 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 38/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3694 - accuracy: 0.8777\n",
            "Epoch 00038: val_accuracy did not improve from 0.90285\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3694 - accuracy: 0.8777 - val_loss: 0.3560 - val_accuracy: 0.8842 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 39/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3576 - accuracy: 0.8804\n",
            "Epoch 00039: val_accuracy did not improve from 0.90285\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.3576 - accuracy: 0.8804 - val_loss: 0.3466 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 40/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3680 - accuracy: 0.8781\n",
            "Epoch 00040: val_accuracy did not improve from 0.90285\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3680 - accuracy: 0.8781 - val_loss: 0.4137 - val_accuracy: 0.8662 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 41/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.8753\n",
            "Epoch 00041: val_accuracy improved from 0.90285 to 0.90692, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.041.h5\n",
            "214/214 [==============================] - 124s 578ms/step - loss: 0.3673 - accuracy: 0.8753 - val_loss: 0.3218 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 42/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3554 - accuracy: 0.8837\n",
            "Epoch 00042: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3554 - accuracy: 0.8837 - val_loss: 0.3511 - val_accuracy: 0.8912 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 43/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.8774\n",
            "Epoch 00043: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3628 - accuracy: 0.8774 - val_loss: 0.3961 - val_accuracy: 0.8761 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 44/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 0.8861\n",
            "Epoch 00044: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.3461 - accuracy: 0.8861 - val_loss: 0.3383 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 45/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8832\n",
            "Epoch 00045: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3496 - accuracy: 0.8832 - val_loss: 0.3509 - val_accuracy: 0.8912 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 46/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.8872\n",
            "Epoch 00046: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 574ms/step - loss: 0.3425 - accuracy: 0.8872 - val_loss: 0.3405 - val_accuracy: 0.9011 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 47/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8863\n",
            "Epoch 00047: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3511 - accuracy: 0.8863 - val_loss: 0.3662 - val_accuracy: 0.8743 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 48/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8866\n",
            "Epoch 00048: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 574ms/step - loss: 0.3429 - accuracy: 0.8866 - val_loss: 0.3204 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 49/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8932\n",
            "Epoch 00049: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 574ms/step - loss: 0.3415 - accuracy: 0.8932 - val_loss: 0.4413 - val_accuracy: 0.8546 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 50/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.8886\n",
            "Epoch 00050: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3460 - accuracy: 0.8886 - val_loss: 0.3540 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 51/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8857\n",
            "Epoch 00051: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3494 - accuracy: 0.8857 - val_loss: 0.3908 - val_accuracy: 0.8755 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 52/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8994\n",
            "Epoch 00052: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3281 - accuracy: 0.8994 - val_loss: 0.4443 - val_accuracy: 0.8592 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 53/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3412 - accuracy: 0.8936\n",
            "Epoch 00053: val_accuracy improved from 0.90692 to 0.90809, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.053.h5\n",
            "214/214 [==============================] - 123s 577ms/step - loss: 0.3412 - accuracy: 0.8936 - val_loss: 0.3160 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 54/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8933\n",
            "Epoch 00054: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3345 - accuracy: 0.8933 - val_loss: 0.3762 - val_accuracy: 0.8883 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 55/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8970\n",
            "Epoch 00055: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3309 - accuracy: 0.8970 - val_loss: 0.3315 - val_accuracy: 0.9029 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 56/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.8918\n",
            "Epoch 00056: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3381 - accuracy: 0.8918 - val_loss: 0.3422 - val_accuracy: 0.9017 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 57/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.8973\n",
            "Epoch 00057: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3300 - accuracy: 0.8973 - val_loss: 0.3293 - val_accuracy: 0.9052 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 58/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.8961\n",
            "Epoch 00058: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3290 - accuracy: 0.8961 - val_loss: 0.3497 - val_accuracy: 0.8994 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 59/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.8999\n",
            "Epoch 00059: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 123s 574ms/step - loss: 0.3265 - accuracy: 0.8999 - val_loss: 0.3165 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 60/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.8981\n",
            "Epoch 00060: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 124s 578ms/step - loss: 0.3273 - accuracy: 0.8981 - val_loss: 0.3557 - val_accuracy: 0.8959 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 61/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3216 - accuracy: 0.9008\n",
            "Epoch 00061: val_accuracy improved from 0.90809 to 0.91041, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.061.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.3216 - accuracy: 0.9008 - val_loss: 0.3330 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 62/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8974\n",
            "Epoch 00062: val_accuracy did not improve from 0.91041\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3311 - accuracy: 0.8974 - val_loss: 0.3408 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 63/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.9022\n",
            "Epoch 00063: val_accuracy improved from 0.91041 to 0.91332, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.063.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.3226 - accuracy: 0.9022 - val_loss: 0.3146 - val_accuracy: 0.9133 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 64/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.8983\n",
            "Epoch 00064: val_accuracy did not improve from 0.91332\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3304 - accuracy: 0.8983 - val_loss: 0.3473 - val_accuracy: 0.9017 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 65/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.8942\n",
            "Epoch 00065: val_accuracy improved from 0.91332 to 0.91507, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.5_0.5_ResNet20v2_model.065.h5\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.3305 - accuracy: 0.8942 - val_loss: 0.3137 - val_accuracy: 0.9151 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 66/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.9011\n",
            "Epoch 00066: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3239 - accuracy: 0.9011 - val_loss: 0.3413 - val_accuracy: 0.9023 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 67/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.9024\n",
            "Epoch 00067: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 124s 577ms/step - loss: 0.3222 - accuracy: 0.9024 - val_loss: 0.3053 - val_accuracy: 0.9151 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 68/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.9009\n",
            "Epoch 00068: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 573ms/step - loss: 0.3204 - accuracy: 0.9009 - val_loss: 0.3444 - val_accuracy: 0.8999 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 69/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.9087\n",
            "Epoch 00069: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3146 - accuracy: 0.9087 - val_loss: 0.3679 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 70/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.9037\n",
            "Epoch 00070: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3170 - accuracy: 0.9037 - val_loss: 0.3133 - val_accuracy: 0.9092 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 71/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.9030\n",
            "Epoch 00071: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3168 - accuracy: 0.9030 - val_loss: 0.3222 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 72/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.9044\n",
            "Epoch 00072: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3174 - accuracy: 0.9044 - val_loss: 0.3780 - val_accuracy: 0.8912 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 73/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.9031\n",
            "Epoch 00073: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3231 - accuracy: 0.9031 - val_loss: 0.3119 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 74/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3199 - accuracy: 0.9025\n",
            "Epoch 00074: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3199 - accuracy: 0.9025 - val_loss: 0.3562 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 75/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9091\n",
            "Epoch 00075: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3092 - accuracy: 0.9091 - val_loss: 0.3232 - val_accuracy: 0.9122 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 76/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.9049\n",
            "Epoch 00076: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3147 - accuracy: 0.9049 - val_loss: 0.3490 - val_accuracy: 0.8982 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 77/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.9057\n",
            "Epoch 00077: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3173 - accuracy: 0.9057 - val_loss: 0.3372 - val_accuracy: 0.9011 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 78/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3291 - accuracy: 0.9002\n",
            "Epoch 00078: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3291 - accuracy: 0.9002 - val_loss: 0.3433 - val_accuracy: 0.8959 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 79/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.9089\n",
            "Epoch 00079: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 576ms/step - loss: 0.3084 - accuracy: 0.9089 - val_loss: 0.3522 - val_accuracy: 0.9011 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 80/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.9085\n",
            "Epoch 00080: val_accuracy did not improve from 0.91507\n",
            "214/214 [==============================] - 123s 575ms/step - loss: 0.3087 - accuracy: 0.9085 - val_loss: 0.3276 - val_accuracy: 0.9098 - lr: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezaiJkW-irF6",
        "colab_type": "code",
        "outputId": "199a4fc4-85c9-46a3-b5d7-c6065a7c9659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b8zeH3hLdZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    dropout=0.6\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=2):\n",
        "\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)\n",
        "\n",
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Resnetv2')\n",
        "model_name = 'HM_0.25_0.25_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYGE4N1MLeRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hDwTgshEMEKF",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    dropout=0.3\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=2):\n",
        "\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)\n",
        "\n",
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Resnetv2')\n",
        "model_name = 'HM_0.3_0.3_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3o_6mWLAMHxW",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lZI3PoikMMfQ",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    dropout=0.1\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=2):\n",
        "\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)\n",
        "\n",
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Resnetv2')\n",
        "model_name = 'HM_0.1_0.1_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "avoByxSrMO-0",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}