{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet Versión 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTxMkZCVWgLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce1410b7-4d1e-4722-a12c-8d3c09a101ad"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "from skimage import data\n",
        "from os import remove\n",
        "from skimage.color import rgb2gray\n",
        "from numpy import load\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape,ZeroPadding2D,Activation,MaxPooling2D,Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import SpatialDropout2D\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CTb70R3YZDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Minería de Datos/Interna/datos')\n",
        "\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/X_R_val_int.npz') ; x_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/X_R_train.npz') ; x_train = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/y_R_val_int.npz') ; y_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/y_R_train.npz') ; y_train = datos['arr_0']\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_R_val_ext.npz') ; y_test2 = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_R_val_ext.npz') ; x_test2 = datos['arr_0']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7RbMR55bWhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cbe52440-5afc-4527-b967-f4fbe7911af9"
      },
      "source": [
        "print('x_test =',x_test.shape)\n",
        "print('x_train =',x_train.shape)\n",
        "print('y_test =',y_test.shape)\n",
        "print('y_train =',y_train.shape)\n",
        "\n",
        "print('y_test_ext=', y_test2.shape)\n",
        "print('x_test_ext=', x_test2.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test = (1719, 200, 200, 3)\n",
            "x_train = (6874, 200, 200, 3)\n",
            "y_test = (1719, 5)\n",
            "y_train = (6874, 5)\n",
            "y_test_ext= (2063, 5)\n",
            "x_test_ext= (2063, 200, 200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXtMPu12ogD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoVqIG4mojgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6bf313a-bf58-485a-e6f4-6f20a7a94868"
      },
      "source": [
        "batch_size = 32 # orig paper trained all networks with batch_size=128\n",
        "epochs = 30\n",
        "\n",
        "data_augmentation = True\n",
        "num_classes = 5\n",
        "# subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter para sexo c: \n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 2\n",
        "\n",
        "# model version\n",
        "# orig paper: version = 1 (ResNet v1), \n",
        "# improved ResNet: version = 2 (ResNet v2)\n",
        "version = 2\n",
        "\n",
        "# computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "model_type"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ResNet20v2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kql8upFhpIg_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "96cf4e15-b26b-41be-cdbc-9242ee7651ef"
      },
      "source": [
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "#x_train = x_train.astype('float32') \n",
        "#x_test = x_test.astype('float32') \n",
        "\n",
        "# if subtract pixel mean is enabled \n",
        "# center the column-data around zero\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (6874, 200, 200, 3)\n",
            "6874 train samples\n",
            "1719 test samples\n",
            "y_train shape: (6874, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j58TCUSpTH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmx8ifYrprJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 dropout=0.2,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    Arguments:\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    Returns:\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Y0J8UMp3TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=5, dropout=0.2):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or \n",
        "    also known as bottleneck layer.\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, \n",
        "    the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, \n",
        "    while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have \n",
        "    the same number filters and the same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    Arguments:\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    Returns:\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVUkR2XgqCuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T92lYa5JqG1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "efbfd1cf-1344-494c-8c2b-11ca64259b09"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200, 200, 16) 0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 200, 200, 16) 272         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200, 200, 16) 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 200, 200, 16) 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 64) 1088        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 64) 1088        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 200, 200, 64) 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 64) 0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 200, 200, 16) 1040        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 16) 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 200, 200, 16) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 200, 200, 64) 1088        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 200, 200, 64) 0           add[0][0]                        \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 200, 200, 64) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 100, 100, 64) 4160        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 100, 100, 64) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 100, 100, 64) 36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 100, 100, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 100, 100, 64) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 100, 100, 128 8320        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 100, 100, 128 8320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 100, 100, 128 0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 100, 100, 128 512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 100, 100, 128 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 100, 100, 128 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 100, 100, 64) 8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 100, 100, 64) 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 100, 100, 64) 0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 128 8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 100, 100, 128 0           add_2[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 100, 128 512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100, 100, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 100, 100, 128 0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 50, 50, 128)  16512       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 50, 50, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 50, 50, 128)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 50, 50, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 50, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 50, 50, 128)  0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 256)  33024       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 256)  33024       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 50, 50, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 50, 50, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 50, 50, 256)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 50, 50, 128)  32896       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 50, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 50, 50, 128)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 50, 50, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 50, 50, 128)  0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 50, 50, 256)  33024       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 50, 50, 256)  0           add_4[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 50, 50, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 50, 50, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 50, 50, 256)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 6, 6, 256)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 5)            46085       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 617,605\n",
            "Trainable params: 614,117\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCCfDIRF1uOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using last check point\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/Minería de Datos/Interna/datos/Modelos/Raza_Primera_ResNet20v2_model.074.h5')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiZiKwkziQ4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3de78520-8421-4056-9f5a-3b782c788df6"
      },
      "source": [
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Modelos')\n",
        "model_name = 'Raza_Segunda_0.2_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7121 - accuracy: 0.7764\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.79290, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Segunda_0.2_ResNet20v2_model.001.h5\n",
            "214/214 [==============================] - 233s 1s/step - loss: 0.7121 - accuracy: 0.7764 - val_loss: 0.7475 - val_accuracy: 0.7929 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7135 - accuracy: 0.7777\n",
            "Epoch 00002: val_accuracy improved from 0.79290 to 0.79697, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Segunda_0.2_ResNet20v2_model.002.h5\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.7135 - accuracy: 0.7777 - val_loss: 0.7295 - val_accuracy: 0.7970 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7058 - accuracy: 0.7799\n",
            "Epoch 00003: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.7058 - accuracy: 0.7799 - val_loss: 0.9740 - val_accuracy: 0.7051 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7039 - accuracy: 0.7748\n",
            "Epoch 00004: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.7039 - accuracy: 0.7748 - val_loss: 0.7522 - val_accuracy: 0.7749 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6986 - accuracy: 0.7824\n",
            "Epoch 00005: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.6986 - accuracy: 0.7824 - val_loss: 0.7401 - val_accuracy: 0.7842 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6865 - accuracy: 0.7882\n",
            "Epoch 00006: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.6865 - accuracy: 0.7882 - val_loss: 0.8058 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.7887\n",
            "Epoch 00007: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.6956 - accuracy: 0.7887 - val_loss: 0.7710 - val_accuracy: 0.7824 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 8/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7033 - accuracy: 0.7799\n",
            "Epoch 00008: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.7033 - accuracy: 0.7799 - val_loss: 0.7791 - val_accuracy: 0.7760 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.7860\n",
            "Epoch 00009: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6950 - accuracy: 0.7860 - val_loss: 0.7656 - val_accuracy: 0.7853 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.7920\n",
            "Epoch 00010: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6764 - accuracy: 0.7920 - val_loss: 0.7353 - val_accuracy: 0.7900 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6817 - accuracy: 0.7898\n",
            "Epoch 00011: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6817 - accuracy: 0.7898 - val_loss: 0.7592 - val_accuracy: 0.7842 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.7913\n",
            "Epoch 00012: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6772 - accuracy: 0.7913 - val_loss: 0.7447 - val_accuracy: 0.7865 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 13/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6829 - accuracy: 0.7875\n",
            "Epoch 00013: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.6829 - accuracy: 0.7875 - val_loss: 0.8075 - val_accuracy: 0.7545 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.7911\n",
            "Epoch 00014: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6758 - accuracy: 0.7911 - val_loss: 0.7857 - val_accuracy: 0.7778 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6779 - accuracy: 0.7911\n",
            "Epoch 00015: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6779 - accuracy: 0.7911 - val_loss: 0.8160 - val_accuracy: 0.7632 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6805 - accuracy: 0.7903\n",
            "Epoch 00016: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6805 - accuracy: 0.7903 - val_loss: 0.7577 - val_accuracy: 0.7708 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6626 - accuracy: 0.7987\n",
            "Epoch 00017: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6626 - accuracy: 0.7987 - val_loss: 0.7999 - val_accuracy: 0.7696 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 18/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.7957\n",
            "Epoch 00018: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.6705 - accuracy: 0.7957 - val_loss: 0.7281 - val_accuracy: 0.7894 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 19/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6601 - accuracy: 0.8024\n",
            "Epoch 00019: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.6601 - accuracy: 0.8024 - val_loss: 0.7322 - val_accuracy: 0.7970 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6600 - accuracy: 0.7957\n",
            "Epoch 00020: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6600 - accuracy: 0.7957 - val_loss: 0.7277 - val_accuracy: 0.7964 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 21/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.7996\n",
            "Epoch 00021: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6553 - accuracy: 0.7996 - val_loss: 0.7752 - val_accuracy: 0.7813 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.8006\n",
            "Epoch 00022: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 230s 1s/step - loss: 0.6603 - accuracy: 0.8006 - val_loss: 0.7782 - val_accuracy: 0.7760 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6540 - accuracy: 0.7954\n",
            "Epoch 00023: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 230s 1s/step - loss: 0.6540 - accuracy: 0.7954 - val_loss: 0.7621 - val_accuracy: 0.7888 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6458 - accuracy: 0.7999\n",
            "Epoch 00024: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 227s 1s/step - loss: 0.6458 - accuracy: 0.7999 - val_loss: 0.7437 - val_accuracy: 0.7952 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.8008\n",
            "Epoch 00025: val_accuracy did not improve from 0.79697\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.6623 - accuracy: 0.8008 - val_loss: 0.7496 - val_accuracy: 0.7935 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 26/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6487 - accuracy: 0.8009\n",
            "Epoch 00026: val_accuracy improved from 0.79697 to 0.80628, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Segunda_0.2_ResNet20v2_model.026.h5\n",
            "214/214 [==============================] - 228s 1s/step - loss: 0.6487 - accuracy: 0.8009 - val_loss: 0.7102 - val_accuracy: 0.8063 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6424 - accuracy: 0.8014\n",
            "Epoch 00027: val_accuracy did not improve from 0.80628\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6424 - accuracy: 0.8014 - val_loss: 0.7276 - val_accuracy: 0.7935 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 28/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.7992\n",
            "Epoch 00028: val_accuracy did not improve from 0.80628\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6482 - accuracy: 0.7992 - val_loss: 0.7119 - val_accuracy: 0.7958 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 29/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6535 - accuracy: 0.8024\n",
            "Epoch 00029: val_accuracy did not improve from 0.80628\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6535 - accuracy: 0.8024 - val_loss: 0.7396 - val_accuracy: 0.7912 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/30\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.8063\n",
            "Epoch 00030: val_accuracy did not improve from 0.80628\n",
            "214/214 [==============================] - 229s 1s/step - loss: 0.6463 - accuracy: 0.8063 - val_loss: 0.7498 - val_accuracy: 0.7853 - lr: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezaiJkW-irF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "56005a8e-3e2b-4b2c-987d-a8fde8b0f841"
      },
      "source": [
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylim(0.45,0.85)\n",
        "plt.xlim(0,30)\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylim(0.55,1.85)\n",
        "plt.xlim(0,30)\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}