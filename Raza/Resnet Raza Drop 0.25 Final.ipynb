{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet Versión 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTxMkZCVWgLd",
        "colab_type": "code",
        "outputId": "cc6449a2-6f84-4b7a-b9b5-82168824164e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "from skimage import data\n",
        "from os import remove\n",
        "from skimage.color import rgb2gray\n",
        "from numpy import load\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape,ZeroPadding2D,Activation,MaxPooling2D,Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import SpatialDropout2D\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CTb70R3YZDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Minería de Datos/Interna/datos')\n",
        "\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/X_R_val_int.npz') ; x_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/X_R_train.npz') ; x_train = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/y_R_val_int.npz') ; y_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/y_R_train.npz') ; y_train = datos['arr_0']\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_R_val_ext.npz') ; y_test2 = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_R_val_ext.npz') ; x_test2 = datos['arr_0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7RbMR55bWhS",
        "colab_type": "code",
        "outputId": "ef89db4c-25fa-4a7b-e6e5-299a5934e670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('x_test =',x_test.shape)\n",
        "print('x_train =',x_train.shape)\n",
        "print('y_test =',y_test.shape)\n",
        "print('y_train =',y_train.shape)\n",
        "\n",
        "print('y_test_ext=', y_test2.shape)\n",
        "print('x_test_ext=', x_test2.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test = (1719, 200, 200, 3)\n",
            "x_train = (6874, 200, 200, 3)\n",
            "y_test = (1719, 5)\n",
            "y_train = (6874, 5)\n",
            "y_test_ext= (2063, 5)\n",
            "x_test_ext= (2063, 200, 200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXtMPu12ogD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoVqIG4mojgL",
        "colab_type": "code",
        "outputId": "fbfaaf33-1869-4429-f66e-63a3e206f176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 32 # orig paper trained all networks with batch_size=128\n",
        "epochs = 85\n",
        "\n",
        "data_augmentation = True\n",
        "num_classes = 5\n",
        "# subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter para sexo c: \n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 2\n",
        "\n",
        "# model version\n",
        "# orig paper: version = 1 (ResNet v1), \n",
        "# improved ResNet: version = 2 (ResNet v2)\n",
        "version = 2\n",
        "\n",
        "# computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "model_type"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ResNet20v2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kql8upFhpIg_",
        "colab_type": "code",
        "outputId": "4d09aa62-3fd7-4dcd-e7ab-c1958362d7d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "#x_train = x_train.astype('float32') \n",
        "#x_test = x_test.astype('float32') \n",
        "\n",
        "# if subtract pixel mean is enabled \n",
        "# center the column-data around zero\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (6874, 200, 200, 3)\n",
            "6874 train samples\n",
            "1719 test samples\n",
            "y_train shape: (6874, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j58TCUSpTH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmx8ifYrprJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 dropout=0.25,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    Arguments:\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    Returns:\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Y0J8UMp3TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=5, dropout=0.25):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or \n",
        "    also known as bottleneck layer.\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, \n",
        "    the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, \n",
        "    while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have \n",
        "    the same number filters and the same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    Arguments:\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    Returns:\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVUkR2XgqCuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T92lYa5JqG1t",
        "colab_type": "code",
        "outputId": "22092aaa-a049-41c3-c464-c9169bc6d2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200, 200, 16) 0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 200, 200, 16) 272         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200, 200, 16) 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 200, 200, 16) 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 64) 1088        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 64) 1088        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 200, 200, 64) 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 64) 0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 200, 200, 16) 1040        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 16) 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 200, 200, 16) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 200, 200, 64) 1088        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 200, 200, 64) 0           add[0][0]                        \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 200, 200, 64) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 100, 100, 64) 4160        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 100, 100, 64) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 100, 100, 64) 36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 100, 100, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 100, 100, 64) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 100, 100, 128 8320        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 100, 100, 128 8320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 100, 100, 128 0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 100, 100, 128 512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 100, 100, 128 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 100, 100, 128 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 100, 100, 64) 8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 100, 100, 64) 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 100, 100, 64) 0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 128 8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 100, 100, 128 0           add_2[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 100, 128 512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100, 100, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 100, 100, 128 0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 50, 50, 128)  16512       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 50, 50, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 50, 50, 128)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 50, 50, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 50, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 50, 50, 128)  0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 256)  33024       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 256)  33024       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 50, 50, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 50, 50, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 50, 50, 256)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 50, 50, 128)  32896       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 50, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 50, 50, 128)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 50, 50, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 50, 50, 128)  0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 50, 50, 256)  33024       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 50, 50, 256)  0           add_4[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 50, 50, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 50, 50, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 50, 50, 256)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 6, 6, 256)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 5)            46085       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 617,605\n",
            "Trainable params: 614,117\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCCfDIRF1uOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using last check point\n",
        "#from tensorflow.keras.models import load_model\n",
        "\n",
        "#model = load_model('/content/drive/My Drive/Minería de Datos/Interna/datos/Modelos/mujer_ResNet20v2_model.083.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiZiKwkziQ4s",
        "colab_type": "code",
        "outputId": "459a032e-6cee-4091-8358-f2732d5be1fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Modelos')\n",
        "model_name = 'Raza_Primera_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.8337 - accuracy: 0.4712\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.53694, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.001.h5\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 1.8337 - accuracy: 0.4712 - val_loss: 1.6324 - val_accuracy: 0.5369 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.5534 - accuracy: 0.5468\n",
            "Epoch 00002: val_accuracy improved from 0.53694 to 0.60035, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.002.h5\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 1.5534 - accuracy: 0.5468 - val_loss: 1.4486 - val_accuracy: 0.6003 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.4523 - accuracy: 0.5728\n",
            "Epoch 00003: val_accuracy improved from 0.60035 to 0.64980, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.003.h5\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.4523 - accuracy: 0.5728 - val_loss: 1.2320 - val_accuracy: 0.6498 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.3669 - accuracy: 0.5802\n",
            "Epoch 00004: val_accuracy improved from 0.64980 to 0.65038, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.004.h5\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.3669 - accuracy: 0.5802 - val_loss: 1.2068 - val_accuracy: 0.6504 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.3104 - accuracy: 0.5950\n",
            "Epoch 00005: val_accuracy improved from 0.65038 to 0.67307, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.005.h5\n",
            "214/214 [==============================] - 80s 372ms/step - loss: 1.3104 - accuracy: 0.5950 - val_loss: 1.1249 - val_accuracy: 0.6731 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.2703 - accuracy: 0.5987\n",
            "Epoch 00006: val_accuracy did not improve from 0.67307\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 1.2703 - accuracy: 0.5987 - val_loss: 1.1327 - val_accuracy: 0.6655 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.2324 - accuracy: 0.6068\n",
            "Epoch 00007: val_accuracy improved from 0.67307 to 0.68296, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.007.h5\n",
            "214/214 [==============================] - 81s 378ms/step - loss: 1.2324 - accuracy: 0.6068 - val_loss: 1.0855 - val_accuracy: 0.6830 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1987 - accuracy: 0.6114\n",
            "Epoch 00008: val_accuracy did not improve from 0.68296\n",
            "214/214 [==============================] - 81s 376ms/step - loss: 1.1987 - accuracy: 0.6114 - val_loss: 1.0842 - val_accuracy: 0.6638 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1755 - accuracy: 0.6191\n",
            "Epoch 00009: val_accuracy did not improve from 0.68296\n",
            "214/214 [==============================] - 81s 378ms/step - loss: 1.1755 - accuracy: 0.6191 - val_loss: 1.0424 - val_accuracy: 0.6760 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1613 - accuracy: 0.6146\n",
            "Epoch 00010: val_accuracy did not improve from 0.68296\n",
            "214/214 [==============================] - 81s 376ms/step - loss: 1.1613 - accuracy: 0.6146 - val_loss: 0.9913 - val_accuracy: 0.6725 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1405 - accuracy: 0.6158\n",
            "Epoch 00011: val_accuracy improved from 0.68296 to 0.68354, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.011.h5\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 1.1405 - accuracy: 0.6158 - val_loss: 0.9888 - val_accuracy: 0.6835 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1178 - accuracy: 0.6270\n",
            "Epoch 00012: val_accuracy improved from 0.68354 to 0.70681, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.012.h5\n",
            "214/214 [==============================] - 82s 381ms/step - loss: 1.1178 - accuracy: 0.6270 - val_loss: 0.9907 - val_accuracy: 0.7068 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1142 - accuracy: 0.6228\n",
            "Epoch 00013: val_accuracy did not improve from 0.70681\n",
            "214/214 [==============================] - 81s 377ms/step - loss: 1.1142 - accuracy: 0.6228 - val_loss: 0.9382 - val_accuracy: 0.6963 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0944 - accuracy: 0.6342\n",
            "Epoch 00014: val_accuracy improved from 0.70681 to 0.71611, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.014.h5\n",
            "214/214 [==============================] - 81s 378ms/step - loss: 1.0944 - accuracy: 0.6342 - val_loss: 0.9219 - val_accuracy: 0.7161 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0697 - accuracy: 0.6441\n",
            "Epoch 00015: val_accuracy did not improve from 0.71611\n",
            "214/214 [==============================] - 81s 377ms/step - loss: 1.0697 - accuracy: 0.6441 - val_loss: 0.9143 - val_accuracy: 0.6987 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0650 - accuracy: 0.6429\n",
            "Epoch 00016: val_accuracy did not improve from 0.71611\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 1.0650 - accuracy: 0.6429 - val_loss: 1.0198 - val_accuracy: 0.6690 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0471 - accuracy: 0.6463\n",
            "Epoch 00017: val_accuracy did not improve from 0.71611\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 1.0471 - accuracy: 0.6463 - val_loss: 0.9567 - val_accuracy: 0.6789 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0539 - accuracy: 0.6429\n",
            "Epoch 00018: val_accuracy did not improve from 0.71611\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 1.0539 - accuracy: 0.6429 - val_loss: 0.9228 - val_accuracy: 0.6958 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 19/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0295 - accuracy: 0.6505\n",
            "Epoch 00019: val_accuracy did not improve from 0.71611\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 1.0295 - accuracy: 0.6505 - val_loss: 1.0017 - val_accuracy: 0.6789 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0325 - accuracy: 0.6492\n",
            "Epoch 00020: val_accuracy did not improve from 0.71611\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 1.0325 - accuracy: 0.6492 - val_loss: 0.9238 - val_accuracy: 0.6946 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 21/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0208 - accuracy: 0.6578\n",
            "Epoch 00021: val_accuracy did not improve from 0.71611\n",
            "214/214 [==============================] - 82s 382ms/step - loss: 1.0208 - accuracy: 0.6578 - val_loss: 0.8812 - val_accuracy: 0.7027 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.6615\n",
            "Epoch 00022: val_accuracy improved from 0.71611 to 0.72077, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.022.h5\n",
            "214/214 [==============================] - 82s 384ms/step - loss: 1.0049 - accuracy: 0.6615 - val_loss: 0.8734 - val_accuracy: 0.7208 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9878 - accuracy: 0.6684\n",
            "Epoch 00023: val_accuracy improved from 0.72077 to 0.72309, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.023.h5\n",
            "214/214 [==============================] - 82s 384ms/step - loss: 0.9878 - accuracy: 0.6684 - val_loss: 0.8506 - val_accuracy: 0.7231 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9870 - accuracy: 0.6637\n",
            "Epoch 00024: val_accuracy did not improve from 0.72309\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 0.9870 - accuracy: 0.6637 - val_loss: 0.8765 - val_accuracy: 0.7184 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9829 - accuracy: 0.6660\n",
            "Epoch 00025: val_accuracy did not improve from 0.72309\n",
            "214/214 [==============================] - 80s 374ms/step - loss: 0.9829 - accuracy: 0.6660 - val_loss: 0.9136 - val_accuracy: 0.7027 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 26/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9715 - accuracy: 0.6808\n",
            "Epoch 00026: val_accuracy did not improve from 0.72309\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 0.9715 - accuracy: 0.6808 - val_loss: 0.9232 - val_accuracy: 0.6975 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9505 - accuracy: 0.6827\n",
            "Epoch 00027: val_accuracy improved from 0.72309 to 0.74753, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.027.h5\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 0.9505 - accuracy: 0.6827 - val_loss: 0.8444 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 28/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9456 - accuracy: 0.6818\n",
            "Epoch 00028: val_accuracy did not improve from 0.74753\n",
            "214/214 [==============================] - 80s 374ms/step - loss: 0.9456 - accuracy: 0.6818 - val_loss: 1.0373 - val_accuracy: 0.6620 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 29/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9416 - accuracy: 0.6901\n",
            "Epoch 00029: val_accuracy did not improve from 0.74753\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 0.9416 - accuracy: 0.6901 - val_loss: 0.8373 - val_accuracy: 0.7347 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9215 - accuracy: 0.7001\n",
            "Epoch 00030: val_accuracy did not improve from 0.74753\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 0.9215 - accuracy: 0.7001 - val_loss: 0.9020 - val_accuracy: 0.7016 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 31/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9163 - accuracy: 0.6976\n",
            "Epoch 00031: val_accuracy improved from 0.74753 to 0.75334, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.031.h5\n",
            "214/214 [==============================] - 81s 377ms/step - loss: 0.9163 - accuracy: 0.6976 - val_loss: 0.8084 - val_accuracy: 0.7533 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 32/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9069 - accuracy: 0.7024\n",
            "Epoch 00032: val_accuracy did not improve from 0.75334\n",
            "214/214 [==============================] - 80s 376ms/step - loss: 0.9069 - accuracy: 0.7024 - val_loss: 0.8353 - val_accuracy: 0.7394 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 33/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9056 - accuracy: 0.6995\n",
            "Epoch 00033: val_accuracy did not improve from 0.75334\n",
            "214/214 [==============================] - 80s 376ms/step - loss: 0.9056 - accuracy: 0.6995 - val_loss: 1.1747 - val_accuracy: 0.6428 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 34/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8857 - accuracy: 0.7143\n",
            "Epoch 00034: val_accuracy did not improve from 0.75334\n",
            "214/214 [==============================] - 81s 376ms/step - loss: 0.8857 - accuracy: 0.7143 - val_loss: 0.9828 - val_accuracy: 0.6894 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 35/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8876 - accuracy: 0.7156\n",
            "Epoch 00035: val_accuracy improved from 0.75334 to 0.75567, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.035.h5\n",
            "214/214 [==============================] - 81s 377ms/step - loss: 0.8876 - accuracy: 0.7156 - val_loss: 0.7930 - val_accuracy: 0.7557 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 36/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.7110\n",
            "Epoch 00036: val_accuracy did not improve from 0.75567\n",
            "214/214 [==============================] - 81s 377ms/step - loss: 0.8737 - accuracy: 0.7110 - val_loss: 0.8215 - val_accuracy: 0.7469 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 37/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8741 - accuracy: 0.7090\n",
            "Epoch 00037: val_accuracy improved from 0.75567 to 0.76905, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.037.h5\n",
            "214/214 [==============================] - 81s 378ms/step - loss: 0.8741 - accuracy: 0.7090 - val_loss: 0.7578 - val_accuracy: 0.7691 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 38/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8538 - accuracy: 0.7226\n",
            "Epoch 00038: val_accuracy did not improve from 0.76905\n",
            "214/214 [==============================] - 81s 377ms/step - loss: 0.8538 - accuracy: 0.7226 - val_loss: 0.8270 - val_accuracy: 0.7458 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 39/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8606 - accuracy: 0.7189\n",
            "Epoch 00039: val_accuracy did not improve from 0.76905\n",
            "214/214 [==============================] - 81s 377ms/step - loss: 0.8606 - accuracy: 0.7189 - val_loss: 0.8528 - val_accuracy: 0.7341 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 40/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8420 - accuracy: 0.7264\n",
            "Epoch 00040: val_accuracy improved from 0.76905 to 0.77371, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.040.h5\n",
            "214/214 [==============================] - 80s 376ms/step - loss: 0.8420 - accuracy: 0.7264 - val_loss: 0.7605 - val_accuracy: 0.7737 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 41/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8356 - accuracy: 0.7268\n",
            "Epoch 00041: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 81s 376ms/step - loss: 0.8356 - accuracy: 0.7268 - val_loss: 0.8458 - val_accuracy: 0.7341 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 42/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8402 - accuracy: 0.7292\n",
            "Epoch 00042: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 81s 376ms/step - loss: 0.8402 - accuracy: 0.7292 - val_loss: 0.8074 - val_accuracy: 0.7481 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 43/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8273 - accuracy: 0.7331\n",
            "Epoch 00043: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.8273 - accuracy: 0.7331 - val_loss: 0.7776 - val_accuracy: 0.7673 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 44/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8314 - accuracy: 0.7302\n",
            "Epoch 00044: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.8314 - accuracy: 0.7302 - val_loss: 0.7563 - val_accuracy: 0.7656 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 45/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8209 - accuracy: 0.7359\n",
            "Epoch 00045: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 0.8209 - accuracy: 0.7359 - val_loss: 0.8105 - val_accuracy: 0.7539 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 46/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8204 - accuracy: 0.7343\n",
            "Epoch 00046: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 0.8204 - accuracy: 0.7343 - val_loss: 0.8884 - val_accuracy: 0.7091 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 47/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8157 - accuracy: 0.7296\n",
            "Epoch 00047: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 0.8157 - accuracy: 0.7296 - val_loss: 0.7932 - val_accuracy: 0.7574 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 48/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7939 - accuracy: 0.7488\n",
            "Epoch 00048: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.7939 - accuracy: 0.7488 - val_loss: 0.7649 - val_accuracy: 0.7673 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 49/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7972 - accuracy: 0.7414\n",
            "Epoch 00049: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 0.7972 - accuracy: 0.7414 - val_loss: 0.8554 - val_accuracy: 0.7400 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 50/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7974 - accuracy: 0.7375\n",
            "Epoch 00050: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 0.7974 - accuracy: 0.7375 - val_loss: 0.8147 - val_accuracy: 0.7458 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 51/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7875 - accuracy: 0.7444\n",
            "Epoch 00051: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.7875 - accuracy: 0.7444 - val_loss: 0.7860 - val_accuracy: 0.7522 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 52/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7909 - accuracy: 0.7431\n",
            "Epoch 00052: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.7909 - accuracy: 0.7431 - val_loss: 0.8781 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 53/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7875 - accuracy: 0.7388\n",
            "Epoch 00053: val_accuracy did not improve from 0.77371\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.7875 - accuracy: 0.7388 - val_loss: 0.8618 - val_accuracy: 0.7411 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 54/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7835 - accuracy: 0.7495\n",
            "Epoch 00054: val_accuracy improved from 0.77371 to 0.78301, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.054.h5\n",
            "214/214 [==============================] - 79s 367ms/step - loss: 0.7835 - accuracy: 0.7495 - val_loss: 0.7465 - val_accuracy: 0.7830 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 55/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7748 - accuracy: 0.7546\n",
            "Epoch 00055: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 0.7748 - accuracy: 0.7546 - val_loss: 0.7868 - val_accuracy: 0.7656 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 56/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7702 - accuracy: 0.7549\n",
            "Epoch 00056: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.7702 - accuracy: 0.7549 - val_loss: 0.7540 - val_accuracy: 0.7702 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 57/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7549\n",
            "Epoch 00057: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 78s 365ms/step - loss: 0.7646 - accuracy: 0.7549 - val_loss: 0.7795 - val_accuracy: 0.7632 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 58/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7525 - accuracy: 0.7621\n",
            "Epoch 00058: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 78s 365ms/step - loss: 0.7525 - accuracy: 0.7621 - val_loss: 0.7901 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 59/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7650 - accuracy: 0.7501\n",
            "Epoch 00059: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.7650 - accuracy: 0.7501 - val_loss: 0.8173 - val_accuracy: 0.7574 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 60/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7483 - accuracy: 0.7612\n",
            "Epoch 00060: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.7483 - accuracy: 0.7612 - val_loss: 0.7758 - val_accuracy: 0.7720 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 61/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7436 - accuracy: 0.7645\n",
            "Epoch 00061: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.7436 - accuracy: 0.7645 - val_loss: 0.8337 - val_accuracy: 0.7469 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 62/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7582 - accuracy: 0.7629\n",
            "Epoch 00062: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 0.7582 - accuracy: 0.7629 - val_loss: 0.7804 - val_accuracy: 0.7702 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 63/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7300 - accuracy: 0.7656\n",
            "Epoch 00063: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 79s 367ms/step - loss: 0.7300 - accuracy: 0.7656 - val_loss: 0.7956 - val_accuracy: 0.7621 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 64/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7451 - accuracy: 0.7638\n",
            "Epoch 00064: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 78s 367ms/step - loss: 0.7451 - accuracy: 0.7638 - val_loss: 0.7419 - val_accuracy: 0.7824 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 65/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7364 - accuracy: 0.7711\n",
            "Epoch 00065: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.7364 - accuracy: 0.7711 - val_loss: 0.7997 - val_accuracy: 0.7574 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 66/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7411 - accuracy: 0.7669\n",
            "Epoch 00066: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 79s 367ms/step - loss: 0.7411 - accuracy: 0.7669 - val_loss: 0.8241 - val_accuracy: 0.7557 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 67/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7353 - accuracy: 0.7650\n",
            "Epoch 00067: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 0.7353 - accuracy: 0.7650 - val_loss: 0.9785 - val_accuracy: 0.6917 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 68/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7315 - accuracy: 0.7742\n",
            "Epoch 00068: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 0.7315 - accuracy: 0.7742 - val_loss: 0.8455 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 69/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7226 - accuracy: 0.7697\n",
            "Epoch 00069: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 0.7226 - accuracy: 0.7697 - val_loss: 0.7964 - val_accuracy: 0.7673 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 70/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7282 - accuracy: 0.7732\n",
            "Epoch 00070: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 0.7282 - accuracy: 0.7732 - val_loss: 0.7775 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 71/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7248 - accuracy: 0.7735\n",
            "Epoch 00071: val_accuracy did not improve from 0.78301\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.7248 - accuracy: 0.7735 - val_loss: 0.7935 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 72/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7163 - accuracy: 0.7708\n",
            "Epoch 00072: val_accuracy improved from 0.78301 to 0.78476, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.072.h5\n",
            "214/214 [==============================] - 80s 372ms/step - loss: 0.7163 - accuracy: 0.7708 - val_loss: 0.7451 - val_accuracy: 0.7848 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 73/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7158 - accuracy: 0.7812\n",
            "Epoch 00073: val_accuracy did not improve from 0.78476\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.7158 - accuracy: 0.7812 - val_loss: 0.7846 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 74/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7010 - accuracy: 0.7806\n",
            "Epoch 00074: val_accuracy improved from 0.78476 to 0.78767, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.074.h5\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 0.7010 - accuracy: 0.7806 - val_loss: 0.7310 - val_accuracy: 0.7877 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 75/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7112 - accuracy: 0.7751\n",
            "Epoch 00075: val_accuracy did not improve from 0.78767\n",
            "214/214 [==============================] - 80s 374ms/step - loss: 0.7112 - accuracy: 0.7751 - val_loss: 0.7614 - val_accuracy: 0.7801 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 76/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.7834\n",
            "Epoch 00076: val_accuracy did not improve from 0.78767\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 0.7036 - accuracy: 0.7834 - val_loss: 0.7632 - val_accuracy: 0.7801 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 77/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7073 - accuracy: 0.7792\n",
            "Epoch 00077: val_accuracy did not improve from 0.78767\n",
            "214/214 [==============================] - 80s 374ms/step - loss: 0.7073 - accuracy: 0.7792 - val_loss: 0.7224 - val_accuracy: 0.7813 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 78/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.7834\n",
            "Epoch 00078: val_accuracy did not improve from 0.78767\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 0.6968 - accuracy: 0.7834 - val_loss: 0.8752 - val_accuracy: 0.7522 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 79/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.7809\n",
            "Epoch 00079: val_accuracy did not improve from 0.78767\n",
            "214/214 [==============================] - 80s 374ms/step - loss: 0.6994 - accuracy: 0.7809 - val_loss: 0.7325 - val_accuracy: 0.7824 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 80/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.7865\n",
            "Epoch 00080: val_accuracy did not improve from 0.78767\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 0.6871 - accuracy: 0.7865 - val_loss: 0.7714 - val_accuracy: 0.7749 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 81/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.7814\n",
            "Epoch 00081: val_accuracy did not improve from 0.78767\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 0.6965 - accuracy: 0.7814 - val_loss: 0.7704 - val_accuracy: 0.7766 - lr: 0.0010\n",
            "Learning rate:  0.0001\n",
            "Epoch 82/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.8087\n",
            "Epoch 00082: val_accuracy did not improve from 0.78767\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 0.6240 - accuracy: 0.8087 - val_loss: 0.7431 - val_accuracy: 0.7853 - lr: 3.1623e-05\n",
            "Learning rate:  0.0001\n",
            "Epoch 83/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.8211\n",
            "Epoch 00083: val_accuracy improved from 0.78767 to 0.80105, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.083.h5\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 0.6013 - accuracy: 0.8211 - val_loss: 0.7198 - val_accuracy: 0.8010 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 84/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5905 - accuracy: 0.8274\n",
            "Epoch 00084: val_accuracy did not improve from 0.80105\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 0.5905 - accuracy: 0.8274 - val_loss: 0.7232 - val_accuracy: 0.7976 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 85/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5901 - accuracy: 0.8248\n",
            "Epoch 00085: val_accuracy improved from 0.80105 to 0.80163, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_Primera_ResNet20v2_model.085.h5\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 0.5901 - accuracy: 0.8248 - val_loss: 0.7162 - val_accuracy: 0.8016 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezaiJkW-irF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "510f34d8-c6bc-4540-d3b5-4dde0bf56e4d"
      },
      "source": [
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}