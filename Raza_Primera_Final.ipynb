{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Resnet Raza Drop 0.3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vachaconcu/Mineriadatos/blob/master/Raza_Primera_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pi35iTtInSU",
        "colab_type": "text"
      },
      "source": [
        "# Modelo Resnet para clasificación de Raza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAqcNFQbIjbO",
        "colab_type": "text"
      },
      "source": [
        "En el código siguiente se importan las funciones necesarias, principalmente de tensorflow.keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gXtMPu12ogD6",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72g2VqSgI_cK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Ahora se importan los datos que ya están en forma de tensores y separados en datos de entrenamiento, validación interna y validación externa.\n",
        "\n",
        "Los datos de etiqueta ya se encuentran en codificación one-hot donde los niveles de raza son: Blanco [10000], Negro [01000], Asiático [00100], Indio [00010], Otro [00001].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1CTb70R3YZDU",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Minería de Datos/Interna/datos')\n",
        "\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/X_R_val_int.npz') ; x_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/X_R_train.npz') ; x_train = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/y_R_val_int.npz') ; y_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/y_R_train.npz') ; y_train = datos['arr_0']\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_R_val_ext.npz') ; y_test2 = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_R_val_ext.npz') ; x_test2 = datos['arr_0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEl6plGaKQkL",
        "colab_type": "text"
      },
      "source": [
        "Se imprimen los tamaños de los conjuntos de datos correspondientes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H7RbMR55bWhS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e52da323-43d3-42fd-8174-de40473cc34e"
      },
      "source": [
        "print('x_test =',x_test.shape)\n",
        "print('x_train =',x_train.shape)\n",
        "print('y_test =',y_test.shape)\n",
        "print('y_train =',y_train.shape)\n",
        "\n",
        "print('y_test_ext=', y_test2.shape)\n",
        "print('x_test_ext=', x_test2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test = (1719, 200, 200, 3)\n",
            "x_train = (6874, 200, 200, 3)\n",
            "y_test = (1719, 5)\n",
            "y_train = (6874, 5)\n",
            "y_test_ext= (2063, 5)\n",
            "x_test_ext= (2063, 200, 200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUA8CpGmKW09",
        "colab_type": "text"
      },
      "source": [
        "El número de clases se establece como 5 ya que las clasificaciones posibles son Blanco, Negro, Asiático, Indio y otro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eoVqIG4mojgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6182dde3-e72f-4235-f2e8-5de4feee6699"
      },
      "source": [
        "batch_size = 32 \n",
        "epochs = 85\n",
        "\n",
        "data_augmentation = True\n",
        "num_classes = 5\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "n = 2\n",
        "version = 2\n",
        "\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "model_type"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ResNet20v2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzO_wfA9K8-Z",
        "colab_type": "text"
      },
      "source": [
        "Se establece el tamaño de entrada como 200x200x3 y se realiza el centrado de las imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kql8upFhpIg_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "83f62c08-3d10-4627-ecb5-ff58085d4570"
      },
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (6874, 200, 200, 3)\n",
            "6874 train samples\n",
            "1719 test samples\n",
            "y_train shape: (6874, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFMQlZjBLKYc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Se programa el valor de la tasa de aprendizaje, ya que si se usa un tamaño de epoch muy grande, esta se haga más pequeña."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4j58TCUSpTH1",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hmx8ifYrprJ_",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 dropout=0.3,\n",
        "                 conv_first=True):\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M3Y0J8UMp3TO",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=5, dropout=0.3):\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    \n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    \n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                \n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                \n",
        "                if res_block == 0:\n",
        "                    \n",
        "                    strides = 2 \n",
        "\n",
        "           \n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                \n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IVUkR2XgqCuS",
        "colab": {}
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T92lYa5JqG1t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3cba834c-ed42-4602-febe-d007728d22b1"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200, 200, 16) 0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 200, 200, 16) 272         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200, 200, 16) 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 200, 200, 16) 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 64) 1088        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 64) 1088        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 200, 200, 64) 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 64) 0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 200, 200, 16) 1040        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 16) 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 200, 200, 16) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 200, 200, 64) 1088        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 200, 200, 64) 0           add[0][0]                        \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 200, 200, 64) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 100, 100, 64) 4160        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 100, 100, 64) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 100, 100, 64) 36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 100, 100, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 100, 100, 64) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 100, 100, 128 8320        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 100, 100, 128 8320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 100, 100, 128 0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 100, 100, 128 512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 100, 100, 128 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 100, 100, 128 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 100, 100, 64) 8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 100, 100, 64) 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 100, 100, 64) 0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 128 8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 100, 100, 128 0           add_2[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 100, 128 512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100, 100, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 100, 100, 128 0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 50, 50, 128)  16512       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 50, 50, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 50, 50, 128)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 50, 50, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 50, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 50, 50, 128)  0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 256)  33024       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 256)  33024       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 50, 50, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 50, 50, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 50, 50, 256)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 50, 50, 128)  32896       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 50, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 50, 50, 128)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 50, 50, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 50, 50, 128)  0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 50, 50, 256)  33024       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 50, 50, 256)  0           add_4[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 50, 50, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 50, 50, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 50, 50, 256)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 6, 6, 256)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 5)            46085       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 617,605\n",
            "Trainable params: 614,117\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kiZiKwkziQ4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6fd3f51-cde6-4287-e180-1bec00b95cf6"
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), './Modelos')\n",
        "model_name = 'Raza_0.3_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    \n",
        "    datagen = ImageDataGenerator(\n",
        "        \n",
        "        featurewise_center=False,\n",
        "        \n",
        "        samplewise_center=False,\n",
        "        \n",
        "        featurewise_std_normalization=False,\n",
        "        \n",
        "        samplewise_std_normalization=False,\n",
        "        \n",
        "        zca_whitening=False,\n",
        "        \n",
        "        rotation_range=0,\n",
        "        \n",
        "        width_shift_range=0.1,\n",
        "        \n",
        "        height_shift_range=0.1,\n",
        "        \n",
        "        horizontal_flip=True,\n",
        "        \n",
        "        vertical_flip=False)\n",
        "\n",
        "    \n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    \n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.8575 - accuracy: 0.4702\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.46888, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.001.h5\n",
            "214/214 [==============================] - 225s 1s/step - loss: 1.8575 - accuracy: 0.4702 - val_loss: 1.6910 - val_accuracy: 0.4689 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.5815 - accuracy: 0.5330\n",
            "Epoch 00002: val_accuracy improved from 0.46888 to 0.61082, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.002.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 1.5815 - accuracy: 0.5330 - val_loss: 1.3981 - val_accuracy: 0.6108 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.4731 - accuracy: 0.5598\n",
            "Epoch 00003: val_accuracy improved from 0.61082 to 0.62885, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.003.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 1.4731 - accuracy: 0.5598 - val_loss: 1.2668 - val_accuracy: 0.6289 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.4008 - accuracy: 0.5742\n",
            "Epoch 00004: val_accuracy improved from 0.62885 to 0.63700, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.004.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 1.4008 - accuracy: 0.5742 - val_loss: 1.2147 - val_accuracy: 0.6370 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.3267 - accuracy: 0.5826\n",
            "Epoch 00005: val_accuracy improved from 0.63700 to 0.64282, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.005.h5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.3267 - accuracy: 0.5826 - val_loss: 1.2131 - val_accuracy: 0.6428 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.2782 - accuracy: 0.5941\n",
            "Epoch 00006: val_accuracy did not improve from 0.64282\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.2782 - accuracy: 0.5941 - val_loss: 1.1277 - val_accuracy: 0.6417 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.2416 - accuracy: 0.6055\n",
            "Epoch 00007: val_accuracy did not improve from 0.64282\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.2416 - accuracy: 0.6055 - val_loss: 1.1275 - val_accuracy: 0.6294 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.2251 - accuracy: 0.6022\n",
            "Epoch 00008: val_accuracy improved from 0.64282 to 0.65271, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.008.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 1.2251 - accuracy: 0.6022 - val_loss: 1.0654 - val_accuracy: 0.6527 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.2033 - accuracy: 0.6074\n",
            "Epoch 00009: val_accuracy improved from 0.65271 to 0.66201, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.009.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 1.2033 - accuracy: 0.6074 - val_loss: 1.0429 - val_accuracy: 0.6620 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1799 - accuracy: 0.6125\n",
            "Epoch 00010: val_accuracy did not improve from 0.66201\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.1799 - accuracy: 0.6125 - val_loss: 1.0715 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1550 - accuracy: 0.6177\n",
            "Epoch 00011: val_accuracy improved from 0.66201 to 0.68703, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.011.h5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.1550 - accuracy: 0.6177 - val_loss: 1.0197 - val_accuracy: 0.6870 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1414 - accuracy: 0.6201\n",
            "Epoch 00012: val_accuracy did not improve from 0.68703\n",
            "214/214 [==============================] - 221s 1s/step - loss: 1.1414 - accuracy: 0.6201 - val_loss: 1.0036 - val_accuracy: 0.6777 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1303 - accuracy: 0.6225\n",
            "Epoch 00013: val_accuracy did not improve from 0.68703\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.1303 - accuracy: 0.6225 - val_loss: 1.0428 - val_accuracy: 0.6475 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.1088 - accuracy: 0.6293\n",
            "Epoch 00014: val_accuracy did not improve from 0.68703\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.1088 - accuracy: 0.6293 - val_loss: 0.9518 - val_accuracy: 0.6864 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0928 - accuracy: 0.6333\n",
            "Epoch 00015: val_accuracy improved from 0.68703 to 0.70390, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.015.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 1.0928 - accuracy: 0.6333 - val_loss: 0.9153 - val_accuracy: 0.7039 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0792 - accuracy: 0.6364\n",
            "Epoch 00016: val_accuracy did not improve from 0.70390\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.0792 - accuracy: 0.6364 - val_loss: 0.9451 - val_accuracy: 0.7004 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0613 - accuracy: 0.6463\n",
            "Epoch 00017: val_accuracy did not improve from 0.70390\n",
            "214/214 [==============================] - 221s 1s/step - loss: 1.0613 - accuracy: 0.6463 - val_loss: 0.9518 - val_accuracy: 0.6830 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0485 - accuracy: 0.6478\n",
            "Epoch 00018: val_accuracy improved from 0.70390 to 0.71262, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.018.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 1.0485 - accuracy: 0.6478 - val_loss: 0.9079 - val_accuracy: 0.7126 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 19/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0419 - accuracy: 0.6517\n",
            "Epoch 00019: val_accuracy did not improve from 0.71262\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.0419 - accuracy: 0.6517 - val_loss: 0.9142 - val_accuracy: 0.7074 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0253 - accuracy: 0.6570\n",
            "Epoch 00020: val_accuracy did not improve from 0.71262\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.0253 - accuracy: 0.6570 - val_loss: 0.9559 - val_accuracy: 0.6899 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 21/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0078 - accuracy: 0.6628\n",
            "Epoch 00021: val_accuracy did not improve from 0.71262\n",
            "214/214 [==============================] - 221s 1s/step - loss: 1.0078 - accuracy: 0.6628 - val_loss: 0.9860 - val_accuracy: 0.6894 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0058 - accuracy: 0.6633\n",
            "Epoch 00022: val_accuracy did not improve from 0.71262\n",
            "214/214 [==============================] - 220s 1s/step - loss: 1.0058 - accuracy: 0.6633 - val_loss: 0.9765 - val_accuracy: 0.6806 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9965 - accuracy: 0.6684\n",
            "Epoch 00023: val_accuracy did not improve from 0.71262\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.9965 - accuracy: 0.6684 - val_loss: 0.9046 - val_accuracy: 0.7080 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9807 - accuracy: 0.6749\n",
            "Epoch 00024: val_accuracy did not improve from 0.71262\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.9807 - accuracy: 0.6749 - val_loss: 0.9540 - val_accuracy: 0.7027 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9647 - accuracy: 0.6780\n",
            "Epoch 00025: val_accuracy did not improve from 0.71262\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.9647 - accuracy: 0.6780 - val_loss: 0.9297 - val_accuracy: 0.7062 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 26/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9581 - accuracy: 0.6792\n",
            "Epoch 00026: val_accuracy improved from 0.71262 to 0.71379, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.026.h5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.9581 - accuracy: 0.6792 - val_loss: 0.8938 - val_accuracy: 0.7138 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9476 - accuracy: 0.6880\n",
            "Epoch 00027: val_accuracy did not improve from 0.71379\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.9476 - accuracy: 0.6880 - val_loss: 0.9671 - val_accuracy: 0.6958 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 28/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9392 - accuracy: 0.6896\n",
            "Epoch 00028: val_accuracy improved from 0.71379 to 0.75160, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.028.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.9392 - accuracy: 0.6896 - val_loss: 0.8333 - val_accuracy: 0.7516 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 29/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9458 - accuracy: 0.6833\n",
            "Epoch 00029: val_accuracy did not improve from 0.75160\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.9458 - accuracy: 0.6833 - val_loss: 0.8864 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9444 - accuracy: 0.6896\n",
            "Epoch 00030: val_accuracy did not improve from 0.75160\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.9444 - accuracy: 0.6896 - val_loss: 0.8379 - val_accuracy: 0.7446 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 31/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9160 - accuracy: 0.7014\n",
            "Epoch 00031: val_accuracy did not improve from 0.75160\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.9160 - accuracy: 0.7014 - val_loss: 0.8766 - val_accuracy: 0.7266 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 32/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9227 - accuracy: 0.6954\n",
            "Epoch 00032: val_accuracy did not improve from 0.75160\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.9227 - accuracy: 0.6954 - val_loss: 0.9554 - val_accuracy: 0.7033 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 33/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.9166 - accuracy: 0.6938\n",
            "Epoch 00033: val_accuracy did not improve from 0.75160\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.9166 - accuracy: 0.6938 - val_loss: 0.8529 - val_accuracy: 0.7475 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 34/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8954 - accuracy: 0.7125\n",
            "Epoch 00034: val_accuracy improved from 0.75160 to 0.75742, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.034.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8954 - accuracy: 0.7125 - val_loss: 0.7997 - val_accuracy: 0.7574 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 35/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8983 - accuracy: 0.7046\n",
            "Epoch 00035: val_accuracy did not improve from 0.75742\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.8983 - accuracy: 0.7046 - val_loss: 0.8469 - val_accuracy: 0.7423 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 36/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8878 - accuracy: 0.7094\n",
            "Epoch 00036: val_accuracy did not improve from 0.75742\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8878 - accuracy: 0.7094 - val_loss: 0.8823 - val_accuracy: 0.7219 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 37/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8889 - accuracy: 0.7100\n",
            "Epoch 00037: val_accuracy did not improve from 0.75742\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8889 - accuracy: 0.7100 - val_loss: 1.1832 - val_accuracy: 0.6428 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 38/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8849 - accuracy: 0.7093\n",
            "Epoch 00038: val_accuracy did not improve from 0.75742\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.8849 - accuracy: 0.7093 - val_loss: 0.8579 - val_accuracy: 0.7295 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 39/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8725 - accuracy: 0.7175\n",
            "Epoch 00039: val_accuracy did not improve from 0.75742\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.8725 - accuracy: 0.7175 - val_loss: 0.7987 - val_accuracy: 0.7574 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 40/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8578 - accuracy: 0.7181\n",
            "Epoch 00040: val_accuracy improved from 0.75742 to 0.76382, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.040.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8578 - accuracy: 0.7181 - val_loss: 0.7857 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 41/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8566 - accuracy: 0.7219\n",
            "Epoch 00041: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.8566 - accuracy: 0.7219 - val_loss: 0.8002 - val_accuracy: 0.7533 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 42/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8517 - accuracy: 0.7248\n",
            "Epoch 00042: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8517 - accuracy: 0.7248 - val_loss: 0.8574 - val_accuracy: 0.7394 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 43/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8537 - accuracy: 0.7167\n",
            "Epoch 00043: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8537 - accuracy: 0.7167 - val_loss: 0.7955 - val_accuracy: 0.7621 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 44/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8368 - accuracy: 0.7279\n",
            "Epoch 00044: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8368 - accuracy: 0.7279 - val_loss: 0.8297 - val_accuracy: 0.7469 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 45/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8298 - accuracy: 0.7325\n",
            "Epoch 00045: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8298 - accuracy: 0.7325 - val_loss: 0.8175 - val_accuracy: 0.7429 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 46/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8183 - accuracy: 0.7374\n",
            "Epoch 00046: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8183 - accuracy: 0.7374 - val_loss: 0.7973 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 47/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8334 - accuracy: 0.7292\n",
            "Epoch 00047: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8334 - accuracy: 0.7292 - val_loss: 1.0084 - val_accuracy: 0.7027 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 48/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8176 - accuracy: 0.7381\n",
            "Epoch 00048: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8176 - accuracy: 0.7381 - val_loss: 0.7869 - val_accuracy: 0.7574 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 49/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8115 - accuracy: 0.7369\n",
            "Epoch 00049: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8115 - accuracy: 0.7369 - val_loss: 0.7720 - val_accuracy: 0.7597 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 50/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8120 - accuracy: 0.7350\n",
            "Epoch 00050: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8120 - accuracy: 0.7350 - val_loss: 0.8321 - val_accuracy: 0.7464 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 51/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7970 - accuracy: 0.7471\n",
            "Epoch 00051: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.7970 - accuracy: 0.7471 - val_loss: 0.8042 - val_accuracy: 0.7574 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 52/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8002 - accuracy: 0.7442\n",
            "Epoch 00052: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8002 - accuracy: 0.7442 - val_loss: 1.2441 - val_accuracy: 0.6510 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 53/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8034 - accuracy: 0.7412\n",
            "Epoch 00053: val_accuracy did not improve from 0.76382\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.8034 - accuracy: 0.7412 - val_loss: 0.9810 - val_accuracy: 0.6992 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 54/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7933 - accuracy: 0.7448\n",
            "Epoch 00054: val_accuracy improved from 0.76382 to 0.77022, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.054.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.7933 - accuracy: 0.7448 - val_loss: 0.7718 - val_accuracy: 0.7702 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 55/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8020 - accuracy: 0.7409\n",
            "Epoch 00055: val_accuracy did not improve from 0.77022\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.8020 - accuracy: 0.7409 - val_loss: 0.8020 - val_accuracy: 0.7574 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 56/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7933 - accuracy: 0.7469\n",
            "Epoch 00056: val_accuracy improved from 0.77022 to 0.77080, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.056.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.7933 - accuracy: 0.7469 - val_loss: 0.7694 - val_accuracy: 0.7708 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 57/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7832 - accuracy: 0.7508\n",
            "Epoch 00057: val_accuracy did not improve from 0.77080\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.7832 - accuracy: 0.7508 - val_loss: 0.7870 - val_accuracy: 0.7592 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 58/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7879 - accuracy: 0.7479\n",
            "Epoch 00058: val_accuracy improved from 0.77080 to 0.77836, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.058.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.7879 - accuracy: 0.7479 - val_loss: 0.7493 - val_accuracy: 0.7784 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 59/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7772 - accuracy: 0.7537\n",
            "Epoch 00059: val_accuracy did not improve from 0.77836\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7772 - accuracy: 0.7537 - val_loss: 0.8610 - val_accuracy: 0.7464 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 60/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7752 - accuracy: 0.7550\n",
            "Epoch 00060: val_accuracy did not improve from 0.77836\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7752 - accuracy: 0.7550 - val_loss: 0.7778 - val_accuracy: 0.7627 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 61/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7797 - accuracy: 0.7545\n",
            "Epoch 00061: val_accuracy did not improve from 0.77836\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7797 - accuracy: 0.7545 - val_loss: 0.7713 - val_accuracy: 0.7597 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 62/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7605 - accuracy: 0.7638\n",
            "Epoch 00062: val_accuracy did not improve from 0.77836\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7605 - accuracy: 0.7638 - val_loss: 0.8034 - val_accuracy: 0.7533 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 63/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7674 - accuracy: 0.7569\n",
            "Epoch 00063: val_accuracy did not improve from 0.77836\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7674 - accuracy: 0.7569 - val_loss: 0.8177 - val_accuracy: 0.7545 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 64/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7782 - accuracy: 0.7523\n",
            "Epoch 00064: val_accuracy did not improve from 0.77836\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7782 - accuracy: 0.7523 - val_loss: 0.7971 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 65/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7717 - accuracy: 0.7562\n",
            "Epoch 00065: val_accuracy did not improve from 0.77836\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7717 - accuracy: 0.7562 - val_loss: 0.7818 - val_accuracy: 0.7627 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 66/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7586 - accuracy: 0.7638\n",
            "Epoch 00066: val_accuracy did not improve from 0.77836\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7586 - accuracy: 0.7638 - val_loss: 0.8234 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 67/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7699 - accuracy: 0.7568\n",
            "Epoch 00067: val_accuracy improved from 0.77836 to 0.77952, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.067.h5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7699 - accuracy: 0.7568 - val_loss: 0.7458 - val_accuracy: 0.7795 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 68/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7538 - accuracy: 0.7606\n",
            "Epoch 00068: val_accuracy did not improve from 0.77952\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7538 - accuracy: 0.7606 - val_loss: 0.7466 - val_accuracy: 0.7772 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 69/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7478 - accuracy: 0.7647\n",
            "Epoch 00069: val_accuracy did not improve from 0.77952\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.7478 - accuracy: 0.7647 - val_loss: 0.8662 - val_accuracy: 0.7429 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 70/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7452 - accuracy: 0.7682\n",
            "Epoch 00070: val_accuracy did not improve from 0.77952\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7452 - accuracy: 0.7682 - val_loss: 0.8184 - val_accuracy: 0.7551 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 71/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7466 - accuracy: 0.7637\n",
            "Epoch 00071: val_accuracy did not improve from 0.77952\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7466 - accuracy: 0.7637 - val_loss: 0.7614 - val_accuracy: 0.7708 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 72/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7408 - accuracy: 0.7664\n",
            "Epoch 00072: val_accuracy did not improve from 0.77952\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7408 - accuracy: 0.7664 - val_loss: 0.8314 - val_accuracy: 0.7568 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 73/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7376 - accuracy: 0.7669\n",
            "Epoch 00073: val_accuracy did not improve from 0.77952\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7376 - accuracy: 0.7669 - val_loss: 0.7727 - val_accuracy: 0.7691 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 74/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7217 - accuracy: 0.7740\n",
            "Epoch 00074: val_accuracy did not improve from 0.77952\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7217 - accuracy: 0.7740 - val_loss: 0.8244 - val_accuracy: 0.7644 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 75/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7254 - accuracy: 0.7705\n",
            "Epoch 00075: val_accuracy did not improve from 0.77952\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7254 - accuracy: 0.7705 - val_loss: 0.7621 - val_accuracy: 0.7795 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 76/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7443 - accuracy: 0.7650\n",
            "Epoch 00076: val_accuracy improved from 0.77952 to 0.79465, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.076.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.7443 - accuracy: 0.7650 - val_loss: 0.7243 - val_accuracy: 0.7946 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 77/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7185 - accuracy: 0.7780\n",
            "Epoch 00077: val_accuracy did not improve from 0.79465\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7185 - accuracy: 0.7780 - val_loss: 1.0062 - val_accuracy: 0.7010 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 78/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7373 - accuracy: 0.7650\n",
            "Epoch 00078: val_accuracy did not improve from 0.79465\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7373 - accuracy: 0.7650 - val_loss: 0.7851 - val_accuracy: 0.7720 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 79/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7301 - accuracy: 0.7714\n",
            "Epoch 00079: val_accuracy did not improve from 0.79465\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7301 - accuracy: 0.7714 - val_loss: 0.8141 - val_accuracy: 0.7609 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 80/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7266 - accuracy: 0.7673\n",
            "Epoch 00080: val_accuracy did not improve from 0.79465\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7266 - accuracy: 0.7673 - val_loss: 0.7966 - val_accuracy: 0.7743 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 81/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7295 - accuracy: 0.7761\n",
            "Epoch 00081: val_accuracy did not improve from 0.79465\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.7295 - accuracy: 0.7761 - val_loss: 0.7332 - val_accuracy: 0.7842 - lr: 3.1623e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 82/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6520 - accuracy: 0.8027\n",
            "Epoch 00082: val_accuracy improved from 0.79465 to 0.79639, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.082.h5\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.6520 - accuracy: 0.8027 - val_loss: 0.7245 - val_accuracy: 0.7964 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 83/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6235 - accuracy: 0.8113\n",
            "Epoch 00083: val_accuracy improved from 0.79639 to 0.79814, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.083.h5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.6235 - accuracy: 0.8113 - val_loss: 0.7391 - val_accuracy: 0.7981 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 84/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6295 - accuracy: 0.8062\n",
            "Epoch 00084: val_accuracy did not improve from 0.79814\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.6295 - accuracy: 0.8062 - val_loss: 0.7358 - val_accuracy: 0.7976 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 85/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6221 - accuracy: 0.8154\n",
            "Epoch 00085: val_accuracy improved from 0.79814 to 0.80454, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Raza_0.3_ResNet20v2_model.085.h5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.6221 - accuracy: 0.8154 - val_loss: 0.7199 - val_accuracy: 0.8045 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ezaiJkW-irF6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "da98bafd-b446-4a31-abc4-81c843ac64dd"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3iUVfbA8e9JL6QXWsBQpXcQRBBQFOwVG7aVxbqWXf2pa9l1dauua0dRWVx7Y8VVRFBBQTpI753QEhIC6fX+/rgzMAmTkIRMJpk5n+fhCZn3nZmbIbznvffce64YY1BKKeW/ArzdAKWUUt6lgUAppfycBgKllPJzGgiUUsrPaSBQSik/p4FAKaX8nAYCpWpIRKaKyDM1PHeniJx7qq+jVEPQQKCUUn5OA4FSSvk5DQTKpziGZB4SkdUikicib4tIcxH5RkRyROQ7EYlzOf8SEVknItkiMldEuroc6ysiKxzP+xgIq/ReF4nISsdzF4hIrzq2+dcislVEskTkSxFp5XhcRORfIpIuIkdFZI2I9HAcu0BE1jvatldEHqzTB6YUGgiUb7oSGA10Bi4GvgF+DyRhf+fvBRCRzsCHwP2OYzOA/4lIiIiEAF8A7wLxwKeO18Xx3L7AFOB2IAF4A/hSREJr01ARGQX8FRgHtAR2AR85Dp8HDHf8HDGOczIdx94GbjfGRAE9gB9q875KudJAoHzRy8aYg8aYvcA8YLEx5hdjTCHwX6Cv47xrgK+NMbONMSXAc0A4cCYwGAgGXjDGlBhjPgOWurzHROANY8xiY0yZMeYdoMjxvNq4AZhijFlhjCkCHgWGiEgqUAJEAV0AMcZsMMbsdzyvBOgmItHGmMPGmBW1fF+ljtFAoHzRQZe/F7j5vpnj762wd+AAGGPKgT1Aa8exvaZiVcZdLn8/DfidY1goW0SygTaO59VG5TbkYu/6WxtjfgBeAV4F0kVksohEO069ErgA2CUiP4rIkFq+r1LHaCBQ/mwf9oIO2DF57MV8L7AfaO14zKmty9/3AH82xsS6/Ikwxnx4im2IxA417QUwxrxkjOkPdMMOET3keHypMeZSIBk7hPVJLd9XqWM0ECh/9glwoYicIyLBwO+wwzsLgIVAKXCviASLyBXAIJfnvgncISJnOJK6kSJyoYhE1bINHwK3ikgfR37hL9ihrJ0iMtDx+sFAHlAIlDtyGDeISIxjSOsoUH4Kn4PycxoIlN8yxmwCxgMvA4ewieWLjTHFxphi4ArgFiALm0+Y5vLcZcCvsUM3h4GtjnNr24bvgCeAz7G9kA7AtY7D0diAcxg7fJQJPOs4diOwU0SOAndgcw1K1YnoxjRKKeXftEeglFJ+TgOBUkr5OQ0ESinl5zQQKKWUnwvydgNqKzEx0aSmpnq7GUop1aQsX778kDEmyd2xJhcIUlNTWbZsmbeboZRSTYqI7KrqmA4NKaWUn9NAoJRSfk4DgVJK+bkmlyNwp6SkhLS0NAoLC73dFI8LCwsjJSWF4OBgbzdFKeUjfCIQpKWlERUVRWpqKhWLRfoWYwyZmZmkpaXRrl07bzdHKeUjfGJoqLCwkISEBJ8OAgAiQkJCgl/0fJRSDccnAgHg80HAyV9+TqVUw/GZQHAyhSVlHDhSQGmZlm1XSilXfhMIikrLSc8posQDgSA7O5vXXnut1s+74IILyM7Orvf2KKVUbfhNIAgKsEMqpeX1v/9CVYGgtLS02ufNmDGD2NjYem+PUkrVhk/MGqqJQA8GgkceeYRt27bRp08fgoODCQsLIy4ujo0bN7J582Yuu+wy9uzZQ2FhIffddx8TJ04EjpfLyM3NZezYsZx11lksWLCA1q1bM336dMLDw+u9rUopVZnPBYKn/reO9fuOnvC4AfKLSgkJCiA4sHYdoW6tovnDxd2rPP63v/2NtWvXsnLlSubOncuFF17I2rVrj03xnDJlCvHx8RQUFDBw4ECuvPJKEhISKrzGli1b+PDDD3nzzTcZN24cn3/+OePHj69VO5VSqi58LhBUxTnXpiE25hw0aFCFef4vvfQS//3vfwHYs2cPW7ZsOSEQtGvXjj59+gDQv39/du7c2QAtVUopHwwE1d25r993lOjwIFLiIjzahsjIyGN/nzt3Lt999x0LFy4kIiKCESNGuF0HEBoaeuzvgYGBFBQUeLSNSinl5LFksYhMEZF0EVlbxfEYEfmfiKwSkXUicqun2uIUFCiUltV/nyAqKoqcnBy3x44cOUJcXBwRERFs3LiRRYsW1fv7K6XUqfBkj2Aq8ArwnyqO3w2sN8ZcLCJJwCYRed8YU+ypBgUFCGUeSBYnJCQwdOhQevToQXh4OM2bNz92bMyYMbz++ut07dqV008/ncGDB9f7+yul1KnwWCAwxvwkIqnVnQJEiV0q2wzIAqqfb3mKAgOEwhLPLCj74IMP3D4eGhrKN9984/aYMw+QmJjI2rXHO04PPvhgvbdPKaWq4s11BK8AXYF9wBrgPmOM26u0iEwUkWUisiwjI6PObxgUGEBpua4sVkopV94MBOcDK4FWQB/gFRGJdneiMWayMWaAMWZAUpLbLTdrxDk0VG4aYu6QUko1Dd4MBLcC04y1FdgBdPHkGzpXF3siT6CUUk2VNwPBbuAcABFpDpwObPfkG3pydbFSSjVVHksWi8iHwAggUUTSgD8AwQDGmNeBp4GpIrIGu97rYWPMIU+1ByAowMa9srJyCA705FsppVST4clZQ9ed5Pg+4DxPvb87QYHaI1BKqcr8pvooeG5oqK5lqAFeeOEF8vPz67U9SilVG34VCDxViloDgVKqKfO5WkPVERE7hbSeN6dxLUM9evRokpOT+eSTTygqKuLyyy/nqaeeIi8vj3HjxpGWlkZZWRlPPPEEBw8eZN++fYwcOZLExETmzJlTr+1SSqma8L1A8M0jcGBNlYdTi0sJCBAIqkWyuEVPGPu3Kg+7lqGeNWsWn332GUuWLMEYwyWXXMJPP/1ERkYGrVq14uuvvwZsDaKYmBief/555syZQ2JiYs3bo5RS9civhobA9go8uZ5s1qxZzJo1i759+9KvXz82btzIli1b6NmzJ7Nnz+bhhx9m3rx5xMTEeK4RSilVC77XI6jmzh0gPTOPopJyOreI8sjbG2N49NFHuf322084tmLFCmbMmMHjjz/OOeecw5NPPumRNiilVG34XY8gMEDqPVnsWob6/PPPZ8qUKeTm5gKwd+9e0tPT2bdvHxEREYwfP56HHnqIFStWnPBcpZTyBt/rEZxEUEAAZeXlGGOwhU9PnWsZ6rFjx3L99dczZMgQAJo1a8Z7773H1q1beeihhwgICCA4OJhJkyYBMHHiRMaMGUOrVq00WayU8goxTawA24ABA8yyZcsqPLZhwwa6du1ao+cfyi1iX3YB3VpGE1TLvYsbi9r8vEopBSAiy40xA9wda5pXwlPgqbUESinVVPldINDCc0opVZHPBIKTDnEVHoGD6wg2JQD1vqisoTS1oTylVOPnE4EgLCyMzMzMk18ky4oJogxomj0CYwyZmZmEhYV5uylKKR/iE7OGUlJSSEtLo9ptLEuLITcdc8hwMBcKMoJIDwtuuEbWk7CwMFJSUrzdDKWUD/GJQBAcHEy7du2qPylrB7w0HC6bxDWzEriyXwp/vERn3iillE8MDdVIRIL9mp9JQmQImXnF3m2PUko1Ev4TCEKjICAI8jOJjwwhK6/I2y1SSqlGwX8CgYjtFeRnEh8ZSmau9giUUgr8KRCAIxBkkRAZQpYODSmlFOCngSC+WQiH84t1Tr5SSuFvgSA87liyuKTMcLSw1NstUkopr/OvQHAsRxACoMNDSimFPwaCgsPER9jlEzpzSCmlPBgIRGSKiKSLyNpqzhkhIitFZJ2I/OipthwTkQCmjKRgGwB05pBSSnm2RzAVGFPVQRGJBV4DLjHGdAeu9mBbLMeisoQAu3uYDg0ppZQHA4Ex5icgq5pTrgemGWN2O85P91RbjomIByCOowC6ulgppfBujqAzECcic0VkuYjcVNWJIjJRRJaJyLJqC8udjCMQhBZnExESqD0CpZTCu4EgCOgPXAicDzwhIp3dnWiMmWyMGWCMGZCUlFT3dzxWbyjLUWZCA4FSSnkzEKQB3xpj8owxh4CfgN4efUctPKeUUifwZiCYDpwlIkEiEgGcAWzw6DuGNIPAEMjPJCkqjP3ZBR59O6WUago8th+BiHwIjAASRSQN+AMQDGCMed0Ys0FEZgKrgXLgLWNMlVNN66lREB4P+Zn0aB3NDxsPkldUSmSoT2zLoJRSdeKxK6Ax5roanPMs8Kyn2uCWY1FZ79NjKTewdu8Rzmif0KBNUEqpxsS/VhaDnTmUn0mvlBgAVqVle7lBSinlXX4YCGy9oYRmoaTEhbMq7Yi3W6SUUl7lh4HA9ggAeqfEsmqP9giUUv7NDwOBzRFQXk7vNjGkHS4gM1eLzyml/Jd/BgJTDoXZ9EqJBWC1Dg8ppfyYfwYCgPwseraOIUA0YayU8m9+GAhsvSHyM4kMDaJjcjPNEyil/Jr/BYLw44EAbMJ4ddoR3b9YKeW3/C8QOIeGCmyF7F5tYsnMKybtsJabUEr5J/8NBI4eQR9NGCul/Jz/BYKQSAgMPRYITm8RRUhggCaMlVJ+y/8CgUiFRWUhQQF0axXNSk0YK6X8lP8FAnCUmTi+i2bvlBjW7j1CWbkmjJVS/sdPA0F8xUDQJpb84jK2pud6sVFKKeUdfhoIEo4NDQHHVhj/svuwt1qklFJeo4EA6JAUScuYML7fmO7FRimllHf4ZyAIj3cUnisDQEQ4r1tz5m3JoKC4zMuNU0qphuWfgSAiATBQeHztwPndW1BYUs5PWzK81y6llPICPw4EVBgeGtgunpjwYGatO+ilRimllHf4aSCoWG8IIDgwgHO6JPP9xoOUlpV7qWFKKdXw/DQQnNgjADive3Oy80tYulNnDyml/IefBoITewQAwzsnERoUwKz1B7zQKKWU8g4/DQTHN6ep8HBIEMM6JTJr3UEtS62U8hseCwQiMkVE0kVk7UnOGygipSJylafacoLgCAgKO6FHAHBetxbszS5g3b6jDdYcpZTyJk/2CKYCY6o7QUQCgb8DszzYDndvfEK9IadzuiYTIDBrvc4eUkr5B48FAmPMT8CJV9qKfgN8DjT8kt7weLc9goRmoQxIjWfWOs0TKKX8g9dyBCLSGrgcmFSDcyeKyDIRWZaRUU8LviLiIf+Q20PndWvOxgM57MnKr5/3UkqpRsybyeIXgIeNMSedtG+MmWyMGWCMGZCUlFQ/7x7fHg5tATdJ4dHdmgMwW4eHlFJ+wJuBYADwkYjsBK4CXhORyxrs3ZO7QWE25Jw4BHRaQiSdkpvx3QYNBEop3+e1QGCMaWeMSTXGpAKfAXcZY75osAYkd7Vf09e7PXxut+Ys3pHFkfySBmuSUkp5gyenj34ILAROF5E0EblNRO4QkTs89Z61ciwQbHB7eHS35pSVG+Zu1tLUSinfFuSpFzbGXFeLc2/xVDuqFJkIkclV9gj6pMSS2CyE2esPcmmf1g3cOKWUajj+ubLYqXm3KgNBQIBwTpfm/Lgpg+JSLUKnlPJd/h0IkrtB+kYod3+hH92tOTlFpSzZcbLlEEop1XT5eSDoCqUFkL3T7eGhHRMJCw7Q2UNKKZ/m54Ggm/1aRcI4PCSQszomMXu9FqFTSvku/w4ESafbrwfd5wkARndLZm92ARv25zRQo5RSqmH5dyAIjYLY06pMGAOM6tIcEV1lrJTyXf4dCMCRMHY/NASQFBXKoNR4Plm2hxLdwlIp5YM0ECR3hcwtUFpc5Sm/HtaevdkFfLV6XwM2TCmlGoYGguRuUF5qg0EVRnVJpnPzZrw+d7smjZVSPkcDwUlKTYBdXHb78A5sOpjDnE1ackIp5Vs0ECR2hoCgahPGAJf0aUWrmDBen7u9gRqmlFINQwNBUAgkdKy2RwAQHBjAhGHtWbIzi+W7dKWxUsp3aCAAOzx0kh4BwLWD2hAbEcwk7RUopXyIBgKwCePDO6Eot9rTIkKCuHlIKt9tOMiG/Ucbpm1KKeVhNQoEInKfiESL9baIrBCR8zzduAbjTBhnbDrpqbcOTSU2Ipgnp6+lvFxnECmlmr6a9gh+ZYw5CpwHxAE3An/zWKsamrPm0L4VJz01NiKE34/tytKdh/l0+R4PN0wppTyvpoFAHF8vAN41xqxzeazpi28PSV1hxTtuN7Ov7Kr+KQxKjeev32wkM7eoARqolFKeU9NAsFxEZmEDwbciEgX4Tr0FETjjdjiwBnYtOOnpAQHCM5f3ILewlL/M2NgADVRKKc+paSC4DXgEGGiMyQeCgVs91ipv6HUNhMfBotdqdHrn5lFMHN6ez1eksXBbpocbp1QNFByGg+u83QrVBNU0EAwBNhljskVkPPA4cMRzzfKCkAjofwtsmgGHd9XoKb8Z1Yk28eE8+Okq1u71rY9DNUELXoEpY2o0vKmUq5oGgklAvoj0Bn4HbAP+47FWecvACYDAksk1Oj08JJBXrutHWbnh8td+5u35O7QWkfKevAwoOgpFuneGqp2aBoJSY69wlwKvGGNeBaI81ywviUmBbpfAindPuqbAqXebWL65bxhnd07m6a/Wc9s7y8jKq7qSqVIeU+z4nc3L8G47VJNT00CQIyKPYqeNfi0iAdg8ge8ZfBcUHYFVH9b4KXGRIbx5U3+euqQ787ccYtwbCzl4tNCDjVTKjSINBKpuahoIrgGKsOsJDgApwLPVPUFEpohIuoisreL4DSKyWkTWiMgCx7CT96UMhFb9YN4/4esHYc5fYNEkyKq+rISIcPOZqbx72yD2ZxdwzRsL2Ztd0ECNVorjQ0IaCFQt1SgQOC7+7wMxInIRUGiMOVmOYCowpprjO4CzjTE9gaeBmg3Me5oIjHwMgiNgzafw4z9g5iPw1W9r9PQz2ifw7oQzyMwrZtzrC9mdme/hBivlUKyBQNVNTUtMjAOWAFcD44DFInJVdc8xxvwEVFmm0xizwBhz2PHtImwvo3HodC7cuwIe2QVPZsLAX8PuhVBSs+Gefm3j+PDXg8krLuXqNxaw81CehxusFC5DQ4e82w7V5NR0aOgx7BqCm40xNwGDgCfqsR23Ad9UdVBEJorIMhFZlpHRwHc7AYHQ8VwoLYQ9i2v8tB6tY/ho4mBKygzXv7mIPVnaM1AepsliVUc1DQQBxhjXrbkya/HcaonISGwgeLiqc4wxk40xA4wxA5KSkurjbWsndShIIGyfW6undWkRzbu3DSK3qJQb3lrM/iOaM1AepMliVUc1vZjPFJFvReQWEbkF+BqYcapvLiK9gLeAS40xjXd5bmiUTSLv+LHWT+3eKoZ3bzuDrLxibnhzMek5OpvI61Z/AnuXe7sV9ausFEodNxo6NKRqqabJ4oewydxejj+TjTFV3sHXhIi0BaYBNxpjNp/KazWI9iNg3y92GX8t9W4Ty9RbB3LgaCE3vrWEI/kl9d48VQszH4HFb3i7FfWr2GURmfYIVC3VeHjHGPO5Mea3jj//Pdn5IvIhsBA4XUTSROQ2EblDRO5wnPIkkAC8JiIrRWRZnX6ChtJ+BJhy2Dm/Tk8fkBrPmzcNYMehPG57ZykFxWX12jxVQ+VlNpjXIaA3as5hocAQDQSq1oKqOygiOYC7mgkCGGNMdFXPNcZcV91rG2MmABNq0shGoXV/CI60eYKuF9fpJYZ2TORf1/Thng9XcM8HK3jjxv4EBeomcQ2q8IgN6L4WCJyJ4rhUOLTFDhUFVvvfW6ljqr0KGWOijDHRbv5EVRcEfFJQiE0a1zJhXNmFvVryp0t78P3GdB6ZtkZrEzW0fMeMZl8LBM4eQVw7wEBBlTO3lTqB3o7WRvsRkLkVsk9tZ7IbB5/Gfed04rPladw0ZQnbM2pW10jVA+cFsiDbu+2ob84cQXw7+1WHh1QtaCCojfYj7Nc6zB6q7P5zO/HUJd1ZuTub81/4iWe/3Uh+cekpv646CdcegS/1xpzlJeI0EKja00BQG8ndIDIJtp96IHDWJvr+wbO5uHcrXp2zjXP++SPvLtxJYYkmkj0m3zFL2ZT5Vrlm59DQsR6BTiFVNaeBoDZEbK9g+9x6u5tMjgrj+XF9+PSOIbSKDeeJ6es4+9k5TJm/QwOCJ7iOnftSnsCZLI5vb79qj0DVggaC2mp3NuSlw9SL4N3L4b0r4Yc/n/LLDkyN57M7hvDBhDNITYjkT1+t56rXF5CZW1QPjVbH5PtoIHD2bmJSICBIA4GqFQ0EtdXlQlt7qLzE/ufL3AY//QMO7zzllxYRzuyYyMe3D+GNG/uz5WAu10xepHsb1CfXHkGhDyWMi3MhIBiCwyEiUQOBqhUNBLUVEQ/jP4fbZsGE7+DmL+3jqz+p17c5v3sLpt5q9za4+vWFWrSuvuRn2rpR4GM9glwIbWb/HpmkOQJVKxoITlVsW0gdBqs+qvdZKEM6JPDehDPIzi/m6tcXsmqPD93Bekv+YftvBj4WCHIgxLF7bKT2CFTtaCCoD72ugaxtHilk1rdtHB/fPoQAgSsnLeDl77dQWlZe7+/jNwqyIKGD4+8+FAiKK/cINBComtNAUB+6XQpBYbXa57g2uraM5pv7hjO2Z0v+OXsz107W/Q3qLD8ToltBULhvBYKiHFslF3RoSNWaBoL6EBZtk8hrP4fSYo+8RUxEMC9f15cXr+3DpgM5nPevn3ht7laKS7V3UGPG2FlD4fEQHutbq4uLcyHE2SNItN8X682CqhkNBPWl17X2DnPrbI++zaV9WjPzgeEM65TIP2ZuYsyLPzF/i9791Uhxrp3tFREP4XE+1iOoNDQEkK+/F6pmNBDUlw6j7H/AVR95/K1ax4Yz+aYB/PuWgZSVG8a/vZhHp62mqFQXoFXLuYYg3BkIfKhHUCFZ7AgEuZonUDWjgaC+BAZBz6th88yq7zSXTYGlb9XbW47sksy39w/n9rPb8+GSPYx7YxH7snU7zCo5y0tEJPhej6Byshg0YaxqTANBfep1DZQVw/J3Tjy2/kv46gGY+Sjkpp94vI7CggN5dGxXXh/fj60Hc7j45fks3NZ4d/30KudisghnjsBHAoExJ+YIQAOBqjENBPWpZW/oOBq++yOs/OD44xmb4Is7IamrDRTLptT7W4/p0ZLp9wwlJiKYG95axKPT1pCRo+UpKsh3XPjD4yEs1ndWFpfk2812Ql3WEYAGAlVjGgjqkwhc8y60Pxu+uAt+eR8Kj8JHN9il/+M/h07n2+Gh0vq/SHdMjmL63UO5+cxUPl22h5HPzeW1uVu1eJ3TsR6BY2ioJB9KfKB8h7PyqHNoKCTS7qanU0hVDWkgqG/B4XDdR7ZK6fS74d8XQNZ2uHoqxLSGwXfaO7W1n1f/OsV5UFb7Te6jwoL5w8Xd+faB4QxuH88/Zm5i4J+/4+73V/DZ8jT/7iXkZwJih4XC4+xjvtArcFYedSaLQVcXq1rRQOAJweFw3YfQYSQcXAPn/xlSz7LH2o+wQ0SLXqu6JEVJAUwaCl//rs5N6JDUjLduHsiHvx7M2B4tWLIziwc/XcWgv3zH01+t988ZRvlZEBYDAYHHA4Ev5AmKjtqvzh4B6OpiVSu6u7WnOHsG+1dBysDjj4vYXsH/7oVdPx8PEK4WvAyHd9jhI2Psc+poSIcEhnRIoLzcsH7/UT5Yspu35+9g8Y5MXr6uH+0SI+v82k1OQZZNFIOPBQJnj6BSIDiS5p32qCZHewSeFBQKbQadeCHvNc4mLBdNOvE5R9Jg3vM2mZmzzw4r1YOAAKFH6xj+cnlPJt/Yn7TDBVz00jy++GVvvbx+k5CfZfMDYIeHwDfWEhRXyhGADg2pWtFA4A3B4TDgV7Dxa8jYXPHYd3+0M0Cuett+v3N+vb/9ed1bMOPeYXRvFcP9H6/k9/9d4x8J5fxMG4DBN3sEodHHH4tMsiuLy7UEiTo5jwUCEZkiIukisraK4yIiL4nIVhFZLSL9PNWWRmngBNuVn3IebPjKPrZ7Maz5FIbeCx3OgchkjwQCgFax4Xzw6zO4c0QHPli8m3Fv+MGeBwWHfXNoqNixO1nloaHyUt9IhiuP82SPYCowpprjY4FOjj8TATfjJD4suiVMnAOxp8HHN8CX98LMhyGqFZz1gB1OSj3L5hHqeZ8Dp6DAAB4e04XJN/ZnR0YeF78yn3/O2sS7i3Yxc+0BVu3JpqzcM+/tFa5DQ6HRdoOaxhAIds6H1Z/W/fmVp4+Cy+pinULqEYd32pl9PsJjyWJjzE8iklrNKZcC/zHGGGCRiMSKSEtjzH5PtanRSewEt82GOX+Gn18EDFzxpp0HDpA6FNZNs4lj56bkHnBe9xb87zdR3PfxSl6Zs7VC3EmJC+f6M9oybkAbEpuFeqwNHldSCCV5x3sCIo1ndfHPL8HBtdDr6ro937lfcbBL4t91UVlS51Nrn6rIGHhzFAy4DUY95u3W1AtvzhpqDexx+T7N8dgJgUBEJmJ7DbRt27ZBGtdggkJg9FPQaTTsWWLrFTmlDrNfd873aCAASE2MZPrdQyktKycrr5j0nCK2pufy0dLd/GPmJv41ezOX923NYxd0IyYi2KNt8QjX8hJOYY0kEBzdBzkH7Hh+QB066c7yEq7P1XpDnlOSb/NNWdu83ZJ60ySmjxpjJgOTAQYMGOBDYxUuUs86cSppYmf7H3rnfOh3k+fbUF5GUEAAydFhJEeH0aN1DJf1bc3W9BzeXbiL9xbvZt6WQ/zz6t6c2THR8+2pT66VR53C4xrHGPrRvWDKbHK3WXLtn++6KY2TBgLPcQ635RzwbjvqkTdnDe0F2rh8n+J4TDmJwGlDYafn8gTHFB6B1wbDi73tMJXzwoktXfHUpT2YdueZhAcHcv1bi3nmq/VNa6aRa3kJp8ZQgbSk8Hjbcuo4KupacM7J+XNqjqD+OavY1vXfqxHyZiD4ErjJMXtoMHDEr/IDNZV6FhxNs8kpTzEGvvwNZG6DZs1h9pPwfFebwC45Xta6d5tYvrr3LMYPbstb83dw2as/s+lAjufaVZ+OlaCu1CPwdiDI2efy9zreYbpuStCebVoAACAASURBVOMUGGR7P7kH69425d6xQHDA8zdoDcST00c/BBYCp4tImojcJiJ3iMgdjlNmANuBrcCbwF2eakuT5pon8JQlb8L66XDuH2DCbLhzgc1VrHjHTmd1ERESxDOX9eTftwzkUG4RF78ynynzd1De2GcXVTU05O1AcNTl3ufovqrPq05Rzok9ArB7M/vQXWuj4exlleTbnrQP8FggMMZcZ4xpaYwJNsakGGPeNsa8box53XHcGGPuNsZ0MMb0NMYs81RbmrSk0yEi0XOBYO8KmPUYdB4DQ35jH2veHS55GWLbHl/jUMnILsnMvH84wzom8qev1nPDW4v54pe9ZOVV2rM5Nx2e6wzb53qm/TXlLlkcHmf/I5d7cYjL9UJd1x5Bce6JOQKwgaCuwUVVLd9lvw8fyRPoyuLGTsROI/XEeoKCbPj0Frtw7bJJFWediECXi+wFvMj98E9is1DeunkAz1zWgy3pOdz/8Ur6PzObK177mbfn7yC3qBQ2fmWHJ3b8VD/tretFO/+wvWsOcpkC6ywz4c27uqOOtFhwZN3v3qvrEWggqH+ue0H7SI9LA0FTkDoMjuyx6wmqk58Fqz6GuX+D0uLqzwVbzuLoXrj63xXvlJ26XARlRbD1u4qPlxbB1Ivg55cQEcYPPo0lvz+X6XcP5d5RnSgpMzz91XrO/Ov3bJ//iX1O+sYa/ahVKs6ziWx39ZlqwrW8hFNjWF18dL8tH53Qof57BFGt7EXLA3tf+DVnOXPwmR5Bk5g+6vc6ngsBQTDvn3DpqyceXz4VVn0EexbbOkVgFxQNnFD1a2ZshhX/see0GeT+nLaD7eyTjV9D98uPP776E9g5z/4JCoMzJhIQIPRuE0vvNrE8MLozv+w+zDtz19J621IQyNj+Cxu3ZHBmh0QCA4Ti0nKW7sxi7qZ0covKiAkPJiY8mJYxYVzYqyXBgZXuUXb8ZKd6bp8DZ95Tq48PcFQejav42LFA4MUppEf32lXmUS1PoUfgJlkMtkcA9nXjUuvcRFVJXqb9PA/vqJjsb8I0EDQF8e1gyN12WmefG+C0M48f++V9+N99kNwdhj1ox/pnPQY/PWfPDQ53/5rfP2WPDX+o6vcNCITTx8L6/9keRlCIXfS04CVo3tPmEL55yNb4731Nhaf2bRtH3/6HYHsp25oNoF3ucn799jxio2Po3iqaxTuyyC0qJSQogOiwII4UlFBSZoe+ftl9mKcu7VGxLVtm2a9py+q28Mq1vIRTY+gR5Oy3F+yoFrDvl9o/v7TY9tpCqsgRgB0e0kBQf/IzISbF3lz4SI9Ah4aairMfhpi28NUDx4d9Dq6zm9ekDoM75tnl7in9YeRj9gKz7N/uX2v3Yjt2P/Q+aJZU/ft2uRiKjti7f4At38Khzfa5V02BdsPtfswbZ5z43I0zIDyeDmPuIgDDm2Oj6doyiq0ZuVzcuxVv3jSAlU+OZtnjo9n8zFg2/GkMt53VjncW7uLTZS6Lzo2BLd9BYKjtFWRurf3nV5DVSIeG9tkhnKiWdvFXbXelc1eC2im69fH3UPUn/5DtcUf5zqwsDQRNRUgkXPgcZGyEhS/bBOEnN0NYNFz5tr17d2o3DNqdDfOfP16QzMkYu06gWXPbyziZ9iNsInOjY/bQzy/agNT9MggOg2s/gJa9bdLZNQ9QVmKDRucxtvcADIvJ4N+3DuLHh0by1yt6MrpbcyJCbKdURAgPCeTRsV04s0MCj32xllV7HEM2GZvgyG4YeJv9Pm1prT8+8jNPzIOEOZPFXhoaKi+zd5TOHgGm9vP+i9xUHnWKbmm/HtV1mvUqP9P2LqNaaI9AeUHn86HrxfDjP2wQyNpmg0BU8xPPHfW4vcNcMrni45tmwJ5FMOKR48XtqhMcBp3OtXf3uxfB7oUw5C4IdNQbCo2C6z+BkAg7ROWsf7/rZzsbp8sFtk5SYAhkbDjp2wUFBvDK9f1IahbKHe8tZ09WPpvnTwPg6lV9yZNI1i6ezS+7D9e8MmpZqW3LCT0C5+Y0XuoR5Kbb0hLRLV3G82t5YamuRxAabQPEUd+4a20Uykod5cwTbS/ORz5bDQRNzZi/28Txtu/txb7dMPfntRkEnc63d/CFR6A4H7bMhllPQEIn6FuL2kVdLoLcAzD9bnsX3ffGisebJcF5f7YBZsU79rGNM2wiucMou8o1oVONZw7FR4bwxo39ycorZtg/5pDxy1dsNm2IadGOjYGdCdy3nMtfW8Dgv37Pit01uIg77/gr5wgCg+3YurcCgTPRGN3a0SOg9kMNx0pQu8kRiDimkGqPoN44f1ciE+2/We4Bn9j8RwNBUxPT2s75P/NeGPpA9eeO/L29CL55Dvw9Fd6/yl5oxv7dXpxrqtN5NvhkboVBv3Z/99nnepurmP0He1e7aQa0H3m815HcFdJP3iNw6tE6hknj+3HP0OYMCd5MhzMv562bB9J/6Pl0CUzjtas6ExkSyPi3FjN/y0nq6eS7WUzm5M3Vxc6x+yjHrCGoQ4/AOTTkJhA4X1tzBPXHuYYgIt4G2fLSigvMmigNBE1Rt0vgvKdPPnOmVR/of6vNHwycAOOnwf9th47n1O79wmNtUjgwFAZNdH+OCFz8IpQWwgfX2HUPXS44fjy5ix3nr5yzqMaoLs15sOMBAspLCOx8nn0wZSBiyrkgfh+f3DGEtvER/GrqUmaurXgBNa6L75z/UcMrTR91/mxeCwSOu//o1naoQQLr0CNwBAJ3wdn52j6S0GwUnOUlIhLr3otrhHT6qK+7+IX6eZ0LnrNDDNWVSU7oAGc/BD88A4hNFDsldbVfMzbZmU01tWWWvdttO9h+73xu2hKS25/NxxOHcMvUJdz1/nLO796CjJwi0g4XcCi3iBGnJ3PniPb0d1dewik81nvrCI7uhYBgO2QVEGAvLLUdc3YGVnfJYnDUGzpgx7Zr0wtU7h0rXphwvLebcwBa9vJem+qB/maomknoYP+czJn3wdr/2ouua9BIdgSC9PUVA0FJoR12cneRMsauau4w4nhyOjzO7tOQZktTxUQE895tZ/Dgp6tYs/cIKXHhnNUpkWahQXyxci9XTjrI/yUv4S5g2qZC0rdsI7+olLjIELq0iKZ/cAwhOZvr9JGcspz9dujG2bOry6Ky4mpyBGADgSmDvPTjCWlVd86hochEOywEPrGoTAOBql9BIXDbrBMfj0u1yeMM1ymmpfD6UHu3727FdPp6e9c84pGKj6cMgs3f2EAhQmRoEJPGn9jL+L8xp/Px0j3kz5kJwOPf7iOfrArn/CUoj/ODDjJ9/g7GDz6NkKAGHC09uq/ixTmqhS0FXhs16RG4ey9VN65VbEUA8YkppBoIVP1zN14dEGjv5F0Txpu/sQnorB0w/P8g7rSKz9ky237tOLri4ykDYOV7kLW92l5KREgQtw5pS/m6dZQeac7c315As7BgwoMDycgpYuOBHKJ+nk3Mrp/401frmLpgJ/835nQu7NkSEanjD18LR/dVHFKIaln7KrPFOTZ3ExTi/rhrIFCnLu8QhMYc/7wjk3wiR6DJYtVwkrtVDASL34BmLUACYOErFc8tzrNrIFIGHV8Y5eSsjVSThWVLJhOwbzlBY/5CcnQ4ESFBiAjJ0WEM75xE387tCKKUd8d3JyIkkHs++IWrXl/IloMe3nDHGEd5idbHH4tqYWd5uWwGdFJV1Rly0tXF9Ss/EyJdpiH7yKIyDQSq4SR3seOpBdm2PMbOeTD4Tuh1Dax4t+K2ivP/ZYeFznv6xNdJ6mITyCcLBNm74fun7fTXHle6P8exunhYm2C+vncY/7iyF9szcrnwpfm89P0Wiks9NEe8MNtubBLlEuTqsqisqhLUThEJdjGfL68l+ORmWPlBw7xX/qGK61F8ZHquDg2phuM6c2jVBzZn0O8muwJ65fu2hzDqMTtU9PNL0HPc8dlCrgICoXU/2LOk6vcyBr76rf37hc87xnPdcKk3FBiTwriBbRjVNZmn/ree52dvZsaa/ZzXrTmRoUFEhgYRFxFCz9YxtIkPR9KW2SR3q761/yyOTR2tlCMA21OIb1ez16mqBLWTyKlVNq3sSBq8diZc/zGcNqR+XvNU5B2C9V/ArgW2Qm5VRRbrS34mRKcc/76uxQIbGQ0EquE4Zw7tXmBLWfe82s4uioiHLhfaoaCh98Gsx+1MotFPVf1abQbBvOftHbG7C+Gaz2DrbLsSO7ZN1a/jvODuWQItbE2kxGahvHxdXy7p3Yo/fbWOl+dsPWFPoOYRAcziToqDInioxb/JzCshr7iU285qx/WD2p48x+C8i6wQCJyLympx0T5ZjwDs8FB93bXuWmCLEK7/onEEggOr7de8dHszUV3p9fqQlwkteh//3rVYoHNmWxOkgUA1nJg2toDd/H/ZYZEzbj9+bOj9trDdtImw6Ws45w/Vz3LpOBp+etZe8AfcWvFYQTbMfARaD7AroavTvIct4b3y/eNF7RxGd2vO6G7NKS83FJSUkVdUSnpOESv3ZFO6djoxaYeh+DCJ2ashrjeB+cJj/13Lwm2Z/PWKnkSFVXNhyHEXCJw9gloMDRXn2sVN1YluBXvraSdY593vth/q5/VO1YE19mtyN1tOpd8tnlsvYYyj8qjL0FB0S2yxwHS76r+J0hyBajgBAXYP5sIjcNrQY3fgALQZCKedZYNAXLuTV0ZtM8g+f8nkE7fwXPKm/Q974T8rVmV1RwT6joe9y+Hg+iqabaeoJkeH0aN1DOMHn8YtYT/aRHdQOM91Xs/UWwcx7c4zeej805mxZj8Xvzyf1WnVLFRz3qE3a3H8sbBYO1xWqx7BSZLFYC9WR/fXz1anzkBwaLMdJvK2/avtUM05T9qc0NrPPfdexblQVlwx8Na1NEgjo4FANazkbvaru1IVwx+0ZRbG/r3i3sLuiMCg2+1aA9cpl0W5sOg1W3CvVZ+atanXOLvCd+X7NTv/8C7Y+j30vxm6XgRrp0FpEQEBwt0jO/LRxCEUlpRzySvzOf9fP/Hct5tYtSe7YtmLo/sgMhkTGMxny9OYNHcbxWXGMZ5fzUXl4Dq7u9yxn7eGQ0NlRcfnwNdVeRnsX2XLjQBsm3Nqr1cfDqyxU3A7nW9/t+Y/X30RuH2/1H3rzmPlJSrNGoImv6hMA4FqWN0usaUnulx04rEOI+HhHbbcdk30vMou7FnyxvHHlk+1m9AMf7DmbYpMtDuxrfqoZns9//Ke/dp3PPS+1s4A2vztscOD2sUzp988NjW7g5vLp/H23PVc+urPjH1xHt+uO2ADwtF9FEe24KYpS3jw01X8feZGrpj0MwVhyVWXmSgrhXevgLfOhUOOzXlOliwGl7UEpzhz6NBmO6TX+3rbk/Hk8FBNei/F+ZC5xfYMAwLgrN/aBYub3GySBHbdyeSRdvc+dwoO22nLVXEG0kjtESh1ajqfb2ecVDWOGxZT89cKDrezjjZ+Ddl7bLmKBS/bKqhV7cNclb432uGkLd9Wf15ZqQ0EHc+1W3W2G2Eviqs+On7OniWEL3qB0MhYrs/5N+sSHuWTQVspKSnh9neXc9HL88nYt5OfDwazfNdhnr6sB6+P78++7EJ+2BvAkYzdlLvba2H7HFv2uCQfPrre5kKKc2vWI4BTTxg7h4Va97NBe/vc2pVgLiux/0YnU14OUy+0u+9VJ3293aO7hWNRXvfL7Qr2+c+7DyTrvwSM7fmVl1V6zzIbYKdVUVQRXCqPuvQIIhLtxIYmvqjMo4FARMaIyCYR2Soij7g53lZE5ojILyKyWkQucPc6SlXJmeBd+pb9D557oHa9AacOo+zdnfNuvypbZ9thgP432+8Dg6DX1bY4Xl6mXQz2xV12T9s7F8AtXxMQ05pBq59kdtILvHhZe3KLSgnK209pZEu+vX84Nw4+jTE9WjDz/mEExbYiKO8g/Z+exd0frODjpbvZcjCHrek5HFn4b0rD4sm78gO7IvtTRxtOliM4dtdaD4EgpBkkdLSfV0EWHFhVs+du+Q5e7gcv97fTh6uz9nO7sdGaT23grcp+x3s7c02BQbY8+97ldgOlyjZ8aXMwR/eeOKy1ybHKfdM3kJvh/v1cC845BQTYGwHXHsH2ufZnqI+cTAPxWCAQkUDgVWAs0A24TkS6VTrtceATY0xf4FrgNU+1R/mo2LZw+gV2Q5yfX7AzhdqdXfvXCQyC3tfZC3p13fzl70BkcsXKqr2uhfISWDcN5v7VDldc8pLdRjT1LJjwHVzyMgG7F3DpLxP47pa2xEku55zRhzbxEcdeJjkqjPPO6EOkFDGmczOW7sji4c/XMPpfP3Hl8zMI2/Yt/8kdxNDPYXXPR+wFB04+NNSsuV29XR89gpa9bQK+/Qj72MmGh3LT4bNfwftX2lIY5SUw5XzYU8ViwNIi+OFPEBxhJxWkVbNW5MAa24OMbXv8sd7X2p3Zlr9T8dwjaTZAnPVbO5z4y38qHl/0ml1TYsqqTji7yxGAo2qs47Pdv8qWYf/sV/aGoDi/6vY3Ip7sEQwCthpjthtjioGPgEsrnWOAaMffY4CmnXFR3nHG7XZ8N3s3DH+o6sVjJ9PnBjvU4DrM4+rIXjt01Hd8xTnjLXrYfZl/ftEOTfW7yd4xO4nYx274FA7vJHjKuQAEuJluKI7x/L+em8Ti35/DrAeG88I1fXjvjN2ESimnj7mD1IRILlnSjflRNhiZkCgycopYujOLT5bt4R8zN3LX+8u56OV5PPjpKjak59u7VsfF6lBuETOmf8C3H77E7swaXqjKSuyF17l4rlmy/ZmrSxjvXQGvDIAN/4MRj8KdP8OvvrUX3Hcuhs1uihMufdv+O142yQ65bK5mqO7Aajss5PrvHRJp16es/6LiPhMb/me/9rjSBouNM45f2PettD2QYb+zr7e6in///Ey7Srty4HWWmcjPgo9vtIFi6P2w6kN4+zybm2jkPLmOoDWwx+X7NOCMSuf8EZglIr8BIoFz3b2QiEwEJgK0bdvW3SnKn6UOsxclkZonmt1J7Ahth9gx5rBo6Hfz8emnW2bDVw/YWU393Gzz2ftamPWYHY8/7xn3r99hFNw6A967yn4f1fLEc1xWF0tSZzo3j6Jz8yhY+jW06MnQs0Yy+EzDW/O2c/vsG7g+oAVffhbIweLvjr1EUIDQJj6C1rHhfL16P58tT+O76Gia7dnGH95dxp6Ny5gW9DghlHLDmkJIHc64gSmM7dGSsOAqpttmbLSbDrmuou4wEhZNsgnWyvtfF+XC57fZUiC3fQdJne3j8e3gV7NsD+HDa2H0n2DwXXaIpSAbfvqH3dmu+2V2uG/LLPcLC8tK7QyqAbedeKz/LbDsbbto0blWZf2XdlZRYkebD1r0mj0+5C5Y/Lpd39L3Rttz+vb3dmaWs81O+YccGwhVutGIamnLpfz3dhtsfzXTFkZMPQs+nwBvjICbv6z5LDYv8Hay+DpgqjEmBbgAeFdETmiTMWayMWaAMWZAUlJSgzdSNXIi9j/aTdPr3htwuuQVu8jsqwfgjeH2zvHzCXabz+AIuOVr9+Ufel1jg9Flr1Wf8G7ZGybMhiH3uE9ou1tdfHC9HZbpcwMAgQHC7Wd3YPq9o8ju+SvGDjidP17cjam3DmTugyPY8PQY5jw4gvcmnMHCR0fxf2NOZ3dJDDkZe1i/cx//iXqNoIhYyuPaMTnqLY4czuCBj1cx9G8/8K/Zmzl0NB9yDgK29zBnUzr7NjjG3Fu6XMw6jLJDPTt/PvHnmOUoFXLFGydeUJsl2c+x8/n2vKkX2rvmn1+wd/HOC3/n821COHvPia+fudUGJte1KMc+417Qqp+dQWaM/Vl2L4Sul9jjzbtB6/7wy7v22JrPbC8vPBZ6XGWDgbteQX7WicNCYNdpFB6xQWvs320QAOg0Gm7/CQQbeBoxT/YI9gKua/tTHI+5ug0YA2CMWSgiYUAikO7Bdilf5G73sbpI7GgvUuunw+wn4KPr7BqDEY/CWQ9Uvb6hWRLcWcMS0nGpcP6f3R+LamnH0ue/YIvrtepjk+ABQXbIw0XH5GY8e3Vv96/jEBsRwl0jOlKW1wdWruXHLl8RsHaPDZrBkUS9PZqve3zJgt5/Zcr8HXzw/RLOmn8jsbKFCSH/YO5RG5ieCZrJFcERrD0ayyDn7Mm2Q2zyddsP4NhKtLzcELB5hr0ID73f3hW7ExoF135gh0++eQQmDbUzd3pdY4Ml2GKBsx63F9hKq76PrSiuamew/jfD/+6zGxgdXAMYO3XZqe+N8NX98OU9doMZZ88hqrkNcKs/gZGPV9wONq/SqmInZ/DufT0M+FXFY3GnQbfLbLBx13NqJDwZCJYCnUSkHTYAXAtcX+mc3cA5wFQR6QqEAVWk7JVqICJ2aKLzGHtn2GawrZzaEEIi4Jr34MvfwJujbPBZ/YltS+RJSklUIzC2NZTkwZqPYcTvjy8KO/thZO5fGHr6WIaOSKb04B8pL8ohvzycJwOmMHTsf+iREkf7L55hXU57xk1eTL+2sfRKiSUhMoSrYvsRs/JzZqY1Y3puN7YcKuLb0IeJaN6LwJGPuW1LWblh5toDfLR0Ny1jujN21HSGbXqaoL1LwfU5iZ0h9rQqAsEqGzATK/U2nHpcCd8+ZgPS0b0Q3/74YkaAHlfAzEfta3ceW3Ffi17XwrQJtiaWayDLPwSxbgoMdh5jS6KccYf7HmmvcXYyw8YZdoZZI+SxQGCMKRWRe4BvgUBgijFmnYj8CVhmjPkS+B3wpog8gE0c32JME5pzpXxbcJgdb25onc+DuxfZC9k8x+Inx7BQnUU5FpW1H1Fxeu2w39kE+Je/gZICguLbwS1fErJ/FdFf3EH76EVw2tWQt4X4wXfwVHR3Plyym2kr0jhaWMqCgJE8G7yZK/Y+yxVAQWgzpKyIOwvu5I+5ZbSKPf5WxaXlTF+5l0k/bmN7Rh4pceGs3JPNJ8tKCQqYwPD2D3Bfbgy9HQVhnTkfs+JdvliyjWHdUkhs5uiRHVhjixhWVegtNMouOFz1sR2+GnJPxYt0WIwN9qs+tKXQXXW50E6TXfVRpUCQ6b6uU0Q8DPtt1Z992zNtGYw1n/hfIAAwxswAZlR67EmXv68HhnqyDUo1SeFxNt/Q/XLY8aMdbz4V7c+2ye9Rj1esvxQYBFe8CW+OtBfAS1+1ifLkrvYudvaTNgFeXkJwSj9u7pHKzWemAlBUWkZW3ijKy+/BlOxGts4mfPuPbEg6n4ULErjs1Z958dq+ZOYV8d36g/ywMZ2jhaV0axnNq9f3Y0yPFhhjWLE7mzmb0vl0WRqXvvozV/ZL4eExpyMifH+4C9eWFvDFFx/z51mDeO7qXozonGRrDHW5sPqfud/NtkcAFYeFnEb+3ia/nb0jp5AIm09YPx0ueNYuXCwrsXkAdzmCkwkIsEFpwct2jUKzxpfnlKZ2Az5gwACzbFk9VVJUSlnuyigfWGsT5s2SbfL63pU13idh88Ecbv33UvZm293W4iNDGNUlmYt6teTszkluy3TnFJbw6pxtTJm/g6BAodwYpLSQVWG3c7Dj1UxIv4ZNB3O4d0AEv117GVzwXPXVZY2ByWfbJO/9a2o3kWD7j/CfS46/R85B+GdnW8iwLqWuD66HSUNg7LNwRjWrlz1IRJYbYwa4O6ZlqJVS7odYWvSwxQEXT7KVUeNSa/xynZtH8cXdQ/lq9T56tI6hX9s4AgOqvxBHhQXzyNguXDuwDS9+v4XgQOGOszsQMnskbdLnMf3uF/n7t5tYt/BzCIE3NkfQNnw/Z3ZIJCbCTftFYNx/7CK12s4mazfc/vnhGdsrO1Zeoo55mubd7Gy01R97LRBURwOBUqpqIx+1K6YrL9yqgaSoUG4dWsOd1lykJkbyr2tcpql2Gg2bZxI27Wb+UF5GfuImyo8Kb22OIGPtCgIEWsaE0yo2jJYx4SQ0C6GguIycwlKOFpYQHR7MkPa7OLNDAu0SI0++aRDYn3Xss/D6UPjuj2R1uIx4qNvQkFOvcXaoLXNbxeR0I6CBQClVtbAYmPC9XVHrLV0vgWX/tjWKgsOJiEmC7hew4NxLWbknmwVbM9mZmce+7AJW7skmM7eIiNAgosOCiAoLZmt6Ll+vtusyWkSH0aVlFKfFR3BaQiQ9WscwqF0VU4+Tu9hE8oKX+fqXw9wILDwgDKkU28rKDdsycklNiCQkqJqlWT2ugtl/sDWURpxQes1WnV3xH5sfSuhg/8S0OfmeGvVAcwRKKZ9mjGFnZj4Lth1i0fYstmfksiszn9wiW9Du8r6teerS7kS72VHu84UbGDpzLMmSTQCGs8re4NWJY+jdxk6HOlpYwm8++IUfN2cQFRbEOV2SOa97C4Z2TCQm3M1w1dSLMNm7kHHvHl9pbIwNALOesNuAuoppYxP47etQP6uS6nIEGgiUUn7HGENWXjHvLtrFyz9spUV0GP8c15vB7RPIKyplW0Yu01bsZeqCnTzUag13Z/0VgLPDPiOvFKbdOZRyY7jtnaXsyszn7pEd2ZtdwPcbDnI4vwSwQ2MdkiJJTYjkaGEJaYcLOC3rZ54rf5ZQSuxK9N7X2HpKO+fZUikXv2inrmZutcULF7xivw65B0Y9Yac015EGAqWUqsIvuw/zwMcr2ZWVT6uY8GMznQBuOTOVxy/oQtB7l0LmVrbeuIwrJy0gJjyYIwUliMCkG/ozpIPNHZSWlbNs12FW7clmW0Yu2zLy2Hkoj5jwYFLiIwgLCmDR+m18OnQvp++bDvtX2mqp5z0NfW+quJIZbPXS2U/YukvJ3eGKyTaJXwcaCJRSqhp5RaW89P0W9h8ppHPzZnRMjqJLiyhSEx0lIQqP2CmkSZ1ZujOLG95azGnxEbx980DaJkRU/+IuCkvK6Pun2VzVP4WnL+thd5oLj3NfusLVltkw/W7ocz2c+8c6/YwaCJRSqh7tzS4gPiKEXgksMwAACDBJREFU8JDaJ3InvLOMDfuPMv/hkTWbweSUl2k3ITrZft5VqC4QeLv6qFJKNTmtY8PrFAQARnVJZm92AVvSc2v3xMiEOgeBk9FAoJRSDWhkF1ti4oeNjafIsgYCpZRqQC1jwunSIkoDgVJK+bNRXZJZvuswRwpKvN0UQAOBUko1uFFdkikrN8zb0ji2X9FAoJRSDaxv2zhiI4IbzfCQBgKllGpggQHC2Z2T+HFTBuXl3p/Cr4FAKaW8YFSXZDLzilm998jJT/YwDQRKKeUFwzslESDw3fqD3m6KBgKllPKGuMgQRp6ezJvztrPWy70CDQRKKeUlf7+qF/GRIdz+7nKy8oq91g4NBEop5SWJzUJ5fXx/MnKL+M2HKygtK/dKO3SHMqWU8qLebWJ55rIe/N9nq3nm6w0MSI3j562HmL/1ELmFpZzbtTlje9rNbkKDPLNbmQYCpZTysnED2rAm7QhTF+xk6oKdRIUGMbhDAhEhgcxce4BPl6cRFRrEfed2YsKw9vX+/h4NBCIyBngRCATeMsb8zc0544A/AgZYZYy53pNtUkqpxuiJi7rRKyWGjsnN6Nk6hqBAO3JfVFrGgq2ZfLN2Py1i6r5DWXU8th+BiAQCm4HRQBqwFLjOGLPe5ZxOwCfAKGPMYRFJNsZUu9RO9yNQSqna89Z+BIOArcaY7caYYuAj4NJK5/waeNUYcxjgZEFAKaVU/fNkIGgN7HH5Ps3xmKvOQGcR+VlEFjmGkk4gIhNFZJmILMvIaBxFmpRSyld4e/poENAJGAFcB7wpIrGVTzLGTDbGDDDGDEhKSmrgJiqllG/zZCDYC7Rx+T7F8ZirNOBLY0yJMWYHNqfQyYNtUkopVYknA8FSoJOItBOREOBa4MtK53yB7Q0gIonYoaLtHmyTUkqpSjwWCIwxpcA9wLfABuATY8w6EfmTiFziOO1bIFNE1gNzgIeMMZmeapNSSqkTeWz6qKfo9FGllKo9b00fVUop1QQ0uR6BiGQAu+r49ETgUD02xxfpZ1Q9/XxOTj+j6nnr8znNGON22mWTCwSnQkSWVdU1UpZ+RtXTz+fk9DOqXmP8fHRoSCml/JwGAqWU8nP+Fggme7sBTYB+RtXTz+fk9DOqXqP7fPwqR6CUUupE/tYjUEopVYkGAqWU8nN+EwhEZIyIbBKRrSLyiLfb420i0kZE5ojIehFZJyL3OR6PF5HZIrLF8TXO2231NhEJFJFfROQrx/ftRGSx43fpY0ctLb8kIrEi8pmIbBSRDSIyRH+HKhKRBxz/x9aKyIciEtbYfof8IhA4dkt7FRgLdAOuE5Fu3m2V15UCvzPGdAMGA3c7PpNHgO+NMZ2A7x3f+7v7sPWynP4O/MsY0xE4DNzmlVY1Di8CM40xXYDe2M9Jf4ccRKQ1cC8wwBjTA7tt77U0st8hvwgE1Gy3NL9ijNlvjFnh+HsO9j9wa+zn8o7jtHeAy7zTwsZBRFKAC4G3HN8LMAr4zHGK335GIhIDDAfeBjDGFBtjstHfocqCgHARCQIigP00st8hfwkENdktzW+JSCrQF1gMNDfG7HccOgA091KzGosXgP8Dyh3fJwDZjuq64N+/S+2ADODfjqGzt0QkEv0dOsYYsxd4DtiNDQBHgOU0st8hfwkEqgoi0gz4HLjfGHPU9Zixc4v9dn6xiFwEpBtjlnu7LY1UENAPmGSM6QvkUWkYSH+HJA7bQ2oHtAIiAbdb8nqTvwSCmuyW5ndEJBgbBN43xkxzPHxQRFo6jrcE0r3Vvv9v735CtKriMI5/n5TCQWEIaqOkmCAh1EAQ4RQMTSuJaDEp6IQE7dq0CGKikAS3uRKaRYGRi/6g2DIyGJpFqTijgS0Vm4UYJMEsksGeFue8zTQz4RA594XzfFbznve8l3Nffvf93Xvu3N/pA8PAy5KuU6YTX6DMiQ/Wy3xoO5bmgDnbP9bXX1ESQ2Jo0YvANdu/2l4ATlPiqq9iqJVEsJbV0ppS57o/Bn62/eGSt74GDte/DwNn13ts/cL2hO1ttndQYuY724coiyiN1W7Nfke2bwK/SNpdm0aBqySGlroBPCtpoB5zve+or2KomSeLJe2jzPduAD6xfazjIXVK0nPA98BPLM5/v0u5T/AF8Bil3Pd+2791Msg+ImkEeNv2S5J2Uq4QHgZmgHHbd7ocX1ckDVFupD9IWWb2dcoJZmKokvQBcIDyn3ozwBuUewJ9E0PNJIKIiFhdK1NDERHxL5IIIiIal0QQEdG4JIKIiMYlEURENC6JIGIdSRrpVTGN6BdJBBERjUsiiFiFpHFJ5yXNSpqsaxLMSzpea8ufk/RI7Tsk6QdJVySd6dXfl7RL0reSLku6JOnxuvnNS2r4n6pPnEZ0JokgYhlJT1CeBB22PQTcBQ5RCoZdtL0HmAKO1I98Crxj+0nKk9q99lPACdtPAXsp1SehVHp9i7I2xk5K7ZmIzmy8d5eI5owCTwMX6sn6JkrhtD+Bz2ufz4DTtSb/oO2p2n4S+FLSFmCr7TMAtv8AqNs7b3uuvp4FdgDT93+3IlaXRBCxkoCTtif+0Si9v6zff63PsrSmzF1yHEbHMjUUsdI5YEzSo/D3Os7bKcdLr2LkQWDa9u/AbUnP1/bXgKm66tucpFfqNh6SNLCuexGxRjkTiVjG9lVJ7wHfSHoAWADepCy88kx97xblPgKUMsIf1R/6XgVOKElhUtLRuo1X13E3ItYs1Ucj1kjSvO3NXY8j4v+WqaGIiMbliiAionG5IoiIaFwSQURE45IIIiIal0QQEdG4JIKIiMb9BXoxOhwiyYiAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}