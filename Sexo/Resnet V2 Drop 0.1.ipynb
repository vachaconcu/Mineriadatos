{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet Versión 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTxMkZCVWgLd",
        "colab_type": "code",
        "outputId": "e6cae2c3-a103-44e0-f0ad-f1c6ea03bf56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "from skimage import data\n",
        "from os import remove\n",
        "from skimage.color import rgb2gray\n",
        "from numpy import load\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape,ZeroPadding2D,Activation,MaxPooling2D,Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import SpatialDropout2D\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CTb70R3YZDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Minería de Datos/Interna/datos')\n",
        "\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/X_HM_val_int.npz') ; x_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/X_HM_train.npz') ; x_train = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/y_HM_val_int.npz') ; y_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Minería de Datos/Interna/datos/y_HM_train.npz') ; y_train = datos['arr_0']\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_val_ext.npz') ; y_test2 = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_val_ext.npz') ; x_test2 = datos['arr_0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7RbMR55bWhS",
        "colab_type": "code",
        "outputId": "645aa811-8098-45d5-d370-062291a03c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('x_test =',x_test.shape)\n",
        "print('x_train =',x_train.shape)\n",
        "print('y_test =',y_test.shape)\n",
        "print('y_train =',y_train.shape)\n",
        "\n",
        "print('y_test_ext=', y_test2.shape)\n",
        "print('x_test_ext=', x_test2.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test = (1719, 200, 200, 3)\n",
            "x_train = (6874, 200, 200, 3)\n",
            "y_test = (1719, 2)\n",
            "y_train = (6874, 2)\n",
            "y_test_ext= (2063, 2)\n",
            "x_test_ext= (2063, 200, 200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXtMPu12ogD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoVqIG4mojgL",
        "colab_type": "code",
        "outputId": "f2ed1e49-fda1-4423-a57f-d3dfb9116f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 32 # orig paper trained all networks with batch_size=128\n",
        "epochs = 90\n",
        "#epochs = 10\n",
        "data_augmentation = True\n",
        "num_classes = 2\n",
        "# subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter para sexo c: \n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 2\n",
        "\n",
        "# model version\n",
        "# orig paper: version = 1 (ResNet v1), \n",
        "# improved ResNet: version = 2 (ResNet v2)\n",
        "version = 2\n",
        "\n",
        "# computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "model_type"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ResNet20v2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kql8upFhpIg_",
        "colab_type": "code",
        "outputId": "44deefcf-333f-45fc-b112-eba11296376b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "#x_train = x_train.astype('float32') \n",
        "#x_test = x_test.astype('float32') \n",
        "\n",
        "# if subtract pixel mean is enabled \n",
        "# center the column-data around zero\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (6874, 200, 200, 3)\n",
            "6874 train samples\n",
            "1719 test samples\n",
            "y_train shape: (6874, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j58TCUSpTH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmx8ifYrprJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 dropout=0.1,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    Arguments:\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    Returns:\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Y0J8UMp3TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=2):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or \n",
        "    also known as bottleneck layer.\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, \n",
        "    the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, \n",
        "    while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have \n",
        "    the same number filters and the same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    Arguments:\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    Returns:\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVUkR2XgqCuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T92lYa5JqG1t",
        "colab_type": "code",
        "outputId": "7817680f-a1ad-4cf9-93b4-22ef7c4250a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200, 200, 16) 0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 200, 200, 16) 272         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200, 200, 16) 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 200, 200, 16) 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 64) 1088        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 64) 1088        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 200, 200, 64) 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 64) 0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 200, 200, 16) 1040        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 16) 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 200, 200, 16) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 200, 200, 64) 1088        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 200, 200, 64) 0           add[0][0]                        \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 200, 200, 64) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 100, 100, 64) 4160        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 100, 100, 64) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 100, 100, 64) 36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 100, 100, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 100, 100, 64) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 100, 100, 128 8320        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 100, 100, 128 8320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 100, 100, 128 0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 100, 100, 128 512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 100, 100, 128 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 100, 100, 128 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 100, 100, 64) 8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 100, 100, 64) 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 100, 100, 64) 0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 128 8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 100, 100, 128 0           add_2[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 100, 128 512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100, 100, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 100, 100, 128 0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 50, 50, 128)  16512       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 50, 50, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 50, 50, 128)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 50, 50, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 50, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 50, 50, 128)  0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 256)  33024       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 256)  33024       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 50, 50, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 50, 50, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 50, 50, 256)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 50, 50, 128)  32896       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 50, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 50, 50, 128)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 50, 50, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 50, 50, 128)  0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 50, 50, 256)  33024       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 50, 50, 256)  0           add_4[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 50, 50, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 50, 50, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 50, 50, 256)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 6, 6, 256)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            18434       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 589,954\n",
            "Trainable params: 586,466\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCCfDIRF1uOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using last check point\n",
        "#from tensorflow.keras.models import load_model\n",
        "\n",
        "#model = load_model('/content/drive/My Drive/Minería de Datos/Interna/datos/Modelos/mujer_ResNet20v2_model.083.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiZiKwkziQ4s",
        "colab_type": "code",
        "outputId": "19d7b52f-b1c8-435d-e235-9774af51d327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Modelos')\n",
        "model_name = 'Drop_MUJER_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0396 - accuracy: 0.7170\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.76207, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.001.h5\n",
            "214/214 [==============================] - 186s 870ms/step - loss: 1.0396 - accuracy: 0.7170 - val_loss: 0.8825 - val_accuracy: 0.7621 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8212 - accuracy: 0.7841\n",
            "Epoch 00002: val_accuracy improved from 0.76207 to 0.79872, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.002.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.8212 - accuracy: 0.7841 - val_loss: 0.7627 - val_accuracy: 0.7987 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7452 - accuracy: 0.8012\n",
            "Epoch 00003: val_accuracy improved from 0.79872 to 0.82315, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.003.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.7452 - accuracy: 0.8012 - val_loss: 0.6657 - val_accuracy: 0.8232 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.8023\n",
            "Epoch 00004: val_accuracy improved from 0.82315 to 0.83653, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.004.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.6962 - accuracy: 0.8023 - val_loss: 0.6101 - val_accuracy: 0.8365 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6283 - accuracy: 0.8221\n",
            "Epoch 00005: val_accuracy improved from 0.83653 to 0.85108, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.005.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.6283 - accuracy: 0.8221 - val_loss: 0.5634 - val_accuracy: 0.8511 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5858 - accuracy: 0.8277\n",
            "Epoch 00006: val_accuracy did not improve from 0.85108\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.5858 - accuracy: 0.8277 - val_loss: 0.5476 - val_accuracy: 0.8458 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.8267\n",
            "Epoch 00007: val_accuracy did not improve from 0.85108\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.5569 - accuracy: 0.8267 - val_loss: 0.5252 - val_accuracy: 0.8424 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.8370\n",
            "Epoch 00008: val_accuracy improved from 0.85108 to 0.85864, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.008.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.5359 - accuracy: 0.8370 - val_loss: 0.4788 - val_accuracy: 0.8586 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.8400\n",
            "Epoch 00009: val_accuracy improved from 0.85864 to 0.86329, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.009.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.5112 - accuracy: 0.8400 - val_loss: 0.4576 - val_accuracy: 0.8633 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.8524\n",
            "Epoch 00010: val_accuracy improved from 0.86329 to 0.87842, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.010.h5\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.4792 - accuracy: 0.8524 - val_loss: 0.4171 - val_accuracy: 0.8784 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.8486\n",
            "Epoch 00011: val_accuracy improved from 0.87842 to 0.87900, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.011.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.4707 - accuracy: 0.8486 - val_loss: 0.4289 - val_accuracy: 0.8790 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.8569\n",
            "Epoch 00012: val_accuracy improved from 0.87900 to 0.88714, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.012.h5\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.4524 - accuracy: 0.8569 - val_loss: 0.3974 - val_accuracy: 0.8871 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.8614\n",
            "Epoch 00013: val_accuracy did not improve from 0.88714\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.4394 - accuracy: 0.8614 - val_loss: 0.3903 - val_accuracy: 0.8819 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.8661\n",
            "Epoch 00014: val_accuracy did not improve from 0.88714\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.4199 - accuracy: 0.8661 - val_loss: 0.5591 - val_accuracy: 0.8063 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.8696\n",
            "Epoch 00015: val_accuracy improved from 0.88714 to 0.89703, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.015.h5\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.4091 - accuracy: 0.8696 - val_loss: 0.3703 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3968 - accuracy: 0.8747\n",
            "Epoch 00016: val_accuracy did not improve from 0.89703\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3968 - accuracy: 0.8747 - val_loss: 0.3664 - val_accuracy: 0.8854 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.8739\n",
            "Epoch 00017: val_accuracy did not improve from 0.89703\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3944 - accuracy: 0.8739 - val_loss: 0.3634 - val_accuracy: 0.8848 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.8840\n",
            "Epoch 00018: val_accuracy improved from 0.89703 to 0.89820, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.018.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3780 - accuracy: 0.8840 - val_loss: 0.3443 - val_accuracy: 0.8982 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 19/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.8783\n",
            "Epoch 00019: val_accuracy did not improve from 0.89820\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3695 - accuracy: 0.8783 - val_loss: 0.3748 - val_accuracy: 0.8813 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.8876\n",
            "Epoch 00020: val_accuracy did not improve from 0.89820\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3662 - accuracy: 0.8876 - val_loss: 0.3603 - val_accuracy: 0.8860 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 21/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.8899\n",
            "Epoch 00021: val_accuracy did not improve from 0.89820\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3523 - accuracy: 0.8899 - val_loss: 0.3554 - val_accuracy: 0.8883 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.8961\n",
            "Epoch 00022: val_accuracy did not improve from 0.89820\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3413 - accuracy: 0.8961 - val_loss: 0.3617 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3380 - accuracy: 0.8921\n",
            "Epoch 00023: val_accuracy improved from 0.89820 to 0.89878, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.023.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3380 - accuracy: 0.8921 - val_loss: 0.3393 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.8986\n",
            "Epoch 00024: val_accuracy improved from 0.89878 to 0.90867, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.024.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3298 - accuracy: 0.8986 - val_loss: 0.3197 - val_accuracy: 0.9087 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.8973\n",
            "Epoch 00025: val_accuracy improved from 0.90867 to 0.91158, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.025.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3298 - accuracy: 0.8973 - val_loss: 0.3231 - val_accuracy: 0.9116 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 26/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.8999\n",
            "Epoch 00026: val_accuracy did not improve from 0.91158\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3168 - accuracy: 0.8999 - val_loss: 0.3169 - val_accuracy: 0.9058 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3223 - accuracy: 0.8993\n",
            "Epoch 00027: val_accuracy did not improve from 0.91158\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3223 - accuracy: 0.8993 - val_loss: 0.4825 - val_accuracy: 0.8441 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 28/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.9015\n",
            "Epoch 00028: val_accuracy improved from 0.91158 to 0.92263, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.028.h5\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3138 - accuracy: 0.9015 - val_loss: 0.2927 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 29/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.9016\n",
            "Epoch 00029: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3138 - accuracy: 0.9016 - val_loss: 0.2824 - val_accuracy: 0.9220 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.9135\n",
            "Epoch 00030: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2959 - accuracy: 0.9135 - val_loss: 0.3195 - val_accuracy: 0.9017 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 31/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.9030\n",
            "Epoch 00031: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3034 - accuracy: 0.9030 - val_loss: 0.2975 - val_accuracy: 0.9127 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 32/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.9065\n",
            "Epoch 00032: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2942 - accuracy: 0.9065 - val_loss: 0.3179 - val_accuracy: 0.9052 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 33/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3075 - accuracy: 0.9000\n",
            "Epoch 00033: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3075 - accuracy: 0.9000 - val_loss: 0.3115 - val_accuracy: 0.9017 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 34/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2914 - accuracy: 0.9110\n",
            "Epoch 00034: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2914 - accuracy: 0.9110 - val_loss: 0.2895 - val_accuracy: 0.9191 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 35/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.9146\n",
            "Epoch 00035: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.2849 - accuracy: 0.9146 - val_loss: 0.3164 - val_accuracy: 0.9011 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 36/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2765 - accuracy: 0.9161\n",
            "Epoch 00036: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2765 - accuracy: 0.9161 - val_loss: 0.2780 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 37/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.9160\n",
            "Epoch 00037: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2764 - accuracy: 0.9160 - val_loss: 0.2838 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 38/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2810 - accuracy: 0.9146\n",
            "Epoch 00038: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2810 - accuracy: 0.9146 - val_loss: 0.2915 - val_accuracy: 0.9133 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 39/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2724 - accuracy: 0.9183\n",
            "Epoch 00039: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2724 - accuracy: 0.9183 - val_loss: 0.2868 - val_accuracy: 0.9098 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 40/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9202\n",
            "Epoch 00040: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2707 - accuracy: 0.9202 - val_loss: 0.2869 - val_accuracy: 0.9110 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 41/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2692 - accuracy: 0.9160\n",
            "Epoch 00041: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2692 - accuracy: 0.9160 - val_loss: 0.2781 - val_accuracy: 0.9133 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 42/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2663 - accuracy: 0.9227\n",
            "Epoch 00042: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2663 - accuracy: 0.9227 - val_loss: 0.3207 - val_accuracy: 0.9023 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 43/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.9231\n",
            "Epoch 00043: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2605 - accuracy: 0.9231 - val_loss: 0.2858 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 44/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.9176\n",
            "Epoch 00044: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.2682 - accuracy: 0.9176 - val_loss: 0.3538 - val_accuracy: 0.8871 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 45/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.9215\n",
            "Epoch 00045: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2636 - accuracy: 0.9215 - val_loss: 0.2736 - val_accuracy: 0.9133 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 46/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.9220\n",
            "Epoch 00046: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2578 - accuracy: 0.9220 - val_loss: 0.2820 - val_accuracy: 0.9122 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 47/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.9259\n",
            "Epoch 00047: val_accuracy did not improve from 0.92263\n",
            "214/214 [==============================] - 183s 853ms/step - loss: 0.2463 - accuracy: 0.9259 - val_loss: 0.2800 - val_accuracy: 0.9151 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 48/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2539 - accuracy: 0.9220\n",
            "Epoch 00048: val_accuracy improved from 0.92263 to 0.92728, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.048.h5\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2539 - accuracy: 0.9220 - val_loss: 0.2680 - val_accuracy: 0.9273 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 49/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.9259\n",
            "Epoch 00049: val_accuracy improved from 0.92728 to 0.92787, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.049.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2468 - accuracy: 0.9259 - val_loss: 0.2540 - val_accuracy: 0.9279 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 50/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9268\n",
            "Epoch 00050: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2449 - accuracy: 0.9268 - val_loss: 0.2878 - val_accuracy: 0.9133 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 51/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.9255\n",
            "Epoch 00051: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.2434 - accuracy: 0.9255 - val_loss: 0.2778 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 52/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.9234\n",
            "Epoch 00052: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2493 - accuracy: 0.9234 - val_loss: 0.2723 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 53/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2531 - accuracy: 0.9212\n",
            "Epoch 00053: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2531 - accuracy: 0.9212 - val_loss: 0.4046 - val_accuracy: 0.8918 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 54/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.9275\n",
            "Epoch 00054: val_accuracy did not improve from 0.92787\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2428 - accuracy: 0.9275 - val_loss: 0.2859 - val_accuracy: 0.9139 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 55/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9291\n",
            "Epoch 00055: val_accuracy improved from 0.92787 to 0.93194, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.055.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2409 - accuracy: 0.9291 - val_loss: 0.2536 - val_accuracy: 0.9319 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 56/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9288\n",
            "Epoch 00056: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2342 - accuracy: 0.9288 - val_loss: 0.2577 - val_accuracy: 0.9284 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 57/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9287\n",
            "Epoch 00057: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2363 - accuracy: 0.9287 - val_loss: 0.4072 - val_accuracy: 0.8726 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 58/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2402 - accuracy: 0.9316\n",
            "Epoch 00058: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2402 - accuracy: 0.9316 - val_loss: 0.2653 - val_accuracy: 0.9232 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 59/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.9309\n",
            "Epoch 00059: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2287 - accuracy: 0.9309 - val_loss: 0.2443 - val_accuracy: 0.9308 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 60/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.9322\n",
            "Epoch 00060: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2355 - accuracy: 0.9322 - val_loss: 0.2584 - val_accuracy: 0.9284 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 61/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9303\n",
            "Epoch 00061: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2317 - accuracy: 0.9303 - val_loss: 0.2560 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 62/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9377\n",
            "Epoch 00062: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2185 - accuracy: 0.9377 - val_loss: 0.2961 - val_accuracy: 0.9168 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 63/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9293\n",
            "Epoch 00063: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2323 - accuracy: 0.9293 - val_loss: 0.2646 - val_accuracy: 0.9232 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 64/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.9351\n",
            "Epoch 00064: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2236 - accuracy: 0.9351 - val_loss: 0.2659 - val_accuracy: 0.9296 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 65/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2253 - accuracy: 0.9345\n",
            "Epoch 00065: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2253 - accuracy: 0.9345 - val_loss: 0.3029 - val_accuracy: 0.9139 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 66/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.9342\n",
            "Epoch 00066: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2356 - accuracy: 0.9342 - val_loss: 0.3124 - val_accuracy: 0.9139 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 67/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.9364\n",
            "Epoch 00067: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2215 - accuracy: 0.9364 - val_loss: 0.2681 - val_accuracy: 0.9261 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 68/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2198 - accuracy: 0.9351\n",
            "Epoch 00068: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2198 - accuracy: 0.9351 - val_loss: 0.2839 - val_accuracy: 0.9273 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 69/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2251 - accuracy: 0.9328\n",
            "Epoch 00069: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2251 - accuracy: 0.9328 - val_loss: 0.3695 - val_accuracy: 0.8883 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 70/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.9395\n",
            "Epoch 00070: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2169 - accuracy: 0.9395 - val_loss: 0.2890 - val_accuracy: 0.9151 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 71/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9331\n",
            "Epoch 00071: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2201 - accuracy: 0.9331 - val_loss: 0.2790 - val_accuracy: 0.9162 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 72/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.9342\n",
            "Epoch 00072: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2192 - accuracy: 0.9342 - val_loss: 0.3109 - val_accuracy: 0.9029 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 73/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.9402\n",
            "Epoch 00073: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2196 - accuracy: 0.9402 - val_loss: 0.2904 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 74/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9386\n",
            "Epoch 00074: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2136 - accuracy: 0.9386 - val_loss: 0.2547 - val_accuracy: 0.9308 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 75/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9366\n",
            "Epoch 00075: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2183 - accuracy: 0.9366 - val_loss: 0.3264 - val_accuracy: 0.9098 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 76/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.9360\n",
            "Epoch 00076: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2158 - accuracy: 0.9360 - val_loss: 0.2728 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 77/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.9353\n",
            "Epoch 00077: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2172 - accuracy: 0.9353 - val_loss: 0.2710 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 78/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9411\n",
            "Epoch 00078: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2141 - accuracy: 0.9411 - val_loss: 0.2657 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 79/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.9370\n",
            "Epoch 00079: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2184 - accuracy: 0.9370 - val_loss: 0.3135 - val_accuracy: 0.9139 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 80/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9385\n",
            "Epoch 00080: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2136 - accuracy: 0.9385 - val_loss: 0.2779 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 81/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.9408\n",
            "Epoch 00081: val_accuracy did not improve from 0.93194\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2124 - accuracy: 0.9408 - val_loss: 0.2540 - val_accuracy: 0.9267 - lr: 0.0010\n",
            "Learning rate:  0.0001\n",
            "Epoch 82/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.9509\n",
            "Epoch 00082: val_accuracy improved from 0.93194 to 0.93892, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.082.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.1839 - accuracy: 0.9509 - val_loss: 0.2264 - val_accuracy: 0.9389 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 83/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9548\n",
            "Epoch 00083: val_accuracy improved from 0.93892 to 0.94124, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Drop_MUJER_ResNet20v2_model.083.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.1764 - accuracy: 0.9548 - val_loss: 0.2260 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 84/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9588\n",
            "Epoch 00084: val_accuracy did not improve from 0.94124\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.1655 - accuracy: 0.9588 - val_loss: 0.2347 - val_accuracy: 0.9389 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 85/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1586 - accuracy: 0.9607\n",
            "Epoch 00085: val_accuracy did not improve from 0.94124\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.1586 - accuracy: 0.9607 - val_loss: 0.2361 - val_accuracy: 0.9389 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 86/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9636\n",
            "Epoch 00086: val_accuracy did not improve from 0.94124\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.1517 - accuracy: 0.9636 - val_loss: 0.2342 - val_accuracy: 0.9383 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 87/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.9652\n",
            "Epoch 00087: val_accuracy did not improve from 0.94124\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.1531 - accuracy: 0.9652 - val_loss: 0.2422 - val_accuracy: 0.9383 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 88/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9651\n",
            "Epoch 00088: val_accuracy did not improve from 0.94124\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.1547 - accuracy: 0.9651 - val_loss: 0.2345 - val_accuracy: 0.9401 - lr: 3.1623e-05\n",
            "Learning rate:  0.0001\n",
            "Epoch 89/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9652\n",
            "Epoch 00089: val_accuracy did not improve from 0.94124\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.1488 - accuracy: 0.9652 - val_loss: 0.2298 - val_accuracy: 0.9389 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 90/90\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.9662\n",
            "Epoch 00090: val_accuracy did not improve from 0.94124\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.1475 - accuracy: 0.9662 - val_loss: 0.2333 - val_accuracy: 0.9401 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezaiJkW-irF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "fdb1527c-afc5-4863-e3ac-cc2a42cdb4a0"
      },
      "source": [
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}