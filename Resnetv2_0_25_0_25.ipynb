{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnetv2_0.25_0.25.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vachaconcu/Mineriadatos/blob/master/Resnetv2_0_25_0_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CTb70R3YZDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from numpy import load\n",
        "os.chdir('/content/drive/My Drive/Mineria/Interna/datos')\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_val_int.npz') ; x_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_train.npz') ; x_train = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_val_int.npz') ; y_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_train.npz') ; y_train = datos['arr_0']\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_val_ext.npz') ; y_test2 = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_val_ext.npz') ; x_test2 = datos['arr_0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7RbMR55bWhS",
        "colab_type": "code",
        "outputId": "517ea2be-e9d4-4282-f76a-3eb5598377fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('x_test =',x_test.shape)\n",
        "print('x_train =',x_train.shape)\n",
        "print('y_test =',y_test.shape)\n",
        "print('y_train =',y_train.shape)\n",
        "\n",
        "print('y_test_ext=', y_test2.shape)\n",
        "print('x_test_ext=', x_test2.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test = (1719, 200, 200, 3)\n",
            "x_train = (6874, 200, 200, 3)\n",
            "y_test = (1719, 2)\n",
            "y_train = (6874, 2)\n",
            "y_test_ext= (2063, 2)\n",
            "x_test_ext= (2063, 200, 200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9DCAJzn05wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoVqIG4mojgL",
        "colab_type": "code",
        "outputId": "aaa19e88-7992-4d76-f459-e87cc61d1fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 32 \n",
        "epochs = 80\n",
        "data_augmentation = True\n",
        "num_classes = 2\n",
        "subtract_pixel_mean = True # subtracting pixel mean improves accuracy\n",
        "n = 2\n",
        "version = 2\n",
        "\n",
        "# computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "model_type"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ResNet20v2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kql8upFhpIg_",
        "colab_type": "code",
        "outputId": "9a78ce27-6ad0-4c8e-ad25-bc21226e1dba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# if subtract pixel mean is enabled \n",
        "# center the column-data around zero\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "    X_test2= x_test2\n",
        "    x_test2 -= x_train_mean\n",
        "    \n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (6874, 200, 200, 3)\n",
            "6874 train samples\n",
            "1719 test samples\n",
            "y_train shape: (6874, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j58TCUSpTH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmx8ifYrprJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    dropout=0.25\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDq4OiWb12Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=2):\n",
        "\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32)')\n",
        "    # start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            # first layer but not first stack\n",
        "            if stack > 0 and res_block == 0:  \n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            # first layer but not first stack\n",
        "            if stack > 0 and res_block == 0:\n",
        "                # linear projection residual shortcut\n",
        "                # connection to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Y0J8UMp3TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=2):\n",
        "\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVUkR2XgqCuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T92lYa5JqG1t",
        "colab_type": "code",
        "outputId": "682e6cc1-c33a-4587-8684-44c6f7e5ed33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200, 200, 16) 0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 200, 200, 16) 272         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200, 200, 16) 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 200, 200, 16) 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 64) 1088        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 64) 1088        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 200, 200, 64) 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 64) 0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 200, 200, 16) 1040        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 16) 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 200, 200, 16) 0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 200, 200, 64) 1088        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 200, 200, 64) 0           add[0][0]                        \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 200, 200, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 200, 200, 64) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 100, 100, 64) 4160        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 100, 100, 64) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 100, 100, 64) 36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 100, 100, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 100, 100, 64) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 100, 100, 128 8320        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 100, 100, 128 8320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 100, 100, 128 0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 100, 100, 128 512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 100, 100, 128 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 100, 100, 128 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 100, 100, 64) 8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 100, 100, 64) 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 100, 100, 64) 0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 128 8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 100, 100, 128 0           add_2[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 100, 128 512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100, 100, 128 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 100, 100, 128 0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 50, 50, 128)  16512       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 50, 50, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 50, 50, 128)  0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 50, 50, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 50, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 50, 50, 128)  0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 256)  33024       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 256)  33024       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 50, 50, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 50, 50, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 50, 50, 256)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 50, 50, 128)  32896       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 50, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 50, 50, 128)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 50, 50, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 50, 50, 128)  0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 50, 50, 256)  33024       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 50, 50, 256)  0           add_4[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 50, 50, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 50, 50, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 50, 50, 256)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 6, 6, 256)    0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            18434       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 589,954\n",
            "Trainable params: 586,466\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCCfDIRF1uOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using last check point\n",
        "#from tensorflow.keras.models import load_model\n",
        "\n",
        "#model = load_model('/content/drive/My Drive/Mineria/Interna/datos/Modelos/mujer_ResNet20v2_model.083.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiZiKwkziQ4s",
        "colab_type": "code",
        "outputId": "3e9e0b2a-cef0-4429-87a8-9f9ee6126dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Resnetv2')\n",
        "model_name = 'HM_0.25_0.25_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0024 - accuracy: 0.7170\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.72077, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.001.h5\n",
            "214/214 [==============================] - 187s 872ms/step - loss: 1.0024 - accuracy: 0.7170 - val_loss: 0.9672 - val_accuracy: 0.7208 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8381 - accuracy: 0.7787\n",
            "Epoch 00002: val_accuracy improved from 0.72077 to 0.79581, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.002.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.8381 - accuracy: 0.7787 - val_loss: 0.7588 - val_accuracy: 0.7958 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7647 - accuracy: 0.7892\n",
            "Epoch 00003: val_accuracy improved from 0.79581 to 0.80977, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.003.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.7647 - accuracy: 0.7892 - val_loss: 0.6943 - val_accuracy: 0.8098 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.8049\n",
            "Epoch 00004: val_accuracy improved from 0.80977 to 0.83130, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.004.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.6915 - accuracy: 0.8049 - val_loss: 0.6305 - val_accuracy: 0.8313 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6450 - accuracy: 0.8113\n",
            "Epoch 00005: val_accuracy did not improve from 0.83130\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.6450 - accuracy: 0.8113 - val_loss: 0.6058 - val_accuracy: 0.8179 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.8221\n",
            "Epoch 00006: val_accuracy improved from 0.83130 to 0.83653, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.006.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.5935 - accuracy: 0.8221 - val_loss: 0.5380 - val_accuracy: 0.8365 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.8186\n",
            "Epoch 00007: val_accuracy improved from 0.83653 to 0.83944, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.007.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.5778 - accuracy: 0.8186 - val_loss: 0.5298 - val_accuracy: 0.8394 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.8331\n",
            "Epoch 00008: val_accuracy improved from 0.83944 to 0.84061, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.008.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.5387 - accuracy: 0.8331 - val_loss: 0.5005 - val_accuracy: 0.8406 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.8319\n",
            "Epoch 00009: val_accuracy improved from 0.84061 to 0.84351, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.009.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.5224 - accuracy: 0.8319 - val_loss: 0.4818 - val_accuracy: 0.8435 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5101 - accuracy: 0.8369\n",
            "Epoch 00010: val_accuracy improved from 0.84351 to 0.86097, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.010.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.5101 - accuracy: 0.8369 - val_loss: 0.4547 - val_accuracy: 0.8610 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.8442\n",
            "Epoch 00011: val_accuracy did not improve from 0.86097\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.4844 - accuracy: 0.8442 - val_loss: 0.4564 - val_accuracy: 0.8482 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4555 - accuracy: 0.8568\n",
            "Epoch 00012: val_accuracy improved from 0.86097 to 0.86911, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.012.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.4555 - accuracy: 0.8568 - val_loss: 0.4135 - val_accuracy: 0.8691 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.8505\n",
            "Epoch 00013: val_accuracy did not improve from 0.86911\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.4573 - accuracy: 0.8505 - val_loss: 0.4614 - val_accuracy: 0.8470 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.8595\n",
            "Epoch 00014: val_accuracy improved from 0.86911 to 0.87435, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.014.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.4330 - accuracy: 0.8595 - val_loss: 0.3889 - val_accuracy: 0.8743 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.8626\n",
            "Epoch 00015: val_accuracy improved from 0.87435 to 0.88540, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.015.h5\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.4261 - accuracy: 0.8626 - val_loss: 0.3682 - val_accuracy: 0.8854 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.8609\n",
            "Epoch 00016: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 853ms/step - loss: 0.4300 - accuracy: 0.8609 - val_loss: 0.3819 - val_accuracy: 0.8714 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.8727\n",
            "Epoch 00017: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3973 - accuracy: 0.8727 - val_loss: 0.5444 - val_accuracy: 0.8051 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.8664\n",
            "Epoch 00018: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 853ms/step - loss: 0.4057 - accuracy: 0.8664 - val_loss: 0.4111 - val_accuracy: 0.8691 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 19/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.8787\n",
            "Epoch 00019: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 853ms/step - loss: 0.3848 - accuracy: 0.8787 - val_loss: 0.4049 - val_accuracy: 0.8807 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8737\n",
            "Epoch 00020: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 854ms/step - loss: 0.3906 - accuracy: 0.8737 - val_loss: 0.3833 - val_accuracy: 0.8767 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 21/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3784 - accuracy: 0.8755\n",
            "Epoch 00021: val_accuracy did not improve from 0.88540\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3784 - accuracy: 0.8755 - val_loss: 0.3668 - val_accuracy: 0.8796 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8828\n",
            "Epoch 00022: val_accuracy improved from 0.88540 to 0.90460, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.022.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.3656 - accuracy: 0.8828 - val_loss: 0.3316 - val_accuracy: 0.9046 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.8819\n",
            "Epoch 00023: val_accuracy did not improve from 0.90460\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3638 - accuracy: 0.8819 - val_loss: 0.3609 - val_accuracy: 0.8831 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.8851\n",
            "Epoch 00024: val_accuracy did not improve from 0.90460\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3618 - accuracy: 0.8851 - val_loss: 0.4180 - val_accuracy: 0.8697 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.8848\n",
            "Epoch 00025: val_accuracy did not improve from 0.90460\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3550 - accuracy: 0.8848 - val_loss: 0.3751 - val_accuracy: 0.8813 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 26/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.8905\n",
            "Epoch 00026: val_accuracy did not improve from 0.90460\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3545 - accuracy: 0.8905 - val_loss: 0.3513 - val_accuracy: 0.8895 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8911\n",
            "Epoch 00027: val_accuracy did not improve from 0.90460\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3429 - accuracy: 0.8911 - val_loss: 0.3990 - val_accuracy: 0.8743 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 28/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.8926\n",
            "Epoch 00028: val_accuracy did not improve from 0.90460\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3369 - accuracy: 0.8926 - val_loss: 0.3355 - val_accuracy: 0.8895 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 29/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.8986\n",
            "Epoch 00029: val_accuracy did not improve from 0.90460\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3304 - accuracy: 0.8986 - val_loss: 0.3990 - val_accuracy: 0.8685 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8955\n",
            "Epoch 00030: val_accuracy improved from 0.90460 to 0.90692, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.030.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.3311 - accuracy: 0.8955 - val_loss: 0.3321 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 31/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.8970\n",
            "Epoch 00031: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3270 - accuracy: 0.8970 - val_loss: 0.5767 - val_accuracy: 0.8272 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 32/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.8986\n",
            "Epoch 00032: val_accuracy did not improve from 0.90692\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3228 - accuracy: 0.8986 - val_loss: 0.3632 - val_accuracy: 0.8901 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 33/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.8992\n",
            "Epoch 00033: val_accuracy improved from 0.90692 to 0.91274, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.033.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.3210 - accuracy: 0.8992 - val_loss: 0.3004 - val_accuracy: 0.9127 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 34/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3171 - accuracy: 0.9003\n",
            "Epoch 00034: val_accuracy did not improve from 0.91274\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3171 - accuracy: 0.9003 - val_loss: 0.3080 - val_accuracy: 0.9075 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 35/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3139 - accuracy: 0.8989\n",
            "Epoch 00035: val_accuracy did not improve from 0.91274\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3139 - accuracy: 0.8989 - val_loss: 0.3282 - val_accuracy: 0.9040 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 36/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.9054\n",
            "Epoch 00036: val_accuracy did not improve from 0.91274\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3115 - accuracy: 0.9054 - val_loss: 0.3603 - val_accuracy: 0.8842 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 37/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3037 - accuracy: 0.9022\n",
            "Epoch 00037: val_accuracy improved from 0.91274 to 0.92321, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.037.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.3037 - accuracy: 0.9022 - val_loss: 0.2962 - val_accuracy: 0.9232 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 38/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3067 - accuracy: 0.9021\n",
            "Epoch 00038: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3067 - accuracy: 0.9021 - val_loss: 0.2998 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 39/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.9008\n",
            "Epoch 00039: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3076 - accuracy: 0.9008 - val_loss: 0.2937 - val_accuracy: 0.9168 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 40/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.9031\n",
            "Epoch 00040: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3047 - accuracy: 0.9031 - val_loss: 0.3194 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 41/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.9027\n",
            "Epoch 00041: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.3020 - accuracy: 0.9027 - val_loss: 0.2965 - val_accuracy: 0.9092 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 42/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3023 - accuracy: 0.9076\n",
            "Epoch 00042: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.3023 - accuracy: 0.9076 - val_loss: 0.2793 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 43/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.9120\n",
            "Epoch 00043: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2945 - accuracy: 0.9120 - val_loss: 0.4429 - val_accuracy: 0.8685 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 44/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.9095\n",
            "Epoch 00044: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2929 - accuracy: 0.9095 - val_loss: 0.3138 - val_accuracy: 0.9023 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 45/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.9114\n",
            "Epoch 00045: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2906 - accuracy: 0.9114 - val_loss: 0.3323 - val_accuracy: 0.8965 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 46/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.9136\n",
            "Epoch 00046: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2785 - accuracy: 0.9136 - val_loss: 0.2886 - val_accuracy: 0.9162 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 47/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.9116\n",
            "Epoch 00047: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2956 - accuracy: 0.9116 - val_loss: 0.3477 - val_accuracy: 0.8976 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 48/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.9186\n",
            "Epoch 00048: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2773 - accuracy: 0.9186 - val_loss: 0.2897 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 49/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.9158\n",
            "Epoch 00049: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2760 - accuracy: 0.9158 - val_loss: 0.3135 - val_accuracy: 0.9151 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 50/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2852 - accuracy: 0.9127\n",
            "Epoch 00050: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2852 - accuracy: 0.9127 - val_loss: 0.2916 - val_accuracy: 0.9162 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 51/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.9163\n",
            "Epoch 00051: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2744 - accuracy: 0.9163 - val_loss: 0.4027 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 52/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.9173\n",
            "Epoch 00052: val_accuracy did not improve from 0.92321\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2795 - accuracy: 0.9173 - val_loss: 0.2995 - val_accuracy: 0.9052 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 53/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.9152\n",
            "Epoch 00053: val_accuracy improved from 0.92321 to 0.92554, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.053.h5\n",
            "214/214 [==============================] - 184s 859ms/step - loss: 0.2805 - accuracy: 0.9152 - val_loss: 0.2706 - val_accuracy: 0.9255 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 54/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2695 - accuracy: 0.9184\n",
            "Epoch 00054: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2695 - accuracy: 0.9184 - val_loss: 0.2840 - val_accuracy: 0.9180 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 55/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.9146\n",
            "Epoch 00055: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2713 - accuracy: 0.9146 - val_loss: 0.3263 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 56/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2754 - accuracy: 0.9184\n",
            "Epoch 00056: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2754 - accuracy: 0.9184 - val_loss: 0.2761 - val_accuracy: 0.9174 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 57/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 0.9218\n",
            "Epoch 00057: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2585 - accuracy: 0.9218 - val_loss: 0.3028 - val_accuracy: 0.9075 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 58/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.9186\n",
            "Epoch 00058: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2653 - accuracy: 0.9186 - val_loss: 0.3058 - val_accuracy: 0.9087 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 59/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2654 - accuracy: 0.9163\n",
            "Epoch 00059: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2654 - accuracy: 0.9163 - val_loss: 0.2826 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 60/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.9239\n",
            "Epoch 00060: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2562 - accuracy: 0.9239 - val_loss: 0.3168 - val_accuracy: 0.9046 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 61/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.9167\n",
            "Epoch 00061: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2686 - accuracy: 0.9167 - val_loss: 0.4250 - val_accuracy: 0.8668 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 62/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.9234\n",
            "Epoch 00062: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2588 - accuracy: 0.9234 - val_loss: 0.3316 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 63/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.9247\n",
            "Epoch 00063: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2584 - accuracy: 0.9247 - val_loss: 0.2806 - val_accuracy: 0.9133 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 64/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.9237\n",
            "Epoch 00064: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2584 - accuracy: 0.9237 - val_loss: 0.2813 - val_accuracy: 0.9215 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 65/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.9203\n",
            "Epoch 00065: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 855ms/step - loss: 0.2609 - accuracy: 0.9203 - val_loss: 0.2758 - val_accuracy: 0.9232 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 66/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2601 - accuracy: 0.9228\n",
            "Epoch 00066: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2601 - accuracy: 0.9228 - val_loss: 0.4025 - val_accuracy: 0.8645 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 67/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9252\n",
            "Epoch 00067: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2528 - accuracy: 0.9252 - val_loss: 0.2803 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 68/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.9237\n",
            "Epoch 00068: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2600 - accuracy: 0.9237 - val_loss: 0.2779 - val_accuracy: 0.9209 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 69/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2570 - accuracy: 0.9222\n",
            "Epoch 00069: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2570 - accuracy: 0.9222 - val_loss: 0.2918 - val_accuracy: 0.9186 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 70/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2484 - accuracy: 0.9263\n",
            "Epoch 00070: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2484 - accuracy: 0.9263 - val_loss: 0.2806 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 71/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2539 - accuracy: 0.9228\n",
            "Epoch 00071: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 856ms/step - loss: 0.2539 - accuracy: 0.9228 - val_loss: 0.2583 - val_accuracy: 0.9255 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 72/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.9260\n",
            "Epoch 00072: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.2522 - accuracy: 0.9260 - val_loss: 0.2800 - val_accuracy: 0.9122 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 73/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.9221\n",
            "Epoch 00073: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2555 - accuracy: 0.9221 - val_loss: 0.2770 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 74/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 0.9228\n",
            "Epoch 00074: val_accuracy did not improve from 0.92554\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2568 - accuracy: 0.9228 - val_loss: 0.2787 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 75/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.9259\n",
            "Epoch 00075: val_accuracy improved from 0.92554 to 0.92728, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.075.h5\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.2500 - accuracy: 0.9259 - val_loss: 0.2677 - val_accuracy: 0.9273 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 76/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.9263\n",
            "Epoch 00076: val_accuracy improved from 0.92728 to 0.93426, saving model to /content/drive/.shortcut-targets-by-id/1EIw6ZmKwlGHMh1CQuZhn85QTdh7-YF5_/Interna/datos/./Resnetv2/HM_0.25_0.25_ResNet20v2_model.076.h5\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2454 - accuracy: 0.9263 - val_loss: 0.2532 - val_accuracy: 0.9343 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 77/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.9224\n",
            "Epoch 00077: val_accuracy did not improve from 0.93426\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2456 - accuracy: 0.9224 - val_loss: 0.2565 - val_accuracy: 0.9296 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 78/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.9258\n",
            "Epoch 00078: val_accuracy did not improve from 0.93426\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2463 - accuracy: 0.9258 - val_loss: 0.3244 - val_accuracy: 0.9098 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 79/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2422 - accuracy: 0.9297\n",
            "Epoch 00079: val_accuracy did not improve from 0.93426\n",
            "214/214 [==============================] - 183s 857ms/step - loss: 0.2422 - accuracy: 0.9297 - val_loss: 0.3100 - val_accuracy: 0.9110 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 80/80\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2519 - accuracy: 0.9240\n",
            "Epoch 00080: val_accuracy did not improve from 0.93426\n",
            "214/214 [==============================] - 184s 858ms/step - loss: 0.2519 - accuracy: 0.9240 - val_loss: 0.3104 - val_accuracy: 0.9145 - lr: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezaiJkW-irF6",
        "colab_type": "code",
        "outputId": "406af238-867f-48af-da72-3b33b36587f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}