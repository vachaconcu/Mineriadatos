{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Resnet Versión 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vachaconcu/Mineriadatos/blob/master/RazaFinal_0.25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTxMkZCVWgLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ba17275-1e05-4f66-b42c-edce730c6eac"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "from skimage import data\n",
        "from os import remove\n",
        "from skimage.color import rgb2gray\n",
        "from numpy import load\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape,ZeroPadding2D,Activation,MaxPooling2D,Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import SpatialDropout2D\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD51PRPCPR_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b8801518-e555-4294-d904-e4f92961a2ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CTb70R3YZDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_val_int.npz') ; x_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_train.npz') ; x_train = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_val_int.npz') ; y_test = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_train.npz') ; y_train = datos['arr_0']\n",
        "\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/y_HM_val_ext.npz') ; y_test2 = datos['arr_0']\n",
        "datos= load('/content/drive/My Drive/Mineria/Interna/datos/X_HM_val_ext.npz') ; x_test2 = datos['arr_0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7RbMR55bWhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7d6cde0c-998f-406c-e1bf-e56f8dbac75c"
      },
      "source": [
        "print('x_test =',x_test.shape)\n",
        "print('x_train =',x_train.shape)\n",
        "print('y_test =',y_test.shape)\n",
        "print('y_train =',y_train.shape)\n",
        "\n",
        "print('y_test_ext=', y_test2.shape)\n",
        "print('x_test_ext=', x_test2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test = (1719, 200, 200, 3)\n",
            "x_train = (6874, 200, 200, 3)\n",
            "y_test = (1719, 2)\n",
            "y_train = (6874, 2)\n",
            "y_test_ext= (2063, 2)\n",
            "x_test_ext= (2063, 200, 200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXtMPu12ogD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoVqIG4mojgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d089cdb-9857-4747-b104-021e0c49a047"
      },
      "source": [
        "batch_size = 32 # orig paper trained all networks with batch_size=128\n",
        "epochs = 85\n",
        "\n",
        "data_augmentation = True\n",
        "num_classes = 2\n",
        "# subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter para sexo c: \n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 2\n",
        "\n",
        "# model version\n",
        "# orig paper: version = 1 (ResNet v1), \n",
        "# improved ResNet: version = 2 (ResNet v2)\n",
        "version = 2\n",
        "\n",
        "# computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "model_type"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ResNet20v2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kql8upFhpIg_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b365615a-cd09-466e-a6a9-3e678705083a"
      },
      "source": [
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "#x_train = x_train.astype('float32') \n",
        "#x_test = x_test.astype('float32') \n",
        "\n",
        "# if subtract pixel mean is enabled \n",
        "# center the column-data around zero\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (6874, 200, 200, 3)\n",
            "6874 train samples\n",
            "1719 test samples\n",
            "y_train shape: (6874, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j58TCUSpTH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmx8ifYrprJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 dropout=0.25,\n",
        "                 conv_first=True):\n",
        "  \n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    \n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGBeU2-4VUlA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b8cc96c-6e46-46ae-fe07-6b9e45cb58ea"
      },
      "source": [
        "num_res_blocks = int((depth - 2) / 9)\n",
        "num_res_blocks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Y0J8UMp3TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=2, dropout=0.25):\n",
        "    \n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "    # start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU\n",
        "    # on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                # first layer but not first stage\n",
        "                if res_block == 0:\n",
        "                    # downsample\n",
        "                    strides = 2 \n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection\n",
        "                # to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "# add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVUkR2XgqCuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T92lYa5JqG1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "810ce9e6-4901-4c0f-b215-b8ac3aad5483"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 200, 200, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 200, 200, 16) 64          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 200, 200, 16) 0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 200, 200, 16) 272         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 200, 200, 16) 64          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 200, 200, 16) 0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 200, 200, 16) 2320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 200, 200, 16) 64          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 200, 200, 16) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 200, 200, 16) 0           dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 200, 200, 64) 1088        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 200, 200, 64) 1088        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 200, 200, 64) 0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 200, 200, 64) 256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 200, 200, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 200, 200, 64) 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 200, 200, 16) 1040        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 200, 200, 16) 64          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 200, 200, 16) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 200, 200, 16) 0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 200, 200, 16) 2320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 200, 200, 16) 64          conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 200, 200, 16) 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 200, 200, 16) 0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 200, 200, 64) 1088        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 200, 200, 64) 0           add_2[0][0]                      \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 200, 200, 64) 256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 200, 200, 64) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 200, 200, 64) 0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 100, 100, 64) 4160        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 100, 100, 64) 256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 100, 100, 64) 0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 100, 100, 64) 36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 100, 100, 64) 256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 100, 100, 64) 0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 100, 100, 128 8320        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 100, 100, 128 8320        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 100, 100, 128 0           conv2d_19[0][0]                  \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 100, 100, 128 512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 100, 100, 128 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 100, 100, 128 0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 100, 100, 64) 8256        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 100, 100, 64) 256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 100, 100, 64) 0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 100, 100, 64) 36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 100, 100, 64) 256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 100, 100, 64) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 100, 100, 64) 0           dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 100, 100, 128 8320        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 100, 100, 128 0           add_4[0][0]                      \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 100, 100, 128 512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 100, 100, 128 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 100, 100, 128 0           dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 50, 50, 128)  16512       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 50, 50, 128)  512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 50, 50, 128)  0           dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 50, 50, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 50, 50, 128)  512         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 50, 50, 128)  0           dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 50, 50, 256)  33024       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 50, 50, 256)  33024       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 50, 50, 256)  0           conv2d_26[0][0]                  \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 50, 50, 256)  1024        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 50, 50, 256)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 50, 50, 256)  0           dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 50, 50, 128)  32896       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 50, 50, 128)  512         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 50, 50, 128)  0           dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 50, 50, 128)  147584      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 50, 50, 128)  512         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 50, 50, 128)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 50, 50, 128)  0           dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 50, 50, 256)  33024       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 50, 50, 256)  0           add_6[0][0]                      \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 50, 50, 256)  1024        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 50, 50, 256)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 50, 50, 256)  0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 6, 6, 256)    0           dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9216)         0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            18434       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 589,954\n",
            "Trainable params: 586,466\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCCfDIRF1uOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using last check point\n",
        "#from tensorflow.keras.models import load_model\n",
        "\n",
        "#model = load_model('/content/drive/My Drive/Mineria/Interna/datos/Modelos/mujer_ResNet20v2_model.083.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiZiKwkziQ4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c58b9e9-4dfe-4419-e364-e2a1dd32aa2b"
      },
      "source": [
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), './Modelos')\n",
        "model_name = 'Mujer_Primera_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 1.0469 - accuracy: 0.7163\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.64165, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.001.h5\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 1.0469 - accuracy: 0.7163 - val_loss: 1.0141 - val_accuracy: 0.6417 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.8484 - accuracy: 0.7745\n",
            "Epoch 00002: val_accuracy improved from 0.64165 to 0.76091, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.002.h5\n",
            "214/214 [==============================] - 78s 364ms/step - loss: 0.8484 - accuracy: 0.7745 - val_loss: 0.8268 - val_accuracy: 0.7609 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.7808 - accuracy: 0.7833\n",
            "Epoch 00003: val_accuracy improved from 0.76091 to 0.77661, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.003.h5\n",
            "214/214 [==============================] - 78s 364ms/step - loss: 0.7808 - accuracy: 0.7833 - val_loss: 0.9253 - val_accuracy: 0.7766 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.8030\n",
            "Epoch 00004: val_accuracy improved from 0.77661 to 0.82897, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.004.h5\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.6941 - accuracy: 0.8030 - val_loss: 0.6153 - val_accuracy: 0.8290 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6312 - accuracy: 0.8115\n",
            "Epoch 00005: val_accuracy did not improve from 0.82897\n",
            "214/214 [==============================] - 78s 362ms/step - loss: 0.6312 - accuracy: 0.8115 - val_loss: 0.5812 - val_accuracy: 0.8272 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.6033 - accuracy: 0.8099\n",
            "Epoch 00006: val_accuracy did not improve from 0.82897\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.6033 - accuracy: 0.8099 - val_loss: 0.5894 - val_accuracy: 0.8255 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.8126\n",
            "Epoch 00007: val_accuracy improved from 0.82897 to 0.84933, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.007.h5\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 0.5785 - accuracy: 0.8126 - val_loss: 0.5026 - val_accuracy: 0.8493 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.8274\n",
            "Epoch 00008: val_accuracy did not improve from 0.84933\n",
            "214/214 [==============================] - 82s 383ms/step - loss: 0.5317 - accuracy: 0.8274 - val_loss: 0.5609 - val_accuracy: 0.8237 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.8274\n",
            "Epoch 00009: val_accuracy did not improve from 0.84933\n",
            "214/214 [==============================] - 78s 364ms/step - loss: 0.5188 - accuracy: 0.8274 - val_loss: 0.5698 - val_accuracy: 0.8127 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4931 - accuracy: 0.8334\n",
            "Epoch 00010: val_accuracy did not improve from 0.84933\n",
            "214/214 [==============================] - 78s 364ms/step - loss: 0.4931 - accuracy: 0.8334 - val_loss: 0.4970 - val_accuracy: 0.8377 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.8363\n",
            "Epoch 00011: val_accuracy improved from 0.84933 to 0.85049, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.011.h5\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 0.4834 - accuracy: 0.8363 - val_loss: 0.4665 - val_accuracy: 0.8505 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.8338\n",
            "Epoch 00012: val_accuracy improved from 0.85049 to 0.86678, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.012.h5\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 0.4806 - accuracy: 0.8338 - val_loss: 0.4161 - val_accuracy: 0.8668 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.8454\n",
            "Epoch 00013: val_accuracy improved from 0.86678 to 0.86853, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.013.h5\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.4559 - accuracy: 0.8454 - val_loss: 0.4006 - val_accuracy: 0.8685 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.8528\n",
            "Epoch 00014: val_accuracy did not improve from 0.86853\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.4372 - accuracy: 0.8528 - val_loss: 0.4111 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8519\n",
            "Epoch 00015: val_accuracy did not improve from 0.86853\n",
            "214/214 [==============================] - 78s 365ms/step - loss: 0.4360 - accuracy: 0.8519 - val_loss: 0.4337 - val_accuracy: 0.8546 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.8500\n",
            "Epoch 00016: val_accuracy did not improve from 0.86853\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.4311 - accuracy: 0.8500 - val_loss: 0.4137 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.8645\n",
            "Epoch 00017: val_accuracy improved from 0.86853 to 0.87667, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.017.h5\n",
            "214/214 [==============================] - 78s 364ms/step - loss: 0.4039 - accuracy: 0.8645 - val_loss: 0.3725 - val_accuracy: 0.8767 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.8682\n",
            "Epoch 00018: val_accuracy did not improve from 0.87667\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.4024 - accuracy: 0.8682 - val_loss: 0.3779 - val_accuracy: 0.8761 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 19/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8657\n",
            "Epoch 00019: val_accuracy improved from 0.87667 to 0.87784, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.019.h5\n",
            "214/214 [==============================] - 79s 367ms/step - loss: 0.3927 - accuracy: 0.8657 - val_loss: 0.3742 - val_accuracy: 0.8778 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.8740\n",
            "Epoch 00020: val_accuracy improved from 0.87784 to 0.89180, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.020.h5\n",
            "214/214 [==============================] - 78s 364ms/step - loss: 0.3794 - accuracy: 0.8740 - val_loss: 0.3408 - val_accuracy: 0.8918 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 21/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.8669\n",
            "Epoch 00021: val_accuracy did not improve from 0.89180\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3831 - accuracy: 0.8669 - val_loss: 0.3780 - val_accuracy: 0.8720 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8743\n",
            "Epoch 00022: val_accuracy did not improve from 0.89180\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3732 - accuracy: 0.8743 - val_loss: 0.4248 - val_accuracy: 0.8557 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.8759\n",
            "Epoch 00023: val_accuracy did not improve from 0.89180\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3670 - accuracy: 0.8759 - val_loss: 0.3665 - val_accuracy: 0.8796 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8765\n",
            "Epoch 00024: val_accuracy improved from 0.89180 to 0.90809, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.024.h5\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3596 - accuracy: 0.8765 - val_loss: 0.3262 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.8772\n",
            "Epoch 00025: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3664 - accuracy: 0.8772 - val_loss: 0.3975 - val_accuracy: 0.8674 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 26/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8842\n",
            "Epoch 00026: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3496 - accuracy: 0.8842 - val_loss: 0.3305 - val_accuracy: 0.8965 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.8813\n",
            "Epoch 00027: val_accuracy did not improve from 0.90809\n",
            "214/214 [==============================] - 78s 362ms/step - loss: 0.3588 - accuracy: 0.8813 - val_loss: 0.3485 - val_accuracy: 0.8860 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 28/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8876\n",
            "Epoch 00028: val_accuracy improved from 0.90809 to 0.91099, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.028.h5\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3429 - accuracy: 0.8876 - val_loss: 0.3045 - val_accuracy: 0.9110 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 29/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.8918\n",
            "Epoch 00029: val_accuracy did not improve from 0.91099\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3344 - accuracy: 0.8918 - val_loss: 0.3097 - val_accuracy: 0.9092 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8908\n",
            "Epoch 00030: val_accuracy did not improve from 0.91099\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3386 - accuracy: 0.8908 - val_loss: 0.3799 - val_accuracy: 0.8807 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 31/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.8942\n",
            "Epoch 00031: val_accuracy did not improve from 0.91099\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3282 - accuracy: 0.8942 - val_loss: 0.3568 - val_accuracy: 0.8807 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 32/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3385 - accuracy: 0.8892\n",
            "Epoch 00032: val_accuracy did not improve from 0.91099\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3385 - accuracy: 0.8892 - val_loss: 0.3264 - val_accuracy: 0.9011 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 33/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.8945\n",
            "Epoch 00033: val_accuracy did not improve from 0.91099\n",
            "214/214 [==============================] - 78s 363ms/step - loss: 0.3244 - accuracy: 0.8945 - val_loss: 0.3914 - val_accuracy: 0.8639 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 34/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.8942\n",
            "Epoch 00034: val_accuracy did not improve from 0.91099\n",
            "214/214 [==============================] - 78s 364ms/step - loss: 0.3251 - accuracy: 0.8942 - val_loss: 0.3042 - val_accuracy: 0.9098 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 35/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3160 - accuracy: 0.8939\n",
            "Epoch 00035: val_accuracy improved from 0.91099 to 0.92147, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.035.h5\n",
            "214/214 [==============================] - 78s 364ms/step - loss: 0.3160 - accuracy: 0.8939 - val_loss: 0.2871 - val_accuracy: 0.9215 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 36/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8968\n",
            "Epoch 00036: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 364ms/step - loss: 0.3177 - accuracy: 0.8968 - val_loss: 0.2954 - val_accuracy: 0.9075 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 37/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.8952\n",
            "Epoch 00037: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.3143 - accuracy: 0.8952 - val_loss: 0.3171 - val_accuracy: 0.8999 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 38/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8970\n",
            "Epoch 00038: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.3123 - accuracy: 0.8970 - val_loss: 0.3636 - val_accuracy: 0.8825 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 39/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3176 - accuracy: 0.8958\n",
            "Epoch 00039: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 364ms/step - loss: 0.3176 - accuracy: 0.8958 - val_loss: 0.3721 - val_accuracy: 0.8819 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 40/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.9019\n",
            "Epoch 00040: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 365ms/step - loss: 0.3030 - accuracy: 0.9019 - val_loss: 0.3009 - val_accuracy: 0.9110 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 41/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.9028\n",
            "Epoch 00041: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.3048 - accuracy: 0.9028 - val_loss: 0.2919 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 42/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.8984\n",
            "Epoch 00042: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.3049 - accuracy: 0.8984 - val_loss: 0.3012 - val_accuracy: 0.9087 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 43/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.9088\n",
            "Epoch 00043: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.2928 - accuracy: 0.9088 - val_loss: 0.3066 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 44/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.9085\n",
            "Epoch 00044: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 367ms/step - loss: 0.2925 - accuracy: 0.9085 - val_loss: 0.3078 - val_accuracy: 0.9023 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 45/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.9031\n",
            "Epoch 00045: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.3042 - accuracy: 0.9031 - val_loss: 0.3055 - val_accuracy: 0.9069 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 46/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.9075\n",
            "Epoch 00046: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.2865 - accuracy: 0.9075 - val_loss: 0.3295 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 47/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.9070\n",
            "Epoch 00047: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 78s 365ms/step - loss: 0.2872 - accuracy: 0.9070 - val_loss: 0.2873 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 48/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2846 - accuracy: 0.9073\n",
            "Epoch 00048: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 83s 386ms/step - loss: 0.2846 - accuracy: 0.9073 - val_loss: 0.2899 - val_accuracy: 0.9133 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 49/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.9066\n",
            "Epoch 00049: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 82s 384ms/step - loss: 0.2961 - accuracy: 0.9066 - val_loss: 0.3020 - val_accuracy: 0.9098 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 50/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.9063\n",
            "Epoch 00050: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 0.2805 - accuracy: 0.9063 - val_loss: 0.2943 - val_accuracy: 0.9116 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 51/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.9126\n",
            "Epoch 00051: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 79s 367ms/step - loss: 0.2818 - accuracy: 0.9126 - val_loss: 0.2971 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 52/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2852 - accuracy: 0.9097\n",
            "Epoch 00052: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 79s 367ms/step - loss: 0.2852 - accuracy: 0.9097 - val_loss: 0.3261 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 53/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9092\n",
            "Epoch 00053: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 0.2834 - accuracy: 0.9092 - val_loss: 0.3319 - val_accuracy: 0.8999 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 54/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.9158\n",
            "Epoch 00054: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 0.2679 - accuracy: 0.9158 - val_loss: 0.3061 - val_accuracy: 0.9017 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 55/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.9179\n",
            "Epoch 00055: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 0.2710 - accuracy: 0.9179 - val_loss: 0.2804 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 56/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.9176\n",
            "Epoch 00056: val_accuracy did not improve from 0.92147\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.2689 - accuracy: 0.9176 - val_loss: 0.2733 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 57/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.9104\n",
            "Epoch 00057: val_accuracy improved from 0.92147 to 0.92612, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.057.h5\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.2814 - accuracy: 0.9104 - val_loss: 0.2635 - val_accuracy: 0.9261 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 58/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.9177\n",
            "Epoch 00058: val_accuracy did not improve from 0.92612\n",
            "214/214 [==============================] - 79s 367ms/step - loss: 0.2686 - accuracy: 0.9177 - val_loss: 0.3144 - val_accuracy: 0.9110 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 59/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.9127\n",
            "Epoch 00059: val_accuracy did not improve from 0.92612\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.2729 - accuracy: 0.9127 - val_loss: 0.2750 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 60/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.9151\n",
            "Epoch 00060: val_accuracy did not improve from 0.92612\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.2772 - accuracy: 0.9151 - val_loss: 0.2688 - val_accuracy: 0.9232 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 61/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2680 - accuracy: 0.9146\n",
            "Epoch 00061: val_accuracy did not improve from 0.92612\n",
            "214/214 [==============================] - 78s 366ms/step - loss: 0.2680 - accuracy: 0.9146 - val_loss: 0.4125 - val_accuracy: 0.8598 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 62/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9183\n",
            "Epoch 00062: val_accuracy did not improve from 0.92612\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 0.2632 - accuracy: 0.9183 - val_loss: 0.2693 - val_accuracy: 0.9255 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 63/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2634 - accuracy: 0.9184\n",
            "Epoch 00063: val_accuracy did not improve from 0.92612\n",
            "214/214 [==============================] - 78s 367ms/step - loss: 0.2634 - accuracy: 0.9184 - val_loss: 0.3037 - val_accuracy: 0.9023 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 64/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.9199\n",
            "Epoch 00064: val_accuracy did not improve from 0.92612\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 0.2620 - accuracy: 0.9199 - val_loss: 0.3008 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 65/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.9183\n",
            "Epoch 00065: val_accuracy did not improve from 0.92612\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 0.2609 - accuracy: 0.9183 - val_loss: 0.3206 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 66/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.9236\n",
            "Epoch 00066: val_accuracy did not improve from 0.92612\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 0.2596 - accuracy: 0.9236 - val_loss: 0.2660 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 67/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.9275\n",
            "Epoch 00067: val_accuracy did not improve from 0.92612\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 0.2522 - accuracy: 0.9275 - val_loss: 0.2753 - val_accuracy: 0.9250 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 68/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.9182\n",
            "Epoch 00068: val_accuracy improved from 0.92612 to 0.93310, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.068.h5\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.2591 - accuracy: 0.9182 - val_loss: 0.2484 - val_accuracy: 0.9331 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 69/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.9201\n",
            "Epoch 00069: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 0.2548 - accuracy: 0.9201 - val_loss: 0.2691 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 70/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2533 - accuracy: 0.9262\n",
            "Epoch 00070: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 81s 378ms/step - loss: 0.2533 - accuracy: 0.9262 - val_loss: 0.2665 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 71/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.9217\n",
            "Epoch 00071: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 80s 372ms/step - loss: 0.2579 - accuracy: 0.9217 - val_loss: 0.2962 - val_accuracy: 0.9133 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 72/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.9195\n",
            "Epoch 00072: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.2622 - accuracy: 0.9195 - val_loss: 0.2576 - val_accuracy: 0.9279 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 73/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.9239\n",
            "Epoch 00073: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.2543 - accuracy: 0.9239 - val_loss: 0.2756 - val_accuracy: 0.9197 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 74/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.9260\n",
            "Epoch 00074: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 80s 372ms/step - loss: 0.2534 - accuracy: 0.9260 - val_loss: 0.2997 - val_accuracy: 0.9127 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 75/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2554 - accuracy: 0.9247\n",
            "Epoch 00075: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 0.2554 - accuracy: 0.9247 - val_loss: 0.3388 - val_accuracy: 0.8982 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 76/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.9296\n",
            "Epoch 00076: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 0.2448 - accuracy: 0.9296 - val_loss: 0.3069 - val_accuracy: 0.9098 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 77/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.9275\n",
            "Epoch 00077: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 0.2462 - accuracy: 0.9275 - val_loss: 0.2510 - val_accuracy: 0.9273 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 78/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9265\n",
            "Epoch 00078: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 0.2409 - accuracy: 0.9265 - val_loss: 0.2611 - val_accuracy: 0.9250 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 79/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.9271\n",
            "Epoch 00079: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 0.2469 - accuracy: 0.9271 - val_loss: 0.2830 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 80/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2436 - accuracy: 0.9278\n",
            "Epoch 00080: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 80s 373ms/step - loss: 0.2436 - accuracy: 0.9278 - val_loss: 0.3369 - val_accuracy: 0.9046 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 81/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 0.9244\n",
            "Epoch 00081: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 0.2532 - accuracy: 0.9244 - val_loss: 0.2754 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Learning rate:  0.0001\n",
            "Epoch 82/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.9389\n",
            "Epoch 00082: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 0.2184 - accuracy: 0.9389 - val_loss: 0.2474 - val_accuracy: 0.9302 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 83/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9445\n",
            "Epoch 00083: val_accuracy did not improve from 0.93310\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 0.2049 - accuracy: 0.9445 - val_loss: 0.2480 - val_accuracy: 0.9331 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 84/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1975 - accuracy: 0.9467\n",
            "Epoch 00084: val_accuracy improved from 0.93310 to 0.93426, saving model to /content/drive/My Drive/Minería de Datos/Interna/datos/./Modelos/Mujer_Primera_ResNet20v2_model.084.h5\n",
            "214/214 [==============================] - 79s 371ms/step - loss: 0.1975 - accuracy: 0.9467 - val_loss: 0.2492 - val_accuracy: 0.9343 - lr: 1.0000e-04\n",
            "Learning rate:  0.0001\n",
            "Epoch 85/85\n",
            "214/214 [==============================] - ETA: 0s - loss: 0.1973 - accuracy: 0.9481\n",
            "Epoch 00085: val_accuracy did not improve from 0.93426\n",
            "214/214 [==============================] - 80s 372ms/step - loss: 0.1973 - accuracy: 0.9481 - val_loss: 0.2440 - val_accuracy: 0.9337 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezaiJkW-irF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "fb72776f-0c9d-42a2-c333-276fff93113f"
      },
      "source": [
        "#print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}